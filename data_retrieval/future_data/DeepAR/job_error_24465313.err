GpuFreq=control_disabled
[I 2024-10-13 11:25:47,180] A new study created in memory with name: no-name-df6a0351-1f12-4813-9ae7-a7e5a5456187
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/torch/random.py:167: UserWarning: CUDA reports that you have 4 available devices, and you have used fork_rng without explicitly specifying which devices are being used. For safety, we initialize *every* CUDA device by default, which can be quite slow if you have a lot of CUDAs. If you know that you are only making use of a few CUDA devices, set the environment variable CUDA_VISIBLE_DEVICES or the 'devices' keyword argument of fork_rng with the set of devices you are actually using. For example, if you are using CPU only, set device.upper()_VISIBLE_DEVICES= or devices=[]; if you are using device 0 only, set CUDA_VISIBLE_DEVICES=0 or devices=[0].  To initialize all devices and suppress this warning, set the 'devices' keyword argument to `range(torch.cuda.device_count())`.
  warnings.warn(message)
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 1 processes
----------------------------------------------------------------------------------------------------

LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Metric val_loss improved. New best score: 0.614
Metric val_loss improved by 0.063 >= min_delta = 0.0. New best score: 0.551
Metric val_loss improved by 0.066 >= min_delta = 0.0. New best score: 0.485
Metric val_loss improved by 0.073 >= min_delta = 0.0. New best score: 0.412
Metric val_loss improved by 0.077 >= min_delta = 0.0. New best score: 0.334
Metric val_loss improved by 0.088 >= min_delta = 0.0. New best score: 0.246
Metric val_loss improved by 0.118 >= min_delta = 0.0. New best score: 0.128
Metric val_loss improved by 0.132 >= min_delta = 0.0. New best score: -0.004
Metric val_loss improved by 0.150 >= min_delta = 0.0. New best score: -0.154
Metric val_loss improved by 0.151 >= min_delta = 0.0. New best score: -0.305
Metric val_loss improved by 0.146 >= min_delta = 0.0. New best score: -0.451
Metric val_loss improved by 0.081 >= min_delta = 0.0. New best score: -0.532
Metric val_loss improved by 0.128 >= min_delta = 0.0. New best score: -0.660
Metric val_loss improved by 0.078 >= min_delta = 0.0. New best score: -0.738
Metric val_loss improved by 0.044 >= min_delta = 0.0. New best score: -0.782
Metric val_loss improved by 0.014 >= min_delta = 0.0. New best score: -0.796
Metric val_loss improved by 0.013 >= min_delta = 0.0. New best score: -0.810
Metric val_loss improved by 0.013 >= min_delta = 0.0. New best score: -0.823
Metric val_loss improved by 0.011 >= min_delta = 0.0. New best score: -0.833
Metric val_loss improved by 0.009 >= min_delta = 0.0. New best score: -0.842
Metric val_loss improved by 0.005 >= min_delta = 0.0. New best score: -0.847
Metric val_loss improved by 0.012 >= min_delta = 0.0. New best score: -0.860
Metric val_loss improved by 0.008 >= min_delta = 0.0. New best score: -0.867
Metric val_loss improved by 0.015 >= min_delta = 0.0. New best score: -0.882
Metric val_loss improved by 0.006 >= min_delta = 0.0. New best score: -0.888
Metric val_loss improved by 0.012 >= min_delta = 0.0. New best score: -0.900
Monitored metric val_loss did not improve in the last 60 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:26:14,773] Trial 0 finished with value: 21.26544189453125 and parameters: {'n_layers': 2, 'dropout': 0.45331392564915196, 'input_chunk_length': 51, 'hidden_dim': 55, 'learning_rate': 4.547145261194438e-05, 'batch_size': 32, 'training_length': 249}. Best is trial 0 with value: 21.26544189453125.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 61 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:26:15,380] Trial 1 finished with value: 17.71782112121582 and parameters: {'n_layers': 1, 'input_chunk_length': 48, 'hidden_dim': 127, 'learning_rate': 7.655668038659712e-05, 'batch_size': 32, 'training_length': 57}. Best is trial 1 with value: 17.71782112121582.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 62 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:26:16,128] Trial 2 finished with value: 22.14247703552246 and parameters: {'n_layers': 1, 'input_chunk_length': 23, 'hidden_dim': 83, 'learning_rate': 0.0003982979131665189, 'batch_size': 16, 'training_length': 114}. Best is trial 1 with value: 17.71782112121582.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 63 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:26:16,871] Trial 3 finished with value: 23.58682632446289 and parameters: {'n_layers': 2, 'dropout': 0.09505382211409702, 'input_chunk_length': 57, 'hidden_dim': 116, 'learning_rate': 6.494903388833213e-07, 'batch_size': 32, 'training_length': 380}. Best is trial 1 with value: 17.71782112121582.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 64 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:26:17,584] Trial 4 finished with value: 19.8252010345459 and parameters: {'n_layers': 1, 'input_chunk_length': 52, 'hidden_dim': 63, 'learning_rate': 1.6970293646590715e-05, 'batch_size': 16, 'training_length': 143}. Best is trial 1 with value: 17.71782112121582.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 65 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:26:18,314] Trial 5 finished with value: 18.6507568359375 and parameters: {'n_layers': 1, 'input_chunk_length': 57, 'hidden_dim': 136, 'learning_rate': 4.23083029051461e-07, 'batch_size': 64, 'training_length': 250}. Best is trial 1 with value: 17.71782112121582.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 66 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:26:20,363] Trial 6 finished with value: 22.749155044555664 and parameters: {'n_layers': 2, 'dropout': 0.17493344147243006, 'input_chunk_length': 45, 'hidden_dim': 189, 'learning_rate': 1.627132014686557e-05, 'batch_size': 16, 'training_length': 239}. Best is trial 1 with value: 17.71782112121582.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 67 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:26:20,949] Trial 7 finished with value: 24.607481002807617 and parameters: {'n_layers': 1, 'input_chunk_length': 53, 'hidden_dim': 53, 'learning_rate': 2.2271702566862057e-06, 'batch_size': 32, 'training_length': 275}. Best is trial 1 with value: 17.71782112121582.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 68 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:26:22,218] Trial 8 finished with value: 33.51827621459961 and parameters: {'n_layers': 2, 'dropout': 0.0626861967476261, 'input_chunk_length': 78, 'hidden_dim': 144, 'learning_rate': 0.00027257831505174196, 'batch_size': 32, 'training_length': 245}. Best is trial 1 with value: 17.71782112121582.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 69 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:26:23,796] Trial 9 finished with value: 20.387592315673828 and parameters: {'n_layers': 1, 'input_chunk_length': 37, 'hidden_dim': 171, 'learning_rate': 8.29485459426416e-06, 'batch_size': 16, 'training_length': 429}. Best is trial 1 with value: 17.71782112121582.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 70 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:26:24,380] Trial 10 finished with value: 23.463537216186523 and parameters: {'n_layers': 1, 'input_chunk_length': 87, 'hidden_dim': 105, 'learning_rate': 9.710386690701786e-05, 'batch_size': 64, 'training_length': 88}. Best is trial 1 with value: 17.71782112121582.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 71 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:26:25,287] Trial 11 finished with value: 33.246456146240234 and parameters: {'n_layers': 1, 'input_chunk_length': 71, 'hidden_dim': 139, 'learning_rate': 1.1081107977792792e-07, 'batch_size': 64, 'training_length': 484}. Best is trial 1 with value: 17.71782112121582.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 72 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:26:26,001] Trial 12 finished with value: 18.55830955505371 and parameters: {'n_layers': 1, 'input_chunk_length': 11, 'hidden_dim': 150, 'learning_rate': 1.2972801963355833e-07, 'batch_size': 64, 'training_length': 164}. Best is trial 1 with value: 17.71782112121582.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 73 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:26:26,592] Trial 13 finished with value: 17.775327682495117 and parameters: {'n_layers': 1, 'input_chunk_length': 11, 'hidden_dim': 164, 'learning_rate': 3.8031609499470387e-06, 'batch_size': 64, 'training_length': 20}. Best is trial 1 with value: 17.71782112121582.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 74 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:26:27,283] Trial 14 finished with value: 19.956119537353516 and parameters: {'n_layers': 1, 'input_chunk_length': 29, 'hidden_dim': 170, 'learning_rate': 4.526221530974926e-06, 'batch_size': 32, 'training_length': 30}. Best is trial 1 with value: 17.71782112121582.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 75 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:26:27,970] Trial 15 finished with value: 29.49266815185547 and parameters: {'n_layers': 1, 'input_chunk_length': 99, 'hidden_dim': 193, 'learning_rate': 4.586088260947701e-05, 'batch_size': 64, 'training_length': 187}. Best is trial 1 with value: 17.71782112121582.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 76 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:26:28,578] Trial 16 finished with value: 24.64303207397461 and parameters: {'n_layers': 1, 'input_chunk_length': 11, 'hidden_dim': 99, 'learning_rate': 2.039349781418271e-06, 'batch_size': 32, 'training_length': 47}. Best is trial 1 with value: 17.71782112121582.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 77 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:26:29,322] Trial 17 finished with value: 30.369064331054688 and parameters: {'n_layers': 2, 'dropout': 0.388577330144534, 'input_chunk_length': 24, 'hidden_dim': 157, 'learning_rate': 0.0009495247742195463, 'batch_size': 64, 'training_length': 81}. Best is trial 1 with value: 17.71782112121582.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 78 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:26:29,974] Trial 18 finished with value: 25.171924591064453 and parameters: {'n_layers': 1, 'input_chunk_length': 69, 'hidden_dim': 125, 'learning_rate': 9.915220662679638e-05, 'batch_size': 32, 'training_length': 364}. Best is trial 1 with value: 17.71782112121582.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 79 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:26:30,747] Trial 19 finished with value: 18.145782470703125 and parameters: {'n_layers': 1, 'input_chunk_length': 36, 'hidden_dim': 172, 'learning_rate': 3.1420743566913785e-05, 'batch_size': 64, 'training_length': 190}. Best is trial 1 with value: 17.71782112121582.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 80 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:26:31,327] Trial 20 finished with value: 19.786361694335938 and parameters: {'n_layers': 2, 'dropout': 0.29194248093631214, 'input_chunk_length': 19, 'hidden_dim': 87, 'learning_rate': 4.370388341292566e-06, 'batch_size': 64, 'training_length': 27}. Best is trial 1 with value: 17.71782112121582.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 81 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:26:32,014] Trial 21 finished with value: 30.943613052368164 and parameters: {'n_layers': 1, 'input_chunk_length': 37, 'hidden_dim': 175, 'learning_rate': 3.775175187367568e-05, 'batch_size': 64, 'training_length': 112}. Best is trial 1 with value: 17.71782112121582.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 82 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:26:32,806] Trial 22 finished with value: 21.267799377441406 and parameters: {'n_layers': 1, 'input_chunk_length': 38, 'hidden_dim': 183, 'learning_rate': 0.00012367165045100448, 'batch_size': 64, 'training_length': 190}. Best is trial 1 with value: 17.71782112121582.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 83 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:26:33,426] Trial 23 finished with value: 18.147424697875977 and parameters: {'n_layers': 1, 'input_chunk_length': 30, 'hidden_dim': 159, 'learning_rate': 2.2071304332525634e-05, 'batch_size': 64, 'training_length': 72}. Best is trial 1 with value: 17.71782112121582.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 84 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:26:34,173] Trial 24 finished with value: 16.256479263305664 and parameters: {'n_layers': 1, 'input_chunk_length': 66, 'hidden_dim': 200, 'learning_rate': 7.981105929675317e-06, 'batch_size': 64, 'training_length': 316}. Best is trial 24 with value: 16.256479263305664.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 85 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:26:35,100] Trial 25 finished with value: 29.29023551940918 and parameters: {'n_layers': 1, 'input_chunk_length': 63, 'hidden_dim': 193, 'learning_rate': 8.20418319268418e-06, 'batch_size': 32, 'training_length': 329}. Best is trial 24 with value: 16.256479263305664.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 86 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:26:35,668] Trial 26 finished with value: 25.6357479095459 and parameters: {'n_layers': 1, 'input_chunk_length': 81, 'hidden_dim': 125, 'learning_rate': 1.0020169683361108e-06, 'batch_size': 64, 'training_length': 328}. Best is trial 24 with value: 16.256479263305664.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 87 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:26:36,551] Trial 27 finished with value: 35.123939514160156 and parameters: {'n_layers': 1, 'input_chunk_length': 64, 'hidden_dim': 163, 'learning_rate': 4.1171675028507576e-06, 'batch_size': 64, 'training_length': 309}. Best is trial 24 with value: 16.256479263305664.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 88 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:26:37,578] Trial 28 finished with value: 22.574844360351562 and parameters: {'n_layers': 1, 'input_chunk_length': 95, 'hidden_dim': 182, 'learning_rate': 2.3323040037453664e-06, 'batch_size': 16, 'training_length': 145}. Best is trial 24 with value: 16.256479263305664.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 89 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:26:39,259] Trial 29 finished with value: 22.881303787231445 and parameters: {'n_layers': 2, 'dropout': 0.26141358705917406, 'input_chunk_length': 44, 'hidden_dim': 151, 'learning_rate': 9.595915359561986e-06, 'batch_size': 32, 'training_length': 408}. Best is trial 24 with value: 16.256479263305664.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 90 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:26:40,082] Trial 30 finished with value: 19.1757755279541 and parameters: {'n_layers': 1, 'input_chunk_length': 76, 'hidden_dim': 198, 'learning_rate': 6.14874044925463e-05, 'batch_size': 32, 'training_length': 212}. Best is trial 24 with value: 16.256479263305664.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 91 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:26:40,952] Trial 31 finished with value: 17.343873977661133 and parameters: {'n_layers': 1, 'input_chunk_length': 17, 'hidden_dim': 176, 'learning_rate': 2.9820230329832978e-05, 'batch_size': 64, 'training_length': 287}. Best is trial 24 with value: 16.256479263305664.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 92 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:26:41,673] Trial 32 finished with value: 16.770381927490234 and parameters: {'n_layers': 1, 'input_chunk_length': 17, 'hidden_dim': 200, 'learning_rate': 0.00023143067652268447, 'batch_size': 64, 'training_length': 286}. Best is trial 24 with value: 16.256479263305664.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 93 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:26:42,407] Trial 33 finished with value: 20.88814353942871 and parameters: {'n_layers': 1, 'input_chunk_length': 17, 'hidden_dim': 198, 'learning_rate': 0.00028619776767316513, 'batch_size': 64, 'training_length': 293}. Best is trial 24 with value: 16.256479263305664.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 94 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:26:43,362] Trial 34 finished with value: 25.13596534729004 and parameters: {'n_layers': 1, 'input_chunk_length': 45, 'hidden_dim': 180, 'learning_rate': 0.00016432940645172816, 'batch_size': 64, 'training_length': 362}. Best is trial 24 with value: 16.256479263305664.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 95 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:26:44,708] Trial 35 finished with value: 32.35054016113281 and parameters: {'n_layers': 1, 'input_chunk_length': 26, 'hidden_dim': 186, 'learning_rate': 0.0008122949948956609, 'batch_size': 16, 'training_length': 290}. Best is trial 24 with value: 16.256479263305664.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 96 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:26:45,259] Trial 36 finished with value: 38.347232818603516 and parameters: {'n_layers': 1, 'input_chunk_length': 18, 'hidden_dim': 66, 'learning_rate': 0.00046527742264457136, 'batch_size': 64, 'training_length': 336}. Best is trial 24 with value: 16.256479263305664.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 97 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:26:46,226] Trial 37 finished with value: 18.204120635986328 and parameters: {'n_layers': 1, 'input_chunk_length': 61, 'hidden_dim': 190, 'learning_rate': 7.19502144657543e-05, 'batch_size': 32, 'training_length': 253}. Best is trial 24 with value: 16.256479263305664.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 98 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:26:48,005] Trial 38 finished with value: 25.678638458251953 and parameters: {'n_layers': 2, 'dropout': 0.016834999825697028, 'input_chunk_length': 47, 'hidden_dim': 199, 'learning_rate': 1.6919876842919492e-05, 'batch_size': 16, 'training_length': 273}. Best is trial 24 with value: 16.256479263305664.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 99 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:26:48,578] Trial 39 finished with value: 18.618131637573242 and parameters: {'n_layers': 1, 'input_chunk_length': 57, 'hidden_dim': 111, 'learning_rate': 2.7240608651069523e-05, 'batch_size': 64, 'training_length': 224}. Best is trial 24 with value: 16.256479263305664.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 100 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:26:49,578] Trial 40 finished with value: 17.30840492248535 and parameters: {'n_layers': 1, 'input_chunk_length': 32, 'hidden_dim': 133, 'learning_rate': 0.00019831081304483024, 'batch_size': 32, 'training_length': 403}. Best is trial 24 with value: 16.256479263305664.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 101 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:26:50,583] Trial 41 finished with value: 17.38837432861328 and parameters: {'n_layers': 1, 'input_chunk_length': 32, 'hidden_dim': 133, 'learning_rate': 0.0002100039097219242, 'batch_size': 32, 'training_length': 408}. Best is trial 24 with value: 16.256479263305664.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 102 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:26:51,617] Trial 42 finished with value: 42.005516052246094 and parameters: {'n_layers': 1, 'input_chunk_length': 30, 'hidden_dim': 132, 'learning_rate': 0.0005363177596028206, 'batch_size': 32, 'training_length': 449}. Best is trial 24 with value: 16.256479263305664.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 103 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:26:52,743] Trial 43 finished with value: 30.80806541442871 and parameters: {'n_layers': 1, 'input_chunk_length': 21, 'hidden_dim': 178, 'learning_rate': 0.00019266864758532521, 'batch_size': 32, 'training_length': 393}. Best is trial 24 with value: 16.256479263305664.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 104 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:26:53,403] Trial 44 finished with value: 30.95511245727539 and parameters: {'n_layers': 1, 'input_chunk_length': 14, 'hidden_dim': 118, 'learning_rate': 0.0003135442690809343, 'batch_size': 32, 'training_length': 457}. Best is trial 24 with value: 16.256479263305664.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 105 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:26:54,395] Trial 45 finished with value: 19.28718376159668 and parameters: {'n_layers': 1, 'input_chunk_length': 33, 'hidden_dim': 150, 'learning_rate': 0.00020040866044286046, 'batch_size': 32, 'training_length': 356}. Best is trial 24 with value: 16.256479263305664.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 106 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:26:55,605] Trial 46 finished with value: 18.374601364135742 and parameters: {'n_layers': 1, 'input_chunk_length': 41, 'hidden_dim': 145, 'learning_rate': 0.0006122828469009714, 'batch_size': 32, 'training_length': 382}. Best is trial 24 with value: 16.256479263305664.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 107 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:26:56,514] Trial 47 finished with value: 32.40644073486328 and parameters: {'n_layers': 1, 'input_chunk_length': 51, 'hidden_dim': 134, 'learning_rate': 5.222919165567856e-05, 'batch_size': 64, 'training_length': 493}. Best is trial 24 with value: 16.256479263305664.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 108 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:26:57,237] Trial 48 finished with value: 17.870155334472656 and parameters: {'n_layers': 1, 'input_chunk_length': 14, 'hidden_dim': 96, 'learning_rate': 0.00014378436081464215, 'batch_size': 16, 'training_length': 421}. Best is trial 24 with value: 16.256479263305664.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 109 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:26:58,259] Trial 49 finished with value: 19.78070831298828 and parameters: {'n_layers': 1, 'input_chunk_length': 24, 'hidden_dim': 167, 'learning_rate': 1.277023342443574e-05, 'batch_size': 64, 'training_length': 461}. Best is trial 24 with value: 16.256479263305664.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 110 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:26:59,188] Trial 50 finished with value: 33.03028869628906 and parameters: {'n_layers': 1, 'input_chunk_length': 26, 'hidden_dim': 139, 'learning_rate': 9.111518138006133e-05, 'batch_size': 32, 'training_length': 313}. Best is trial 24 with value: 16.256479263305664.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 111 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:26:59,822] Trial 51 finished with value: 30.7740421295166 and parameters: {'n_layers': 1, 'input_chunk_length': 48, 'hidden_dim': 118, 'learning_rate': 0.00023732205487031005, 'batch_size': 32, 'training_length': 267}. Best is trial 24 with value: 16.256479263305664.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 112 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:00,872] Trial 52 finished with value: 26.745004653930664 and parameters: {'n_layers': 1, 'input_chunk_length': 70, 'hidden_dim': 188, 'learning_rate': 0.00036667466286392574, 'batch_size': 32, 'training_length': 305}. Best is trial 24 with value: 16.256479263305664.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 113 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:01,528] Trial 53 finished with value: 25.14931869506836 and parameters: {'n_layers': 1, 'input_chunk_length': 54, 'hidden_dim': 125, 'learning_rate': 7.71608290448473e-05, 'batch_size': 32, 'training_length': 344}. Best is trial 24 with value: 16.256479263305664.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 114 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:02,176] Trial 54 finished with value: 26.627914428710938 and parameters: {'n_layers': 1, 'input_chunk_length': 41, 'hidden_dim': 109, 'learning_rate': 0.00012213572219688942, 'batch_size': 32, 'training_length': 405}. Best is trial 24 with value: 16.256479263305664.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 115 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:02,922] Trial 55 finished with value: 22.2879581451416 and parameters: {'n_layers': 1, 'input_chunk_length': 33, 'hidden_dim': 129, 'learning_rate': 4.473594498728757e-05, 'batch_size': 64, 'training_length': 237}. Best is trial 24 with value: 16.256479263305664.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 116 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:03,732] Trial 56 finished with value: 29.29889488220215 and parameters: {'n_layers': 1, 'input_chunk_length': 22, 'hidden_dim': 193, 'learning_rate': 1.2378639353407023e-05, 'batch_size': 64, 'training_length': 436}. Best is trial 24 with value: 16.256479263305664.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 117 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:04,621] Trial 57 finished with value: 28.209810256958008 and parameters: {'n_layers': 1, 'input_chunk_length': 67, 'hidden_dim': 141, 'learning_rate': 2.200833575993836e-05, 'batch_size': 32, 'training_length': 263}. Best is trial 24 with value: 16.256479263305664.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 118 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:05,432] Trial 58 finished with value: 21.89224624633789 and parameters: {'n_layers': 1, 'input_chunk_length': 15, 'hidden_dim': 158, 'learning_rate': 6.569468705383539e-06, 'batch_size': 64, 'training_length': 285}. Best is trial 24 with value: 16.256479263305664.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 119 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:06,157] Trial 59 finished with value: 19.839200973510742 and parameters: {'n_layers': 2, 'dropout': 0.36391585689927464, 'input_chunk_length': 10, 'hidden_dim': 99, 'learning_rate': 0.0001366295041163134, 'batch_size': 32, 'training_length': 319}. Best is trial 24 with value: 16.256479263305664.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 120 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:06,713] Trial 60 finished with value: 23.488994598388672 and parameters: {'n_layers': 1, 'input_chunk_length': 34, 'hidden_dim': 77, 'learning_rate': 9.608645398665778e-05, 'batch_size': 64, 'training_length': 375}. Best is trial 24 with value: 16.256479263305664.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 121 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:07,328] Trial 61 finished with value: 32.160987854003906 and parameters: {'n_layers': 1, 'input_chunk_length': 28, 'hidden_dim': 175, 'learning_rate': 5.935080510206086e-06, 'batch_size': 64, 'training_length': 40}. Best is trial 24 with value: 16.256479263305664.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 122 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:07,971] Trial 62 finished with value: 17.782825469970703 and parameters: {'n_layers': 1, 'input_chunk_length': 19, 'hidden_dim': 164, 'learning_rate': 1.369811745733716e-06, 'batch_size': 64, 'training_length': 70}. Best is trial 24 with value: 16.256479263305664.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 123 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:08,554] Trial 63 finished with value: 16.830442428588867 and parameters: {'n_layers': 1, 'input_chunk_length': 13, 'hidden_dim': 153, 'learning_rate': 2.747511194599658e-06, 'batch_size': 64, 'training_length': 16}. Best is trial 24 with value: 16.256479263305664.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 124 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:09,201] Trial 64 finished with value: 25.995464324951172 and parameters: {'n_layers': 1, 'input_chunk_length': 15, 'hidden_dim': 138, 'learning_rate': 2.125636271549544e-06, 'batch_size': 64, 'training_length': 105}. Best is trial 24 with value: 16.256479263305664.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 125 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:09,833] Trial 65 finished with value: 18.624942779541016 and parameters: {'n_layers': 1, 'input_chunk_length': 58, 'hidden_dim': 150, 'learning_rate': 3.552035085132997e-05, 'batch_size': 64, 'training_length': 82}. Best is trial 24 with value: 16.256479263305664.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 126 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:10,806] Trial 66 finished with value: 17.756223678588867 and parameters: {'n_layers': 1, 'input_chunk_length': 75, 'hidden_dim': 145, 'learning_rate': 3.392228060097508e-07, 'batch_size': 16, 'training_length': 167}. Best is trial 24 with value: 16.256479263305664.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 127 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:11,449] Trial 67 finished with value: 19.16868782043457 and parameters: {'n_layers': 1, 'input_chunk_length': 12, 'hidden_dim': 154, 'learning_rate': 2.9110238397739975e-06, 'batch_size': 64, 'training_length': 56}. Best is trial 24 with value: 16.256479263305664.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 128 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:12,220] Trial 68 finished with value: 23.358671188354492 and parameters: {'n_layers': 1, 'input_chunk_length': 40, 'hidden_dim': 129, 'learning_rate': 0.0003590797621112811, 'batch_size': 32, 'training_length': 100}. Best is trial 24 with value: 16.256479263305664.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 129 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:13,065] Trial 69 finished with value: 17.541040420532227 and parameters: {'n_layers': 1, 'input_chunk_length': 22, 'hidden_dim': 185, 'learning_rate': 1.4261690250998963e-06, 'batch_size': 64, 'training_length': 216}. Best is trial 24 with value: 16.256479263305664.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 130 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:13,774] Trial 70 finished with value: 29.250530242919922 and parameters: {'n_layers': 1, 'input_chunk_length': 22, 'hidden_dim': 193, 'learning_rate': 9.803555601520984e-07, 'batch_size': 64, 'training_length': 214}. Best is trial 24 with value: 16.256479263305664.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 131 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:14,495] Trial 71 finished with value: 23.970815658569336 and parameters: {'n_layers': 1, 'input_chunk_length': 17, 'hidden_dim': 184, 'learning_rate': 1.6024405356363908e-06, 'batch_size': 64, 'training_length': 128}. Best is trial 24 with value: 16.256479263305664.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 132 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:15,101] Trial 72 finished with value: 16.24340057373047 and parameters: {'n_layers': 1, 'input_chunk_length': 26, 'hidden_dim': 200, 'learning_rate': 2.972680728074533e-07, 'batch_size': 64, 'training_length': 50}. Best is trial 72 with value: 16.24340057373047.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 133 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:15,706] Trial 73 finished with value: 16.24336051940918 and parameters: {'n_layers': 1, 'input_chunk_length': 26, 'hidden_dim': 200, 'learning_rate': 2.5112625987340477e-07, 'batch_size': 64, 'training_length': 43}. Best is trial 73 with value: 16.24336051940918.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 134 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:16,306] Trial 74 finished with value: 19.47966766357422 and parameters: {'n_layers': 1, 'input_chunk_length': 26, 'hidden_dim': 199, 'learning_rate': 2.081606365388536e-07, 'batch_size': 64, 'training_length': 54}. Best is trial 73 with value: 16.24336051940918.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 135 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:16,901] Trial 75 finished with value: 18.67318344116211 and parameters: {'n_layers': 1, 'input_chunk_length': 20, 'hidden_dim': 195, 'learning_rate': 4.585085015598549e-07, 'batch_size': 64, 'training_length': 28}. Best is trial 73 with value: 16.24336051940918.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 136 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:17,555] Trial 76 finished with value: 27.154735565185547 and parameters: {'n_layers': 1, 'input_chunk_length': 28, 'hidden_dim': 189, 'learning_rate': 1.5231389678988466e-07, 'batch_size': 64, 'training_length': 67}. Best is trial 73 with value: 16.24336051940918.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 137 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:18,173] Trial 77 finished with value: 18.164697647094727 and parameters: {'n_layers': 1, 'input_chunk_length': 31, 'hidden_dim': 177, 'learning_rate': 3.2590703831204767e-07, 'batch_size': 64, 'training_length': 46}. Best is trial 73 with value: 16.24336051940918.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 138 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:18,916] Trial 78 finished with value: 16.24463653564453 and parameters: {'n_layers': 1, 'input_chunk_length': 25, 'hidden_dim': 200, 'learning_rate': 8.187800232561273e-07, 'batch_size': 64, 'training_length': 302}. Best is trial 73 with value: 16.24336051940918.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 139 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:19,649] Trial 79 finished with value: 16.244186401367188 and parameters: {'n_layers': 1, 'input_chunk_length': 25, 'hidden_dim': 200, 'learning_rate': 5.888546371569051e-07, 'batch_size': 64, 'training_length': 300}. Best is trial 73 with value: 16.24336051940918.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 140 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:20,410] Trial 80 finished with value: 16.24435806274414 and parameters: {'n_layers': 1, 'input_chunk_length': 25, 'hidden_dim': 200, 'learning_rate': 5.933663618163143e-07, 'batch_size': 64, 'training_length': 344}. Best is trial 73 with value: 16.24336051940918.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 141 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:21,175] Trial 81 finished with value: 16.24468231201172 and parameters: {'n_layers': 1, 'input_chunk_length': 26, 'hidden_dim': 200, 'learning_rate': 6.930657982721669e-07, 'batch_size': 64, 'training_length': 346}. Best is trial 73 with value: 16.24336051940918.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 142 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:21,913] Trial 82 finished with value: 16.244234085083008 and parameters: {'n_layers': 1, 'input_chunk_length': 24, 'hidden_dim': 200, 'learning_rate': 6.537126013290431e-07, 'batch_size': 64, 'training_length': 302}. Best is trial 73 with value: 16.24336051940918.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 143 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:22,650] Trial 83 finished with value: 16.244449615478516 and parameters: {'n_layers': 1, 'input_chunk_length': 25, 'hidden_dim': 200, 'learning_rate': 6.75409172606997e-07, 'batch_size': 64, 'training_length': 301}. Best is trial 73 with value: 16.24336051940918.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 144 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:23,424] Trial 84 finished with value: 18.681705474853516 and parameters: {'n_layers': 1, 'input_chunk_length': 24, 'hidden_dim': 195, 'learning_rate': 6.167841783852228e-07, 'batch_size': 64, 'training_length': 347}. Best is trial 73 with value: 16.24336051940918.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 145 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:24,183] Trial 85 finished with value: 16.2369441986084 and parameters: {'n_layers': 1, 'input_chunk_length': 35, 'hidden_dim': 200, 'learning_rate': 8.249000729019718e-07, 'batch_size': 64, 'training_length': 328}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 146 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:25,101] Trial 86 finished with value: 19.735275268554688 and parameters: {'n_layers': 1, 'input_chunk_length': 35, 'hidden_dim': 191, 'learning_rate': 7.646277980834354e-07, 'batch_size': 64, 'training_length': 300}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 147 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:25,860] Trial 87 finished with value: 16.42658805847168 and parameters: {'n_layers': 1, 'input_chunk_length': 26, 'hidden_dim': 196, 'learning_rate': 2.3057505839377496e-07, 'batch_size': 64, 'training_length': 327}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 148 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:26,624] Trial 88 finished with value: 16.244388580322266 and parameters: {'n_layers': 1, 'input_chunk_length': 27, 'hidden_dim': 200, 'learning_rate': 5.310772070836241e-07, 'batch_size': 64, 'training_length': 343}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 149 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:27,383] Trial 89 finished with value: 16.470972061157227 and parameters: {'n_layers': 1, 'input_chunk_length': 28, 'hidden_dim': 196, 'learning_rate': 5.342885215164336e-07, 'batch_size': 64, 'training_length': 324}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 150 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:28,964] Trial 90 finished with value: 24.39129638671875 and parameters: {'n_layers': 2, 'dropout': 0.4851659498818436, 'input_chunk_length': 38, 'hidden_dim': 188, 'learning_rate': 3.534089789732977e-07, 'batch_size': 64, 'training_length': 371}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 151 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:29,723] Trial 91 finished with value: 16.245460510253906 and parameters: {'n_layers': 1, 'input_chunk_length': 24, 'hidden_dim': 200, 'learning_rate': 9.00062989538008e-07, 'batch_size': 64, 'training_length': 342}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 152 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:30,678] Trial 92 finished with value: 19.297840118408203 and parameters: {'n_layers': 1, 'input_chunk_length': 29, 'hidden_dim': 181, 'learning_rate': 2.494615583363877e-07, 'batch_size': 64, 'training_length': 357}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 153 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:31,592] Trial 93 finished with value: 19.74136734008789 and parameters: {'n_layers': 1, 'input_chunk_length': 25, 'hidden_dim': 191, 'learning_rate': 7.371038598449406e-07, 'batch_size': 64, 'training_length': 296}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 154 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:32,316] Trial 94 finished with value: 16.244060516357422 and parameters: {'n_layers': 1, 'input_chunk_length': 30, 'hidden_dim': 200, 'learning_rate': 4.817986604344635e-07, 'batch_size': 64, 'training_length': 278}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 155 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:33,043] Trial 95 finished with value: 16.427160263061523 and parameters: {'n_layers': 1, 'input_chunk_length': 30, 'hidden_dim': 196, 'learning_rate': 4.4302948283981394e-07, 'batch_size': 64, 'training_length': 280}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 156 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:33,968] Trial 96 finished with value: 31.70926284790039 and parameters: {'n_layers': 1, 'input_chunk_length': 36, 'hidden_dim': 186, 'learning_rate': 1.609937847348615e-07, 'batch_size': 64, 'training_length': 312}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 157 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:34,832] Trial 97 finished with value: 19.732955932617188 and parameters: {'n_layers': 1, 'input_chunk_length': 20, 'hidden_dim': 191, 'learning_rate': 5.562596627788563e-07, 'batch_size': 64, 'training_length': 244}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 158 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:35,553] Trial 98 finished with value: 20.833860397338867 and parameters: {'n_layers': 1, 'input_chunk_length': 28, 'hidden_dim': 194, 'learning_rate': 2.9379366993156356e-07, 'batch_size': 64, 'training_length': 258}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 159 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:36,296] Trial 99 finished with value: 21.98451805114746 and parameters: {'n_layers': 1, 'input_chunk_length': 31, 'hidden_dim': 197, 'learning_rate': 1.077217110658312e-06, 'batch_size': 64, 'training_length': 303}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 160 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:37,176] Trial 100 finished with value: 24.960227966308594 and parameters: {'n_layers': 1, 'input_chunk_length': 23, 'hidden_dim': 188, 'learning_rate': 1.0069090816628454e-07, 'batch_size': 64, 'training_length': 273}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 161 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:37,930] Trial 101 finished with value: 16.244674682617188 and parameters: {'n_layers': 1, 'input_chunk_length': 26, 'hidden_dim': 200, 'learning_rate': 7.104710914063505e-07, 'batch_size': 64, 'training_length': 334}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 162 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:38,698] Trial 102 finished with value: 16.24355125427246 and parameters: {'n_layers': 1, 'input_chunk_length': 21, 'hidden_dim': 200, 'learning_rate': 4.016185860488131e-07, 'batch_size': 64, 'training_length': 337}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 163 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:39,715] Trial 103 finished with value: 18.592973709106445 and parameters: {'n_layers': 1, 'input_chunk_length': 21, 'hidden_dim': 192, 'learning_rate': 4.2246096474135e-07, 'batch_size': 64, 'training_length': 387}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 164 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:40,933] Trial 104 finished with value: 16.42727279663086 and parameters: {'n_layers': 1, 'input_chunk_length': 34, 'hidden_dim': 196, 'learning_rate': 5.083464714249598e-07, 'batch_size': 16, 'training_length': 321}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 165 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:41,906] Trial 105 finished with value: 22.54031753540039 and parameters: {'n_layers': 1, 'input_chunk_length': 19, 'hidden_dim': 182, 'learning_rate': 4.0846459790991063e-07, 'batch_size': 64, 'training_length': 367}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 166 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:42,648] Trial 106 finished with value: 21.986278533935547 and parameters: {'n_layers': 1, 'input_chunk_length': 22, 'hidden_dim': 197, 'learning_rate': 1.8504583282564844e-07, 'batch_size': 64, 'training_length': 294}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 167 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:43,572] Trial 107 finished with value: 24.967571258544922 and parameters: {'n_layers': 1, 'input_chunk_length': 32, 'hidden_dim': 188, 'learning_rate': 1.1654579838629496e-06, 'batch_size': 64, 'training_length': 312}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 168 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:44,356] Trial 108 finished with value: 29.273204803466797 and parameters: {'n_layers': 1, 'input_chunk_length': 28, 'hidden_dim': 193, 'learning_rate': 2.953203868211237e-07, 'batch_size': 64, 'training_length': 353}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 169 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:45,111] Trial 109 finished with value: 16.247526168823242 and parameters: {'n_layers': 1, 'input_chunk_length': 16, 'hidden_dim': 200, 'learning_rate': 9.155691898746414e-07, 'batch_size': 64, 'training_length': 336}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 170 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:45,847] Trial 110 finished with value: 21.98637580871582 and parameters: {'n_layers': 1, 'input_chunk_length': 24, 'hidden_dim': 197, 'learning_rate': 2.737334537050069e-07, 'batch_size': 64, 'training_length': 286}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 171 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:46,394] Trial 111 finished with value: 17.769472122192383 and parameters: {'n_layers': 1, 'input_chunk_length': 27, 'hidden_dim': 50, 'learning_rate': 8.045565630980734e-07, 'batch_size': 64, 'training_length': 333}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 172 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:47,132] Trial 112 finished with value: 16.244415283203125 and parameters: {'n_layers': 1, 'input_chunk_length': 30, 'hidden_dim': 200, 'learning_rate': 6.324697642168287e-07, 'batch_size': 64, 'training_length': 305}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 173 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:47,875] Trial 113 finished with value: 20.81239891052246 and parameters: {'n_layers': 1, 'input_chunk_length': 31, 'hidden_dim': 194, 'learning_rate': 3.749255788642429e-07, 'batch_size': 64, 'training_length': 303}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 174 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:48,762] Trial 114 finished with value: 17.535030364990234 and parameters: {'n_layers': 1, 'input_chunk_length': 29, 'hidden_dim': 185, 'learning_rate': 6.040911007234405e-07, 'batch_size': 64, 'training_length': 276}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 175 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:49,507] Trial 115 finished with value: 16.24570083618164 and parameters: {'n_layers': 1, 'input_chunk_length': 23, 'hidden_dim': 200, 'learning_rate': 1.192215785776925e-06, 'batch_size': 64, 'training_length': 319}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 176 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:50,390] Trial 116 finished with value: 17.828474044799805 and parameters: {'n_layers': 1, 'input_chunk_length': 19, 'hidden_dim': 190, 'learning_rate': 1.8388699596124206e-06, 'batch_size': 64, 'training_length': 266}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 177 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:51,592] Trial 117 finished with value: 29.248973846435547 and parameters: {'n_layers': 1, 'input_chunk_length': 25, 'hidden_dim': 193, 'learning_rate': 1.3008581799500464e-07, 'batch_size': 16, 'training_length': 310}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 178 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:52,331] Trial 118 finished with value: 16.438737869262695 and parameters: {'n_layers': 1, 'input_chunk_length': 33, 'hidden_dim': 196, 'learning_rate': 5.069991260213468e-07, 'batch_size': 64, 'training_length': 289}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 179 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:53,048] Trial 119 finished with value: 18.836458206176758 and parameters: {'n_layers': 1, 'input_chunk_length': 39, 'hidden_dim': 198, 'learning_rate': 6.142192533913805e-07, 'batch_size': 64, 'training_length': 251}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 180 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:54,000] Trial 120 finished with value: 17.82322120666504 and parameters: {'n_layers': 1, 'input_chunk_length': 30, 'hidden_dim': 190, 'learning_rate': 1.8718588355188185e-07, 'batch_size': 64, 'training_length': 328}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 181 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:54,760] Trial 121 finished with value: 16.245006561279297 and parameters: {'n_layers': 1, 'input_chunk_length': 26, 'hidden_dim': 200, 'learning_rate': 8.330408680995076e-07, 'batch_size': 64, 'training_length': 339}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 182 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:55,532] Trial 122 finished with value: 16.244338989257812 and parameters: {'n_layers': 1, 'input_chunk_length': 27, 'hidden_dim': 200, 'learning_rate': 6.606961532792585e-07, 'batch_size': 64, 'training_length': 354}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 183 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:56,303] Trial 123 finished with value: 20.80487823486328 and parameters: {'n_layers': 1, 'input_chunk_length': 21, 'hidden_dim': 194, 'learning_rate': 3.941180697622784e-07, 'batch_size': 64, 'training_length': 352}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 184 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:57,110] Trial 124 finished with value: 21.98634147644043 and parameters: {'n_layers': 1, 'input_chunk_length': 24, 'hidden_dim': 197, 'learning_rate': 5.210898290005111e-07, 'batch_size': 64, 'training_length': 360}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 185 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:58,046] Trial 125 finished with value: 18.09554100036621 and parameters: {'n_layers': 1, 'input_chunk_length': 36, 'hidden_dim': 187, 'learning_rate': 1.3913263736461233e-06, 'batch_size': 64, 'training_length': 300}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 186 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:58,928] Trial 126 finished with value: 18.59889793395996 and parameters: {'n_layers': 1, 'input_chunk_length': 18, 'hidden_dim': 192, 'learning_rate': 6.758590125968759e-07, 'batch_size': 64, 'training_length': 234}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 187 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:27:59,679] Trial 127 finished with value: 16.24356460571289 and parameters: {'n_layers': 1, 'input_chunk_length': 29, 'hidden_dim': 200, 'learning_rate': 3.383454490666521e-07, 'batch_size': 64, 'training_length': 319}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 188 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:00,319] Trial 128 finished with value: 18.702926635742188 and parameters: {'n_layers': 1, 'input_chunk_length': 87, 'hidden_dim': 195, 'learning_rate': 2.561910022285222e-07, 'batch_size': 64, 'training_length': 102}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 189 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:01,406] Trial 129 finished with value: 20.9317626953125 and parameters: {'n_layers': 2, 'dropout': 0.16614709803672478, 'input_chunk_length': 29, 'hidden_dim': 197, 'learning_rate': 3.010038962913473e-07, 'batch_size': 64, 'training_length': 324}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 190 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:02,405] Trial 130 finished with value: 21.162534713745117 and parameters: {'n_layers': 1, 'input_chunk_length': 27, 'hidden_dim': 183, 'learning_rate': 3.5173392751510106e-07, 'batch_size': 64, 'training_length': 395}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 191 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:03,154] Trial 131 finished with value: 19.474716186523438 and parameters: {'n_layers': 1, 'input_chunk_length': 23, 'hidden_dim': 199, 'learning_rate': 4.906253981467493e-07, 'batch_size': 64, 'training_length': 312}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 192 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:03,943] Trial 132 finished with value: 16.244226455688477 and parameters: {'n_layers': 1, 'input_chunk_length': 31, 'hidden_dim': 200, 'learning_rate': 5.914727643353939e-07, 'batch_size': 64, 'training_length': 375}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 193 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:04,911] Trial 133 finished with value: 19.740671157836914 and parameters: {'n_layers': 1, 'input_chunk_length': 32, 'hidden_dim': 191, 'learning_rate': 4.34400853964311e-07, 'batch_size': 64, 'training_length': 347}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 194 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:05,691] Trial 134 finished with value: 20.810043334960938 and parameters: {'n_layers': 1, 'input_chunk_length': 34, 'hidden_dim': 194, 'learning_rate': 6.151059954692445e-07, 'batch_size': 64, 'training_length': 365}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 195 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:06,467] Trial 135 finished with value: 16.24337387084961 and parameters: {'n_layers': 1, 'input_chunk_length': 30, 'hidden_dim': 200, 'learning_rate': 2.371112845758271e-07, 'batch_size': 64, 'training_length': 373}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 196 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:07,251] Trial 136 finished with value: 21.98617172241211 and parameters: {'n_layers': 1, 'input_chunk_length': 30, 'hidden_dim': 197, 'learning_rate': 2.2367982547846784e-07, 'batch_size': 64, 'training_length': 366}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 197 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:08,250] Trial 137 finished with value: 27.144947052001953 and parameters: {'n_layers': 1, 'input_chunk_length': 43, 'hidden_dim': 189, 'learning_rate': 1.4462516454902664e-07, 'batch_size': 64, 'training_length': 383}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 198 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:09,027] Trial 138 finished with value: 16.243236541748047 and parameters: {'n_layers': 1, 'input_chunk_length': 37, 'hidden_dim': 200, 'learning_rate': 1.9741712453179852e-07, 'batch_size': 64, 'training_length': 375}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 199 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:10,347] Trial 139 finished with value: 29.250560760498047 and parameters: {'n_layers': 1, 'input_chunk_length': 36, 'hidden_dim': 193, 'learning_rate': 1.9048449305599866e-07, 'batch_size': 16, 'training_length': 392}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 200 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:11,343] Trial 140 finished with value: 24.83673667907715 and parameters: {'n_layers': 1, 'input_chunk_length': 33, 'hidden_dim': 179, 'learning_rate': 2.383861361417035e-07, 'batch_size': 64, 'training_length': 382}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 201 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:12,128] Trial 141 finished with value: 22.00259780883789 and parameters: {'n_layers': 1, 'input_chunk_length': 28, 'hidden_dim': 197, 'learning_rate': 3.2070918805574656e-07, 'batch_size': 64, 'training_length': 377}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 202 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:12,921] Trial 142 finished with value: 16.243736267089844 and parameters: {'n_layers': 1, 'input_chunk_length': 30, 'hidden_dim': 200, 'learning_rate': 4.027088793666003e-07, 'batch_size': 64, 'training_length': 413}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 203 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:13,700] Trial 143 finished with value: 18.68195343017578 and parameters: {'n_layers': 1, 'input_chunk_length': 38, 'hidden_dim': 195, 'learning_rate': 3.8331903195363416e-07, 'batch_size': 64, 'training_length': 356}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 204 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:14,507] Trial 144 finished with value: 16.24347686767578 and parameters: {'n_layers': 1, 'input_chunk_length': 27, 'hidden_dim': 200, 'learning_rate': 2.7503034469086074e-07, 'batch_size': 64, 'training_length': 421}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 205 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:15,055] Trial 145 finished with value: 32.41324996948242 and parameters: {'n_layers': 1, 'input_chunk_length': 31, 'hidden_dim': 59, 'learning_rate': 2.7127940510474985e-07, 'batch_size': 64, 'training_length': 441}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 206 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:15,869] Trial 146 finished with value: 21.98097801208496 and parameters: {'n_layers': 1, 'input_chunk_length': 35, 'hidden_dim': 197, 'learning_rate': 1.6539123217375798e-07, 'batch_size': 64, 'training_length': 423}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 207 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:16,665] Trial 147 finished with value: 29.245004653930664 and parameters: {'n_layers': 1, 'input_chunk_length': 21, 'hidden_dim': 193, 'learning_rate': 2.0130259238484128e-07, 'batch_size': 64, 'training_length': 402}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 208 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:17,746] Trial 148 finished with value: 17.82393455505371 and parameters: {'n_layers': 1, 'input_chunk_length': 27, 'hidden_dim': 190, 'learning_rate': 3.3828922643685655e-07, 'batch_size': 64, 'training_length': 475}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 209 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:18,781] Trial 149 finished with value: 31.704023361206055 and parameters: {'n_layers': 1, 'input_chunk_length': 32, 'hidden_dim': 186, 'learning_rate': 1.1479327163935663e-07, 'batch_size': 64, 'training_length': 425}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 210 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:19,578] Trial 150 finished with value: 16.24374771118164 and parameters: {'n_layers': 1, 'input_chunk_length': 29, 'hidden_dim': 200, 'learning_rate': 4.406451971065724e-07, 'batch_size': 64, 'training_length': 413}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 211 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:20,355] Trial 151 finished with value: 16.268388748168945 and parameters: {'n_layers': 1, 'input_chunk_length': 28, 'hidden_dim': 200, 'learning_rate': 4.194804679810317e-07, 'batch_size': 64, 'training_length': 375}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 212 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:21,161] Trial 152 finished with value: 16.422204971313477 and parameters: {'n_layers': 1, 'input_chunk_length': 29, 'hidden_dim': 196, 'learning_rate': 2.598564395605342e-07, 'batch_size': 64, 'training_length': 416}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 213 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:21,956] Trial 153 finished with value: 18.833499908447266 and parameters: {'n_layers': 1, 'input_chunk_length': 34, 'hidden_dim': 198, 'learning_rate': 4.4904444593777144e-07, 'batch_size': 64, 'training_length': 400}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 214 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:22,761] Trial 154 finished with value: 16.243356704711914 and parameters: {'n_layers': 1, 'input_chunk_length': 25, 'hidden_dim': 200, 'learning_rate': 2.266531840606848e-07, 'batch_size': 64, 'training_length': 434}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 215 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:23,576] Trial 155 finished with value: 20.810585021972656 and parameters: {'n_layers': 1, 'input_chunk_length': 31, 'hidden_dim': 194, 'learning_rate': 2.3613499963948284e-07, 'batch_size': 64, 'training_length': 436}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 216 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:24,606] Trial 156 finished with value: 19.74127769470215 and parameters: {'n_layers': 1, 'input_chunk_length': 23, 'hidden_dim': 191, 'learning_rate': 3.027682363854064e-07, 'batch_size': 64, 'training_length': 411}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 217 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:25,421] Trial 157 finished with value: 16.243181228637695 and parameters: {'n_layers': 1, 'input_chunk_length': 26, 'hidden_dim': 200, 'learning_rate': 1.6471012701380903e-07, 'batch_size': 64, 'training_length': 455}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 218 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:26,240] Trial 158 finished with value: 21.9864501953125 and parameters: {'n_layers': 1, 'input_chunk_length': 25, 'hidden_dim': 197, 'learning_rate': 1.5513992510682742e-07, 'batch_size': 64, 'training_length': 433}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 219 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:27,060] Trial 159 finished with value: 20.80974578857422 and parameters: {'n_layers': 1, 'input_chunk_length': 22, 'hidden_dim': 194, 'learning_rate': 1.9355977358154468e-07, 'batch_size': 64, 'training_length': 453}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 220 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:27,884] Trial 160 finished with value: 16.242944717407227 and parameters: {'n_layers': 1, 'input_chunk_length': 29, 'hidden_dim': 200, 'learning_rate': 1.1729224642879835e-07, 'batch_size': 64, 'training_length': 468}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 221 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:28,723] Trial 161 finished with value: 16.243162155151367 and parameters: {'n_layers': 1, 'input_chunk_length': 30, 'hidden_dim': 200, 'learning_rate': 1.3916696181656423e-07, 'batch_size': 64, 'training_length': 498}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 222 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:29,549] Trial 162 finished with value: 16.422019958496094 and parameters: {'n_layers': 1, 'input_chunk_length': 29, 'hidden_dim': 196, 'learning_rate': 1.1764838081372315e-07, 'batch_size': 64, 'training_length': 459}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 223 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:30,386] Trial 163 finished with value: 16.243240356445312 and parameters: {'n_layers': 1, 'input_chunk_length': 33, 'hidden_dim': 200, 'learning_rate': 1.259386754806329e-07, 'batch_size': 64, 'training_length': 484}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 224 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:31,217] Trial 164 finished with value: 21.98638916015625 and parameters: {'n_layers': 1, 'input_chunk_length': 33, 'hidden_dim': 197, 'learning_rate': 1.5306196188103954e-07, 'batch_size': 64, 'training_length': 499}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 225 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:32,057] Trial 165 finished with value: 29.24701690673828 and parameters: {'n_layers': 1, 'input_chunk_length': 37, 'hidden_dim': 193, 'learning_rate': 1.3378709309608466e-07, 'batch_size': 64, 'training_length': 475}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 226 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:32,885] Trial 166 finished with value: 16.24322509765625 and parameters: {'n_layers': 1, 'input_chunk_length': 27, 'hidden_dim': 200, 'learning_rate': 1.736726935623814e-07, 'batch_size': 64, 'training_length': 470}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 227 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:33,982] Trial 167 finished with value: 17.821895599365234 and parameters: {'n_layers': 1, 'input_chunk_length': 29, 'hidden_dim': 190, 'learning_rate': 1.1582427814627517e-07, 'batch_size': 64, 'training_length': 471}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 228 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:35,433] Trial 168 finished with value: 21.980867385864258 and parameters: {'n_layers': 1, 'input_chunk_length': 35, 'hidden_dim': 197, 'learning_rate': 1.0326023970863973e-07, 'batch_size': 16, 'training_length': 490}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 229 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:36,267] Trial 169 finished with value: 20.80869483947754 and parameters: {'n_layers': 1, 'input_chunk_length': 50, 'hidden_dim': 194, 'learning_rate': 1.6889978086794408e-07, 'batch_size': 64, 'training_length': 468}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 230 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:37,101] Trial 170 finished with value: 16.24329948425293 and parameters: {'n_layers': 1, 'input_chunk_length': 32, 'hidden_dim': 200, 'learning_rate': 2.1457195121062692e-07, 'batch_size': 64, 'training_length': 485}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 231 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:37,935] Trial 171 finished with value: 16.243301391601562 and parameters: {'n_layers': 1, 'input_chunk_length': 32, 'hidden_dim': 200, 'learning_rate': 2.1482747544568343e-07, 'batch_size': 64, 'training_length': 485}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 232 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:38,769] Trial 172 finished with value: 16.24329948425293 and parameters: {'n_layers': 1, 'input_chunk_length': 32, 'hidden_dim': 200, 'learning_rate': 2.1160132201328462e-07, 'batch_size': 64, 'training_length': 489}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 233 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:39,615] Trial 173 finished with value: 21.98647117614746 and parameters: {'n_layers': 1, 'input_chunk_length': 33, 'hidden_dim': 197, 'learning_rate': 2.0132013059581576e-07, 'batch_size': 64, 'training_length': 483}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 234 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:40,458] Trial 174 finished with value: 18.67481231689453 and parameters: {'n_layers': 1, 'input_chunk_length': 32, 'hidden_dim': 195, 'learning_rate': 1.3542071086537474e-07, 'batch_size': 64, 'training_length': 486}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 235 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:41,010] Trial 175 finished with value: 25.226966857910156 and parameters: {'n_layers': 1, 'input_chunk_length': 37, 'hidden_dim': 88, 'learning_rate': 2.2129618315914894e-07, 'batch_size': 64, 'training_length': 499}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 236 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:42,106] Trial 176 finished with value: 18.59716796875 and parameters: {'n_layers': 1, 'input_chunk_length': 27, 'hidden_dim': 192, 'learning_rate': 1.699638448741565e-07, 'batch_size': 64, 'training_length': 466}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 237 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:42,944] Trial 177 finished with value: 16.309123992919922 and parameters: {'n_layers': 1, 'input_chunk_length': 40, 'hidden_dim': 200, 'learning_rate': 1.3372570116486317e-07, 'batch_size': 64, 'training_length': 446}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 238 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:43,814] Trial 178 finished with value: 21.981138229370117 and parameters: {'n_layers': 1, 'input_chunk_length': 35, 'hidden_dim': 197, 'learning_rate': 2.2128362675568775e-07, 'batch_size': 64, 'training_length': 479}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 239 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:44,666] Trial 179 finished with value: 18.682191848754883 and parameters: {'n_layers': 1, 'input_chunk_length': 31, 'hidden_dim': 195, 'learning_rate': 1.7584679691731042e-07, 'batch_size': 64, 'training_length': 492}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 240 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:46,428] Trial 180 finished with value: 24.391016006469727 and parameters: {'n_layers': 2, 'dropout': 0.16925558194110774, 'input_chunk_length': 26, 'hidden_dim': 188, 'learning_rate': 2.6388528404324215e-07, 'batch_size': 64, 'training_length': 459}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 241 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:47,243] Trial 181 finished with value: 16.243236541748047 and parameters: {'n_layers': 1, 'input_chunk_length': 30, 'hidden_dim': 200, 'learning_rate': 2.1045995897821233e-07, 'batch_size': 64, 'training_length': 446}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 242 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:48,058] Trial 182 finished with value: 16.243379592895508 and parameters: {'n_layers': 1, 'input_chunk_length': 33, 'hidden_dim': 200, 'learning_rate': 2.1257119196248048e-07, 'batch_size': 64, 'training_length': 448}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 243 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:48,877] Trial 183 finished with value: 16.243303298950195 and parameters: {'n_layers': 1, 'input_chunk_length': 34, 'hidden_dim': 200, 'learning_rate': 2.1339481732085482e-07, 'batch_size': 64, 'training_length': 450}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 244 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:49,698] Trial 184 finished with value: 21.986602783203125 and parameters: {'n_layers': 1, 'input_chunk_length': 33, 'hidden_dim': 197, 'learning_rate': 2.0245420788879686e-07, 'batch_size': 64, 'training_length': 448}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 245 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:50,535] Trial 185 finished with value: 29.247602462768555 and parameters: {'n_layers': 1, 'input_chunk_length': 35, 'hidden_dim': 193, 'learning_rate': 1.5004994206307904e-07, 'batch_size': 64, 'training_length': 481}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 246 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:51,367] Trial 186 finished with value: 21.986595153808594 and parameters: {'n_layers': 1, 'input_chunk_length': 43, 'hidden_dim': 197, 'learning_rate': 1.2380756821198353e-07, 'batch_size': 64, 'training_length': 464}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 247 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:52,191] Trial 187 finished with value: 16.243040084838867 and parameters: {'n_layers': 1, 'input_chunk_length': 38, 'hidden_dim': 200, 'learning_rate': 1.0128762521197033e-07, 'batch_size': 64, 'training_length': 453}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 248 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:53,259] Trial 188 finished with value: 19.742998123168945 and parameters: {'n_layers': 1, 'input_chunk_length': 38, 'hidden_dim': 191, 'learning_rate': 1.1124868543502205e-07, 'batch_size': 64, 'training_length': 443}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 249 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:53,820] Trial 189 finished with value: 21.61384391784668 and parameters: {'n_layers': 1, 'input_chunk_length': 36, 'hidden_dim': 71, 'learning_rate': 1.023502486539818e-07, 'batch_size': 64, 'training_length': 456}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 250 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:54,658] Trial 190 finished with value: 21.979949951171875 and parameters: {'n_layers': 1, 'input_chunk_length': 41, 'hidden_dim': 197, 'learning_rate': 1.778425106108769e-07, 'batch_size': 64, 'training_length': 471}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 251 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:55,491] Trial 191 finished with value: 16.243507385253906 and parameters: {'n_layers': 1, 'input_chunk_length': 33, 'hidden_dim': 200, 'learning_rate': 2.3067067162583766e-07, 'batch_size': 64, 'training_length': 487}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 252 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:56,326] Trial 192 finished with value: 16.24339485168457 and parameters: {'n_layers': 1, 'input_chunk_length': 34, 'hidden_dim': 200, 'learning_rate': 2.23089089276542e-07, 'batch_size': 64, 'training_length': 491}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 253 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:57,167] Trial 193 finished with value: 18.67497444152832 and parameters: {'n_layers': 1, 'input_chunk_length': 34, 'hidden_dim': 195, 'learning_rate': 1.3736152121525134e-07, 'batch_size': 64, 'training_length': 498}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 254 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:57,993] Trial 194 finished with value: 18.83367156982422 and parameters: {'n_layers': 1, 'input_chunk_length': 39, 'hidden_dim': 198, 'learning_rate': 1.6106446748027522e-07, 'batch_size': 64, 'training_length': 450}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 255 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:58,806] Trial 195 finished with value: 16.243213653564453 and parameters: {'n_layers': 1, 'input_chunk_length': 32, 'hidden_dim': 200, 'learning_rate': 2.0807573147276918e-07, 'batch_size': 64, 'training_length': 431}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 256 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:28:59,638] Trial 196 finished with value: 20.8106689453125 and parameters: {'n_layers': 1, 'input_chunk_length': 31, 'hidden_dim': 194, 'learning_rate': 2.013630329922751e-07, 'batch_size': 64, 'training_length': 479}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 257 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:00,469] Trial 197 finished with value: 21.986927032470703 and parameters: {'n_layers': 1, 'input_chunk_length': 37, 'hidden_dim': 197, 'learning_rate': 1.4072004327452677e-07, 'batch_size': 64, 'training_length': 463}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 258 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:01,308] Trial 198 finished with value: 16.243240356445312 and parameters: {'n_layers': 1, 'input_chunk_length': 34, 'hidden_dim': 200, 'learning_rate': 1.8519676225882288e-07, 'batch_size': 64, 'training_length': 487}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 259 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:02,419] Trial 199 finished with value: 18.59137535095215 and parameters: {'n_layers': 1, 'input_chunk_length': 35, 'hidden_dim': 192, 'learning_rate': 1.7623658490483648e-07, 'batch_size': 64, 'training_length': 489}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 260 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:03,789] Trial 200 finished with value: 16.2437744140625 and parameters: {'n_layers': 1, 'input_chunk_length': 32, 'hidden_dim': 200, 'learning_rate': 2.1711857094030655e-07, 'batch_size': 16, 'training_length': 432}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 261 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:04,629] Trial 201 finished with value: 21.98660659790039 and parameters: {'n_layers': 1, 'input_chunk_length': 34, 'hidden_dim': 197, 'learning_rate': 2.490785823304803e-07, 'batch_size': 64, 'training_length': 473}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 262 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:05,454] Trial 202 finished with value: 16.24309730529785 and parameters: {'n_layers': 1, 'input_chunk_length': 32, 'hidden_dim': 200, 'learning_rate': 1.7833830618486715e-07, 'batch_size': 64, 'training_length': 500}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 263 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:06,285] Trial 203 finished with value: 18.67465591430664 and parameters: {'n_layers': 1, 'input_chunk_length': 32, 'hidden_dim': 195, 'learning_rate': 1.4995082395659325e-07, 'batch_size': 64, 'training_length': 500}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 264 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:07,126] Trial 204 finished with value: 21.986644744873047 and parameters: {'n_layers': 1, 'input_chunk_length': 37, 'hidden_dim': 197, 'learning_rate': 1.8141988891330865e-07, 'batch_size': 64, 'training_length': 485}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 265 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:07,947] Trial 205 finished with value: 16.24309539794922 and parameters: {'n_layers': 1, 'input_chunk_length': 34, 'hidden_dim': 200, 'learning_rate': 1.2777718233571922e-07, 'batch_size': 64, 'training_length': 455}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 266 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:08,761] Trial 206 finished with value: 16.243022918701172 and parameters: {'n_layers': 1, 'input_chunk_length': 31, 'hidden_dim': 200, 'learning_rate': 1.0133483493717875e-07, 'batch_size': 64, 'training_length': 439}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 267 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:09,580] Trial 207 finished with value: 18.682083129882812 and parameters: {'n_layers': 1, 'input_chunk_length': 31, 'hidden_dim': 195, 'learning_rate': 1.2113568265741366e-07, 'batch_size': 64, 'training_length': 439}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 268 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:10,411] Trial 208 finished with value: 21.98639678955078 and parameters: {'n_layers': 1, 'input_chunk_length': 30, 'hidden_dim': 197, 'learning_rate': 1.0389668783608769e-07, 'batch_size': 64, 'training_length': 463}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 269 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:11,246] Trial 209 finished with value: 29.247787475585938 and parameters: {'n_layers': 1, 'input_chunk_length': 36, 'hidden_dim': 193, 'learning_rate': 1.2374438759099135e-07, 'batch_size': 64, 'training_length': 454}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 270 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:12,090] Trial 210 finished with value: 16.243141174316406 and parameters: {'n_layers': 1, 'input_chunk_length': 30, 'hidden_dim': 200, 'learning_rate': 1.4644573089738176e-07, 'batch_size': 64, 'training_length': 476}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 271 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:12,922] Trial 211 finished with value: 16.243064880371094 and parameters: {'n_layers': 1, 'input_chunk_length': 29, 'hidden_dim': 200, 'learning_rate': 1.47299603153226e-07, 'batch_size': 64, 'training_length': 476}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 272 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:13,756] Trial 212 finished with value: 18.8673152923584 and parameters: {'n_layers': 1, 'input_chunk_length': 28, 'hidden_dim': 198, 'learning_rate': 1.0139156526485126e-07, 'batch_size': 64, 'training_length': 477}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 273 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:14,588] Trial 213 finished with value: 16.24309730529785 and parameters: {'n_layers': 1, 'input_chunk_length': 32, 'hidden_dim': 200, 'learning_rate': 1.506112734970271e-07, 'batch_size': 64, 'training_length': 469}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 274 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:15,426] Trial 214 finished with value: 18.67471694946289 and parameters: {'n_layers': 1, 'input_chunk_length': 32, 'hidden_dim': 195, 'learning_rate': 1.3973068203153997e-07, 'batch_size': 64, 'training_length': 469}. Best is trial 85 with value: 16.2369441986084.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 275 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:16,261] Trial 215 finished with value: 16.23515510559082 and parameters: {'n_layers': 1, 'input_chunk_length': 35, 'hidden_dim': 200, 'learning_rate': 1.5350204404165898e-07, 'batch_size': 64, 'training_length': 481}. Best is trial 215 with value: 16.23515510559082.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 276 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:17,102] Trial 216 finished with value: 21.98089027404785 and parameters: {'n_layers': 1, 'input_chunk_length': 35, 'hidden_dim': 197, 'learning_rate': 1.2897992481914356e-07, 'batch_size': 64, 'training_length': 481}. Best is trial 215 with value: 16.23515510559082.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 277 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:17,927] Trial 217 finished with value: 16.243276596069336 and parameters: {'n_layers': 1, 'input_chunk_length': 33, 'hidden_dim': 200, 'learning_rate': 1.5579049384553815e-07, 'batch_size': 64, 'training_length': 467}. Best is trial 215 with value: 16.23515510559082.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 278 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:18,763] Trial 218 finished with value: 20.80908203125 and parameters: {'n_layers': 1, 'input_chunk_length': 39, 'hidden_dim': 194, 'learning_rate': 1.5658609677754485e-07, 'batch_size': 64, 'training_length': 470}. Best is trial 215 with value: 16.23515510559082.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 279 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:19,608] Trial 219 finished with value: 21.98691177368164 and parameters: {'n_layers': 1, 'input_chunk_length': 32, 'hidden_dim': 197, 'learning_rate': 1.2697102249035278e-07, 'batch_size': 64, 'training_length': 488}. Best is trial 215 with value: 16.23515510559082.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 280 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:20,701] Trial 220 finished with value: 19.742761611938477 and parameters: {'n_layers': 1, 'input_chunk_length': 30, 'hidden_dim': 191, 'learning_rate': 1.721663235175264e-07, 'batch_size': 64, 'training_length': 477}. Best is trial 215 with value: 16.23515510559082.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 281 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:21,522] Trial 221 finished with value: 16.243131637573242 and parameters: {'n_layers': 1, 'input_chunk_length': 34, 'hidden_dim': 200, 'learning_rate': 1.5185887301799873e-07, 'batch_size': 64, 'training_length': 458}. Best is trial 215 with value: 16.23515510559082.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 282 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:22,345] Trial 222 finished with value: 16.24321746826172 and parameters: {'n_layers': 1, 'input_chunk_length': 36, 'hidden_dim': 200, 'learning_rate': 1.571833908641941e-07, 'batch_size': 64, 'training_length': 464}. Best is trial 215 with value: 16.23515510559082.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 283 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:23,178] Trial 223 finished with value: 21.986942291259766 and parameters: {'n_layers': 1, 'input_chunk_length': 37, 'hidden_dim': 197, 'learning_rate': 1.003246128379663e-07, 'batch_size': 64, 'training_length': 463}. Best is trial 215 with value: 16.23515510559082.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 284 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:24,002] Trial 224 finished with value: 16.235090255737305 and parameters: {'n_layers': 1, 'input_chunk_length': 35, 'hidden_dim': 200, 'learning_rate': 1.4910650029470637e-07, 'batch_size': 64, 'training_length': 458}. Best is trial 224 with value: 16.235090255737305.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 285 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:24,840] Trial 225 finished with value: 18.681869506835938 and parameters: {'n_layers': 1, 'input_chunk_length': 36, 'hidden_dim': 195, 'learning_rate': 1.4909446012351906e-07, 'batch_size': 64, 'training_length': 458}. Best is trial 224 with value: 16.235090255737305.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 286 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:25,671] Trial 226 finished with value: 21.98640251159668 and parameters: {'n_layers': 1, 'input_chunk_length': 38, 'hidden_dim': 197, 'learning_rate': 1.2295626500293652e-07, 'batch_size': 64, 'training_length': 468}. Best is trial 224 with value: 16.235090255737305.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 287 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:26,491] Trial 227 finished with value: 16.24310874938965 and parameters: {'n_layers': 1, 'input_chunk_length': 34, 'hidden_dim': 200, 'learning_rate': 1.5219151147712097e-07, 'batch_size': 64, 'training_length': 456}. Best is trial 224 with value: 16.235090255737305.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 288 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:27,315] Trial 228 finished with value: 20.804916381835938 and parameters: {'n_layers': 1, 'input_chunk_length': 35, 'hidden_dim': 194, 'learning_rate': 1.502687338735357e-07, 'batch_size': 64, 'training_length': 456}. Best is trial 224 with value: 16.235090255737305.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 289 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:28,155] Trial 229 finished with value: 21.98003387451172 and parameters: {'n_layers': 1, 'input_chunk_length': 41, 'hidden_dim': 197, 'learning_rate': 1.2555125602347352e-07, 'batch_size': 64, 'training_length': 459}. Best is trial 224 with value: 16.235090255737305.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 290 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:28,983] Trial 230 finished with value: 16.235111236572266 and parameters: {'n_layers': 1, 'input_chunk_length': 35, 'hidden_dim': 200, 'learning_rate': 1.5846294059013611e-07, 'batch_size': 64, 'training_length': 440}. Best is trial 224 with value: 16.235090255737305.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 291 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:29,813] Trial 231 finished with value: 16.235109329223633 and parameters: {'n_layers': 1, 'input_chunk_length': 35, 'hidden_dim': 200, 'learning_rate': 1.622728545396592e-07, 'batch_size': 64, 'training_length': 444}. Best is trial 224 with value: 16.235090255737305.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 292 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:30,633] Trial 232 finished with value: 18.83367156982422 and parameters: {'n_layers': 1, 'input_chunk_length': 39, 'hidden_dim': 198, 'learning_rate': 1.7022286060809964e-07, 'batch_size': 64, 'training_length': 444}. Best is trial 224 with value: 16.235090255737305.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 293 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:31,448] Trial 233 finished with value: 16.235029220581055 and parameters: {'n_layers': 1, 'input_chunk_length': 35, 'hidden_dim': 200, 'learning_rate': 1.2090587658234099e-07, 'batch_size': 64, 'training_length': 438}. Best is trial 233 with value: 16.235029220581055.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 294 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:32,268] Trial 234 finished with value: 21.986391067504883 and parameters: {'n_layers': 1, 'input_chunk_length': 36, 'hidden_dim': 197, 'learning_rate': 1.1664516815827158e-07, 'batch_size': 64, 'training_length': 433}. Best is trial 233 with value: 16.235029220581055.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 295 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:33,091] Trial 235 finished with value: 20.804149627685547 and parameters: {'n_layers': 1, 'input_chunk_length': 37, 'hidden_dim': 194, 'learning_rate': 1.3509756654525985e-07, 'batch_size': 64, 'training_length': 443}. Best is trial 233 with value: 16.235029220581055.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 296 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:33,920] Trial 236 finished with value: 16.2349796295166 and parameters: {'n_layers': 1, 'input_chunk_length': 35, 'hidden_dim': 200, 'learning_rate': 1.0379298541976888e-07, 'batch_size': 64, 'training_length': 450}. Best is trial 236 with value: 16.2349796295166.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 297 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:34,753] Trial 237 finished with value: 21.981191635131836 and parameters: {'n_layers': 1, 'input_chunk_length': 35, 'hidden_dim': 197, 'learning_rate': 1.0158860547553623e-07, 'batch_size': 64, 'training_length': 450}. Best is trial 236 with value: 16.2349796295166.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 298 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:35,568] Trial 238 finished with value: 16.24318504333496 and parameters: {'n_layers': 1, 'input_chunk_length': 38, 'hidden_dim': 200, 'learning_rate': 1.4341096835833875e-07, 'batch_size': 64, 'training_length': 427}. Best is trial 236 with value: 16.2349796295166.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 299 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:36,388] Trial 239 finished with value: 29.24775505065918 and parameters: {'n_layers': 1, 'input_chunk_length': 39, 'hidden_dim': 193, 'learning_rate': 1.5039481085586948e-07, 'batch_size': 64, 'training_length': 430}. Best is trial 236 with value: 16.2349796295166.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 300 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:37,209] Trial 240 finished with value: 21.986852645874023 and parameters: {'n_layers': 1, 'input_chunk_length': 43, 'hidden_dim': 197, 'learning_rate': 1.156940833179553e-07, 'batch_size': 64, 'training_length': 439}. Best is trial 236 with value: 16.2349796295166.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 301 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:38,023] Trial 241 finished with value: 16.24308967590332 and parameters: {'n_layers': 1, 'input_chunk_length': 37, 'hidden_dim': 200, 'learning_rate': 1.4529527992902562e-07, 'batch_size': 64, 'training_length': 424}. Best is trial 236 with value: 16.2349796295166.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 302 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:38,837] Trial 242 finished with value: 16.2431697845459 and parameters: {'n_layers': 1, 'input_chunk_length': 38, 'hidden_dim': 200, 'learning_rate': 1.4189513777012326e-07, 'batch_size': 64, 'training_length': 425}. Best is trial 236 with value: 16.2349796295166.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 303 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:39,652] Trial 243 finished with value: 16.233652114868164 and parameters: {'n_layers': 1, 'input_chunk_length': 41, 'hidden_dim': 200, 'learning_rate': 1.5055161273654963e-07, 'batch_size': 64, 'training_length': 437}. Best is trial 243 with value: 16.233652114868164.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 304 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:40,470] Trial 244 finished with value: 21.986574172973633 and parameters: {'n_layers': 1, 'input_chunk_length': 39, 'hidden_dim': 197, 'learning_rate': 1.0158635149339044e-07, 'batch_size': 64, 'training_length': 428}. Best is trial 243 with value: 16.233652114868164.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 305 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:41,479] Trial 245 finished with value: 20.389617919921875 and parameters: {'n_layers': 1, 'input_chunk_length': 41, 'hidden_dim': 171, 'learning_rate': 1.3278654137631862e-07, 'batch_size': 64, 'training_length': 419}. Best is trial 243 with value: 16.233652114868164.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 306 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:42,300] Trial 246 finished with value: 16.243139266967773 and parameters: {'n_layers': 1, 'input_chunk_length': 37, 'hidden_dim': 200, 'learning_rate': 1.481362707739685e-07, 'batch_size': 64, 'training_length': 436}. Best is trial 243 with value: 16.233652114868164.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 307 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:43,327] Trial 247 finished with value: 18.682056427001953 and parameters: {'n_layers': 1, 'input_chunk_length': 38, 'hidden_dim': 195, 'learning_rate': 1.2140563068196958e-07, 'batch_size': 32, 'training_length': 424}. Best is trial 243 with value: 16.233652114868164.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 308 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:44,158] Trial 248 finished with value: 22.02958869934082 and parameters: {'n_layers': 1, 'input_chunk_length': 40, 'hidden_dim': 197, 'learning_rate': 1.3740066323227618e-07, 'batch_size': 64, 'training_length': 438}. Best is trial 243 with value: 16.233652114868164.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 309 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:45,520] Trial 249 finished with value: 16.243610382080078 and parameters: {'n_layers': 1, 'input_chunk_length': 37, 'hidden_dim': 200, 'learning_rate': 1.4518967824764087e-07, 'batch_size': 16, 'training_length': 426}. Best is trial 243 with value: 16.233652114868164.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 310 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:46,352] Trial 250 finished with value: 18.68414878845215 and parameters: {'n_layers': 1, 'input_chunk_length': 35, 'hidden_dim': 195, 'learning_rate': 1.1407588123535209e-07, 'batch_size': 64, 'training_length': 452}. Best is trial 243 with value: 16.233652114868164.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 311 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:47,426] Trial 251 finished with value: 18.597084045410156 and parameters: {'n_layers': 1, 'input_chunk_length': 38, 'hidden_dim': 192, 'learning_rate': 1.6671366566105235e-07, 'batch_size': 64, 'training_length': 439}. Best is trial 243 with value: 16.233652114868164.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 312 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:48,239] Trial 252 finished with value: 16.233631134033203 and parameters: {'n_layers': 1, 'input_chunk_length': 41, 'hidden_dim': 200, 'learning_rate': 1.387929443631152e-07, 'batch_size': 64, 'training_length': 443}. Best is trial 252 with value: 16.233631134033203.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 313 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:49,066] Trial 253 finished with value: 21.980037689208984 and parameters: {'n_layers': 1, 'input_chunk_length': 41, 'hidden_dim': 197, 'learning_rate': 1.0018568448964014e-07, 'batch_size': 64, 'training_length': 446}. Best is trial 252 with value: 16.233631134033203.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 314 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:49,901] Trial 254 finished with value: 21.98642921447754 and parameters: {'n_layers': 1, 'input_chunk_length': 44, 'hidden_dim': 197, 'learning_rate': 1.335408214894292e-07, 'batch_size': 64, 'training_length': 456}. Best is trial 252 with value: 16.233631134033203.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 315 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:50,719] Trial 255 finished with value: 16.23333740234375 and parameters: {'n_layers': 1, 'input_chunk_length': 46, 'hidden_dim': 200, 'learning_rate': 1.4910724807083804e-07, 'batch_size': 64, 'training_length': 438}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 316 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:51,966] Trial 256 finished with value: 23.94725799560547 and parameters: {'n_layers': 2, 'dropout': 0.3387104728185948, 'input_chunk_length': 46, 'hidden_dim': 194, 'learning_rate': 1.1849829275909526e-07, 'batch_size': 64, 'training_length': 440}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 317 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:52,801] Trial 257 finished with value: 21.984830856323242 and parameters: {'n_layers': 1, 'input_chunk_length': 42, 'hidden_dim': 197, 'learning_rate': 1.6523670371809862e-07, 'batch_size': 64, 'training_length': 453}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 318 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:53,623] Trial 258 finished with value: 16.233963012695312 and parameters: {'n_layers': 1, 'input_chunk_length': 47, 'hidden_dim': 200, 'learning_rate': 1.0042818741517621e-07, 'batch_size': 64, 'training_length': 445}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 319 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:54,696] Trial 259 finished with value: 19.735177993774414 and parameters: {'n_layers': 1, 'input_chunk_length': 45, 'hidden_dim': 191, 'learning_rate': 1.0057502787919486e-07, 'batch_size': 64, 'training_length': 443}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 320 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:55,523] Trial 260 finished with value: 18.681671142578125 and parameters: {'n_layers': 1, 'input_chunk_length': 48, 'hidden_dim': 195, 'learning_rate': 1.256382480679027e-07, 'batch_size': 64, 'training_length': 435}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 321 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:56,341] Trial 261 finished with value: 16.309146881103516 and parameters: {'n_layers': 1, 'input_chunk_length': 40, 'hidden_dim': 200, 'learning_rate': 1.2135446627496192e-07, 'batch_size': 64, 'training_length': 445}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 322 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:57,172] Trial 262 finished with value: 21.984703063964844 and parameters: {'n_layers': 1, 'input_chunk_length': 42, 'hidden_dim': 197, 'learning_rate': 1.4511869972888862e-07, 'batch_size': 64, 'training_length': 459}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 323 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:57,874] Trial 263 finished with value: 16.234188079833984 and parameters: {'n_layers': 1, 'input_chunk_length': 49, 'hidden_dim': 200, 'learning_rate': 1.0007334930197665e-07, 'batch_size': 64, 'training_length': 197}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 324 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:58,702] Trial 264 finished with value: 20.803604125976562 and parameters: {'n_layers': 1, 'input_chunk_length': 34, 'hidden_dim': 194, 'learning_rate': 1.0077365409264623e-07, 'batch_size': 64, 'training_length': 452}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 325 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:29:59,543] Trial 265 finished with value: 21.98038673400879 and parameters: {'n_layers': 1, 'input_chunk_length': 49, 'hidden_dim': 197, 'learning_rate': 1.1788928631660195e-07, 'batch_size': 64, 'training_length': 475}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 326 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:00,321] Trial 266 finished with value: 19.742048263549805 and parameters: {'n_layers': 1, 'input_chunk_length': 52, 'hidden_dim': 191, 'learning_rate': 1.7550248427745103e-07, 'batch_size': 64, 'training_length': 161}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 327 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:01,144] Trial 267 finished with value: 16.233644485473633 and parameters: {'n_layers': 1, 'input_chunk_length': 56, 'hidden_dim': 200, 'learning_rate': 1.0104010757877116e-07, 'batch_size': 64, 'training_length': 448}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 328 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:01,739] Trial 268 finished with value: 25.94811248779297 and parameters: {'n_layers': 1, 'input_chunk_length': 60, 'hidden_dim': 120, 'learning_rate': 1.1514332149187983e-07, 'batch_size': 64, 'training_length': 448}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 329 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:02,568] Trial 269 finished with value: 21.986480712890625 and parameters: {'n_layers': 1, 'input_chunk_length': 57, 'hidden_dim': 197, 'learning_rate': 1.0239978719637618e-07, 'batch_size': 32, 'training_length': 206}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 330 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:03,953] Trial 270 finished with value: 20.8018856048584 and parameters: {'n_layers': 1, 'input_chunk_length': 47, 'hidden_dim': 194, 'learning_rate': 1.1927734856515273e-07, 'batch_size': 16, 'training_length': 438}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 331 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:04,786] Trial 271 finished with value: 16.24327278137207 and parameters: {'n_layers': 1, 'input_chunk_length': 52, 'hidden_dim': 200, 'learning_rate': 1.7051876018919537e-07, 'batch_size': 64, 'training_length': 462}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 332 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:05,624] Trial 272 finished with value: 21.986465454101562 and parameters: {'n_layers': 1, 'input_chunk_length': 44, 'hidden_dim': 197, 'learning_rate': 1.4170317929356613e-07, 'batch_size': 64, 'training_length': 457}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 333 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:06,352] Trial 273 finished with value: 27.144758224487305 and parameters: {'n_layers': 1, 'input_chunk_length': 50, 'hidden_dim': 189, 'learning_rate': 1.0040065665982144e-07, 'batch_size': 64, 'training_length': 123}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 334 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:06,949] Trial 274 finished with value: 23.56906509399414 and parameters: {'n_layers': 1, 'input_chunk_length': 56, 'hidden_dim': 105, 'learning_rate': 1.2215633411854085e-07, 'batch_size': 64, 'training_length': 445}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 335 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:07,771] Trial 275 finished with value: 16.239978790283203 and parameters: {'n_layers': 1, 'input_chunk_length': 45, 'hidden_dim': 200, 'learning_rate': 1.784711752999252e-07, 'batch_size': 64, 'training_length': 435}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 336 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:08,598] Trial 276 finished with value: 20.80135154724121 and parameters: {'n_layers': 1, 'input_chunk_length': 54, 'hidden_dim': 194, 'learning_rate': 1.875286055351033e-07, 'batch_size': 64, 'training_length': 432}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 337 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:09,412] Trial 277 finished with value: 21.98373794555664 and parameters: {'n_layers': 1, 'input_chunk_length': 45, 'hidden_dim': 197, 'learning_rate': 1.7062778599569827e-07, 'batch_size': 64, 'training_length': 415}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 338 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:10,228] Trial 278 finished with value: 16.24313735961914 and parameters: {'n_layers': 1, 'input_chunk_length': 48, 'hidden_dim': 200, 'learning_rate': 1.0047309628835531e-07, 'batch_size': 64, 'training_length': 440}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 339 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:11,311] Trial 279 finished with value: 18.588361740112305 and parameters: {'n_layers': 1, 'input_chunk_length': 47, 'hidden_dim': 192, 'learning_rate': 1.0223479714517096e-07, 'batch_size': 64, 'training_length': 447}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 340 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:12,151] Trial 280 finished with value: 21.980222702026367 and parameters: {'n_layers': 1, 'input_chunk_length': 49, 'hidden_dim': 197, 'learning_rate': 1.221373875496709e-07, 'batch_size': 64, 'training_length': 454}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 341 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:12,985] Trial 281 finished with value: 18.67529296875 and parameters: {'n_layers': 1, 'input_chunk_length': 47, 'hidden_dim': 195, 'learning_rate': 3.5665287079621084e-06, 'batch_size': 64, 'training_length': 464}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 342 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:14,019] Trial 282 finished with value: 30.012208938598633 and parameters: {'n_layers': 1, 'input_chunk_length': 46, 'hidden_dim': 162, 'learning_rate': 1.009054286986237e-07, 'batch_size': 64, 'training_length': 436}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 343 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:14,862] Trial 283 finished with value: 16.24312400817871 and parameters: {'n_layers': 1, 'input_chunk_length': 43, 'hidden_dim': 200, 'learning_rate': 1.3216623255180365e-07, 'batch_size': 64, 'training_length': 443}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 344 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:15,577] Trial 284 finished with value: 18.83312225341797 and parameters: {'n_layers': 1, 'input_chunk_length': 43, 'hidden_dim': 198, 'learning_rate': 1.3252683189322065e-07, 'batch_size': 64, 'training_length': 178}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 345 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:16,393] Trial 285 finished with value: 20.800765991210938 and parameters: {'n_layers': 1, 'input_chunk_length': 45, 'hidden_dim': 194, 'learning_rate': 1.7650870522584246e-07, 'batch_size': 64, 'training_length': 419}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 346 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:17,219] Trial 286 finished with value: 16.243127822875977 and parameters: {'n_layers': 1, 'input_chunk_length': 43, 'hidden_dim': 200, 'learning_rate': 1.2738183823000927e-07, 'batch_size': 64, 'training_length': 449}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 347 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:18,052] Trial 287 finished with value: 21.98673439025879 and parameters: {'n_layers': 1, 'input_chunk_length': 43, 'hidden_dim': 197, 'learning_rate': 1.1963002429359734e-07, 'batch_size': 64, 'training_length': 449}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 348 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:19,116] Trial 288 finished with value: 18.590742111206055 and parameters: {'n_layers': 1, 'input_chunk_length': 42, 'hidden_dim': 192, 'learning_rate': 1.3399969954747546e-07, 'batch_size': 64, 'training_length': 427}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 349 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:19,935] Trial 289 finished with value: 16.233592987060547 and parameters: {'n_layers': 1, 'input_chunk_length': 41, 'hidden_dim': 200, 'learning_rate': 1.2407276987959378e-07, 'batch_size': 64, 'training_length': 442}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 350 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:21,422] Trial 290 finished with value: 21.04817771911621 and parameters: {'n_layers': 2, 'dropout': 0.41773152439000955, 'input_chunk_length': 40, 'hidden_dim': 197, 'learning_rate': 1.6032175942851494e-07, 'batch_size': 64, 'training_length': 434}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 351 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:22,460] Trial 291 finished with value: 18.680028915405273 and parameters: {'n_layers': 1, 'input_chunk_length': 41, 'hidden_dim': 195, 'learning_rate': 1.8090671562172204e-07, 'batch_size': 32, 'training_length': 443}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 352 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:23,291] Trial 292 finished with value: 16.23983383178711 and parameters: {'n_layers': 1, 'input_chunk_length': 45, 'hidden_dim': 200, 'learning_rate': 1.192651117744435e-07, 'batch_size': 64, 'training_length': 466}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 353 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:24,382] Trial 293 finished with value: 17.816246032714844 and parameters: {'n_layers': 1, 'input_chunk_length': 45, 'hidden_dim': 190, 'learning_rate': 1.2001704241115165e-07, 'batch_size': 64, 'training_length': 467}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 354 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:25,808] Trial 294 finished with value: 18.68253517150879 and parameters: {'n_layers': 1, 'input_chunk_length': 53, 'hidden_dim': 195, 'learning_rate': 1.522202535955021e-07, 'batch_size': 16, 'training_length': 471}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 355 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:26,643] Trial 295 finished with value: 18.826383590698242 and parameters: {'n_layers': 1, 'input_chunk_length': 46, 'hidden_dim': 198, 'learning_rate': 1.1610318660443009e-07, 'batch_size': 64, 'training_length': 456}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 356 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:27,474] Trial 296 finished with value: 16.243202209472656 and parameters: {'n_layers': 1, 'input_chunk_length': 60, 'hidden_dim': 200, 'learning_rate': 1.0018956576853843e-07, 'batch_size': 64, 'training_length': 461}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 357 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:28,300] Trial 297 finished with value: 29.24798011779785 and parameters: {'n_layers': 1, 'input_chunk_length': 36, 'hidden_dim': 193, 'learning_rate': 1.7924309444813293e-07, 'batch_size': 64, 'training_length': 431}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 358 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:29,118] Trial 298 finished with value: 22.029523849487305 and parameters: {'n_layers': 1, 'input_chunk_length': 40, 'hidden_dim': 197, 'learning_rate': 1.4578560160065355e-07, 'batch_size': 64, 'training_length': 409}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 359 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:29,947] Trial 299 finished with value: 16.23358726501465 and parameters: {'n_layers': 1, 'input_chunk_length': 51, 'hidden_dim': 200, 'learning_rate': 1.182179485301624e-07, 'batch_size': 64, 'training_length': 453}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 360 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:30,793] Trial 300 finished with value: 18.681516647338867 and parameters: {'n_layers': 1, 'input_chunk_length': 50, 'hidden_dim': 195, 'learning_rate': 1.1747629691598711e-07, 'batch_size': 64, 'training_length': 471}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 361 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:31,635] Trial 301 finished with value: 21.97945785522461 and parameters: {'n_layers': 1, 'input_chunk_length': 97, 'hidden_dim': 197, 'learning_rate': 1.1781675651825883e-07, 'batch_size': 64, 'training_length': 451}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 362 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:32,449] Trial 302 finished with value: 16.233396530151367 and parameters: {'n_layers': 1, 'input_chunk_length': 54, 'hidden_dim': 200, 'learning_rate': 1.3689092500854402e-07, 'batch_size': 64, 'training_length': 440}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 363 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:33,512] Trial 303 finished with value: 18.637907028198242 and parameters: {'n_layers': 1, 'input_chunk_length': 55, 'hidden_dim': 192, 'learning_rate': 1.1571793070425207e-05, 'batch_size': 64, 'training_length': 425}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 364 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:34,348] Trial 304 finished with value: 21.986473083496094 and parameters: {'n_layers': 1, 'input_chunk_length': 52, 'hidden_dim': 197, 'learning_rate': 1.1753456606075182e-07, 'batch_size': 64, 'training_length': 438}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 365 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:35,175] Trial 305 finished with value: 16.234155654907227 and parameters: {'n_layers': 1, 'input_chunk_length': 49, 'hidden_dim': 200, 'learning_rate': 1.0108069596477909e-07, 'batch_size': 64, 'training_length': 442}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 366 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:36,002] Trial 306 finished with value: 18.679828643798828 and parameters: {'n_layers': 1, 'input_chunk_length': 51, 'hidden_dim': 195, 'learning_rate': 1.0100395591494595e-07, 'batch_size': 64, 'training_length': 430}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 367 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:37,075] Trial 307 finished with value: 27.122684478759766 and parameters: {'n_layers': 1, 'input_chunk_length': 49, 'hidden_dim': 189, 'learning_rate': 5.220628303718568e-06, 'batch_size': 64, 'training_length': 443}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 368 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:37,891] Trial 308 finished with value: 18.826059341430664 and parameters: {'n_layers': 1, 'input_chunk_length': 54, 'hidden_dim': 198, 'learning_rate': 1.3184169084669404e-07, 'batch_size': 64, 'training_length': 419}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 369 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:38,714] Trial 309 finished with value: 16.233619689941406 and parameters: {'n_layers': 1, 'input_chunk_length': 51, 'hidden_dim': 200, 'learning_rate': 1.1572595994544884e-07, 'batch_size': 64, 'training_length': 437}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 370 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:39,542] Trial 310 finished with value: 29.246124267578125 and parameters: {'n_layers': 1, 'input_chunk_length': 53, 'hidden_dim': 193, 'learning_rate': 1.0062655656463401e-07, 'batch_size': 64, 'training_length': 434}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 371 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:40,367] Trial 311 finished with value: 21.979942321777344 and parameters: {'n_layers': 1, 'input_chunk_length': 51, 'hidden_dim': 197, 'learning_rate': 1.1607199762041727e-07, 'batch_size': 64, 'training_length': 421}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 372 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:41,188] Trial 312 finished with value: 16.24311637878418 and parameters: {'n_layers': 1, 'input_chunk_length': 48, 'hidden_dim': 200, 'learning_rate': 1.0009988553851733e-07, 'batch_size': 64, 'training_length': 441}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 373 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:42,075] Trial 313 finished with value: 18.67626953125 and parameters: {'n_layers': 1, 'input_chunk_length': 55, 'hidden_dim': 195, 'learning_rate': 1.3885480281070336e-07, 'batch_size': 64, 'training_length': 448}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 374 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:42,846] Trial 314 finished with value: 16.243440628051758 and parameters: {'n_layers': 1, 'input_chunk_length': 50, 'hidden_dim': 200, 'learning_rate': 1.425057891730049e-07, 'batch_size': 32, 'training_length': 146}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 375 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:43,669] Trial 315 finished with value: 21.980064392089844 and parameters: {'n_layers': 1, 'input_chunk_length': 47, 'hidden_dim': 197, 'learning_rate': 1.1643249882723146e-07, 'batch_size': 64, 'training_length': 428}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 376 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:44,749] Trial 316 finished with value: 18.58978843688965 and parameters: {'n_layers': 1, 'input_chunk_length': 51, 'hidden_dim': 192, 'learning_rate': 1.8611120691352585e-07, 'batch_size': 64, 'training_length': 437}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 377 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:45,460] Trial 317 finished with value: 18.67435646057129 and parameters: {'n_layers': 1, 'input_chunk_length': 49, 'hidden_dim': 195, 'learning_rate': 1.006547942773913e-07, 'batch_size': 64, 'training_length': 203}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 378 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:46,848] Trial 318 finished with value: 16.233776092529297 and parameters: {'n_layers': 1, 'input_chunk_length': 46, 'hidden_dim': 200, 'learning_rate': 1.5147845283661622e-07, 'batch_size': 16, 'training_length': 451}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 379 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:47,597] Trial 319 finished with value: 33.134765625 and parameters: {'n_layers': 1, 'input_chunk_length': 45, 'hidden_dim': 86, 'learning_rate': 1.2425397061120343e-07, 'batch_size': 16, 'training_length': 233}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 380 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:49,001] Trial 320 finished with value: 21.979860305786133 and parameters: {'n_layers': 1, 'input_chunk_length': 47, 'hidden_dim': 197, 'learning_rate': 1.6012345720572368e-07, 'batch_size': 16, 'training_length': 450}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 381 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:49,823] Trial 321 finished with value: 16.29953956604004 and parameters: {'n_layers': 1, 'input_chunk_length': 57, 'hidden_dim': 200, 'learning_rate': 2.0452010511844406e-05, 'batch_size': 64, 'training_length': 444}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 382 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:51,237] Trial 322 finished with value: 18.67447280883789 and parameters: {'n_layers': 1, 'input_chunk_length': 49, 'hidden_dim': 195, 'learning_rate': 1.1961995770680528e-07, 'batch_size': 16, 'training_length': 458}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 383 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:52,649] Trial 323 finished with value: 21.980375289916992 and parameters: {'n_layers': 1, 'input_chunk_length': 53, 'hidden_dim': 197, 'learning_rate': 1.8474659467764625e-07, 'batch_size': 16, 'training_length': 459}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 384 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:54,313] Trial 324 finished with value: 17.81694984436035 and parameters: {'n_layers': 1, 'input_chunk_length': 45, 'hidden_dim': 190, 'learning_rate': 1.3825482729440054e-07, 'batch_size': 16, 'training_length': 451}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 385 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:55,949] Trial 325 finished with value: 31.710834503173828 and parameters: {'n_layers': 1, 'input_chunk_length': 48, 'hidden_dim': 186, 'learning_rate': 1.5674703757499479e-07, 'batch_size': 16, 'training_length': 437}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 386 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:56,585] Trial 326 finished with value: 16.23984146118164 and parameters: {'n_layers': 1, 'input_chunk_length': 47, 'hidden_dim': 200, 'learning_rate': 2.509763315273607e-06, 'batch_size': 64, 'training_length': 91}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 387 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:57,971] Trial 327 finished with value: 29.24442481994629 and parameters: {'n_layers': 1, 'input_chunk_length': 46, 'hidden_dim': 193, 'learning_rate': 1.008385016047054e-07, 'batch_size': 16, 'training_length': 443}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 388 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:58,650] Trial 328 finished with value: 21.979772567749023 and parameters: {'n_layers': 1, 'input_chunk_length': 51, 'hidden_dim': 197, 'learning_rate': 1.191958217757083e-07, 'batch_size': 64, 'training_length': 150}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 389 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:30:59,471] Trial 329 finished with value: 16.243141174316406 and parameters: {'n_layers': 1, 'input_chunk_length': 44, 'hidden_dim': 200, 'learning_rate': 1.2054017372943318e-07, 'batch_size': 64, 'training_length': 410}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 390 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:00,154] Trial 330 finished with value: 20.80856704711914 and parameters: {'n_layers': 1, 'input_chunk_length': 48, 'hidden_dim': 194, 'learning_rate': 1.0005435583334464e-07, 'batch_size': 64, 'training_length': 128}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 391 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:00,823] Trial 331 finished with value: 21.97458839416504 and parameters: {'n_layers': 1, 'input_chunk_length': 55, 'hidden_dim': 197, 'learning_rate': 2.5896782079024507e-06, 'batch_size': 64, 'training_length': 96}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 392 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:01,523] Trial 332 finished with value: 16.2385311126709 and parameters: {'n_layers': 1, 'input_chunk_length': 58, 'hidden_dim': 200, 'learning_rate': 1.8351546278835346e-07, 'batch_size': 64, 'training_length': 192}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 393 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:02,160] Trial 333 finished with value: 16.269123077392578 and parameters: {'n_layers': 1, 'input_chunk_length': 59, 'hidden_dim': 200, 'learning_rate': 3.2578614309258077e-06, 'batch_size': 64, 'training_length': 85}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 394 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:02,786] Trial 334 finished with value: 21.997886657714844 and parameters: {'n_layers': 1, 'input_chunk_length': 59, 'hidden_dim': 197, 'learning_rate': 1.98789287703933e-07, 'batch_size': 64, 'training_length': 71}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 395 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:03,589] Trial 335 finished with value: 18.603641510009766 and parameters: {'n_layers': 1, 'input_chunk_length': 57, 'hidden_dim': 192, 'learning_rate': 2.097560227030819e-06, 'batch_size': 64, 'training_length': 163}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 396 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:04,583] Trial 336 finished with value: 21.229694366455078 and parameters: {'n_layers': 2, 'dropout': 0.20931633905677965, 'input_chunk_length': 51, 'hidden_dim': 195, 'learning_rate': 1.909227194904648e-07, 'batch_size': 64, 'training_length': 258}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 397 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:05,274] Trial 337 finished with value: 16.24802589416504 and parameters: {'n_layers': 1, 'input_chunk_length': 46, 'hidden_dim': 200, 'learning_rate': 8.174130048825726e-06, 'batch_size': 64, 'training_length': 176}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 398 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:06,305] Trial 338 finished with value: 21.976436614990234 and parameters: {'n_layers': 1, 'input_chunk_length': 53, 'hidden_dim': 197, 'learning_rate': 4.493126281140588e-06, 'batch_size': 32, 'training_length': 432}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 399 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:07,131] Trial 339 finished with value: 27.14409828186035 and parameters: {'n_layers': 1, 'input_chunk_length': 48, 'hidden_dim': 189, 'learning_rate': 2.609517013118886e-07, 'batch_size': 64, 'training_length': 199}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 400 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:07,838] Trial 340 finished with value: 18.82854652404785 and parameters: {'n_layers': 1, 'input_chunk_length': 56, 'hidden_dim': 198, 'learning_rate': 1.6685284784898427e-07, 'batch_size': 64, 'training_length': 192}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 401 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:08,962] Trial 341 finished with value: 20.877819061279297 and parameters: {'n_layers': 1, 'input_chunk_length': 61, 'hidden_dim': 194, 'learning_rate': 1.391524050447343e-07, 'batch_size': 16, 'training_length': 217}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 402 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:09,690] Trial 342 finished with value: 16.2434024810791 and parameters: {'n_layers': 1, 'input_chunk_length': 50, 'hidden_dim': 200, 'learning_rate': 1.714167848565407e-07, 'batch_size': 64, 'training_length': 242}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 403 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:10,517] Trial 343 finished with value: 18.677717208862305 and parameters: {'n_layers': 1, 'input_chunk_length': 46, 'hidden_dim': 195, 'learning_rate': 1.3823167023482325e-07, 'batch_size': 64, 'training_length': 430}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 404 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:11,337] Trial 344 finished with value: 21.98641014099121 and parameters: {'n_layers': 1, 'input_chunk_length': 44, 'hidden_dim': 197, 'learning_rate': 1.9105066031345594e-07, 'batch_size': 64, 'training_length': 419}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 405 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:12,162] Trial 345 finished with value: 16.247102737426758 and parameters: {'n_layers': 1, 'input_chunk_length': 62, 'hidden_dim': 200, 'learning_rate': 1.6836847515734844e-06, 'batch_size': 64, 'training_length': 443}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 406 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:12,907] Trial 346 finished with value: 18.588653564453125 and parameters: {'n_layers': 1, 'input_chunk_length': 54, 'hidden_dim': 192, 'learning_rate': 1.3435108046666302e-07, 'batch_size': 64, 'training_length': 118}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 407 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:13,748] Trial 347 finished with value: 21.97991180419922 and parameters: {'n_layers': 1, 'input_chunk_length': 47, 'hidden_dim': 197, 'learning_rate': 2.3398443311549858e-07, 'batch_size': 64, 'training_length': 462}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 408 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:14,580] Trial 348 finished with value: 16.23428726196289 and parameters: {'n_layers': 1, 'input_chunk_length': 49, 'hidden_dim': 200, 'learning_rate': 1.5698994416417853e-07, 'batch_size': 64, 'training_length': 437}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 409 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:15,411] Trial 349 finished with value: 20.80065155029297 and parameters: {'n_layers': 1, 'input_chunk_length': 49, 'hidden_dim': 194, 'learning_rate': 2.0437486636664847e-07, 'batch_size': 64, 'training_length': 436}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 410 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:16,249] Trial 350 finished with value: 21.9865665435791 and parameters: {'n_layers': 1, 'input_chunk_length': 52, 'hidden_dim': 197, 'learning_rate': 1.6225138259986121e-07, 'batch_size': 64, 'training_length': 450}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 411 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:17,171] Trial 351 finished with value: 24.777803421020508 and parameters: {'n_layers': 1, 'input_chunk_length': 50, 'hidden_dim': 146, 'learning_rate': 6.11158428269909e-06, 'batch_size': 64, 'training_length': 462}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 412 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:17,820] Trial 352 finished with value: 16.241666793823242 and parameters: {'n_layers': 1, 'input_chunk_length': 42, 'hidden_dim': 200, 'learning_rate': 1.5665525013282684e-07, 'batch_size': 64, 'training_length': 107}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 413 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:18,499] Trial 353 finished with value: 19.7415828704834 and parameters: {'n_layers': 1, 'input_chunk_length': 65, 'hidden_dim': 191, 'learning_rate': 1.9968343067140763e-07, 'batch_size': 64, 'training_length': 80}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 414 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:19,163] Trial 354 finished with value: 16.243488311767578 and parameters: {'n_layers': 1, 'input_chunk_length': 43, 'hidden_dim': 200, 'learning_rate': 2.550137556509562e-07, 'batch_size': 64, 'training_length': 133}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 415 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:19,802] Trial 355 finished with value: 18.67252540588379 and parameters: {'n_layers': 1, 'input_chunk_length': 42, 'hidden_dim': 195, 'learning_rate': 1.6172956685381328e-07, 'batch_size': 64, 'training_length': 82}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 416 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:21,178] Trial 356 finished with value: 21.983139038085938 and parameters: {'n_layers': 1, 'input_chunk_length': 45, 'hidden_dim': 197, 'learning_rate': 1.5736293355565607e-07, 'batch_size': 16, 'training_length': 426}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 417 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:21,822] Trial 357 finished with value: 16.234237670898438 and parameters: {'n_layers': 1, 'input_chunk_length': 47, 'hidden_dim': 200, 'learning_rate': 2.227102108473177e-07, 'batch_size': 64, 'training_length': 93}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 418 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:22,539] Trial 358 finished with value: 18.090145111083984 and parameters: {'n_layers': 1, 'input_chunk_length': 48, 'hidden_dim': 187, 'learning_rate': 2.1125094742605576e-07, 'batch_size': 64, 'training_length': 112}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 419 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:23,197] Trial 359 finished with value: 19.149080276489258 and parameters: {'n_layers': 1, 'input_chunk_length': 47, 'hidden_dim': 155, 'learning_rate': 2.773381072952465e-07, 'batch_size': 64, 'training_length': 89}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 420 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:24,040] Trial 360 finished with value: 21.98564910888672 and parameters: {'n_layers': 1, 'input_chunk_length': 84, 'hidden_dim': 197, 'learning_rate': 1.0863944921649989e-06, 'batch_size': 64, 'training_length': 445}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 421 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:24,747] Trial 361 finished with value: 29.2479190826416 and parameters: {'n_layers': 1, 'input_chunk_length': 50, 'hidden_dim': 193, 'learning_rate': 1.3400128324520638e-07, 'batch_size': 32, 'training_length': 60}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 422 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:25,563] Trial 362 finished with value: 16.23346519470215 and parameters: {'n_layers': 1, 'input_chunk_length': 46, 'hidden_dim': 200, 'learning_rate': 2.3213021932571003e-07, 'batch_size': 64, 'training_length': 416}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 423 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:26,401] Trial 363 finished with value: 21.982568740844727 and parameters: {'n_layers': 1, 'input_chunk_length': 58, 'hidden_dim': 197, 'learning_rate': 2.398758144567252e-07, 'batch_size': 64, 'training_length': 452}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 424 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:27,402] Trial 364 finished with value: 28.35190200805664 and parameters: {'n_layers': 1, 'input_chunk_length': 52, 'hidden_dim': 166, 'learning_rate': 1.946221580659135e-07, 'batch_size': 64, 'training_length': 413}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 425 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:28,129] Trial 365 finished with value: 18.674293518066406 and parameters: {'n_layers': 1, 'input_chunk_length': 49, 'hidden_dim': 195, 'learning_rate': 1.2877587160965612e-07, 'batch_size': 64, 'training_length': 226}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 426 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:28,932] Trial 366 finished with value: 16.233915328979492 and parameters: {'n_layers': 1, 'input_chunk_length': 55, 'hidden_dim': 200, 'learning_rate': 2.884873463246393e-07, 'batch_size': 64, 'training_length': 401}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 427 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:29,988] Trial 367 finished with value: 18.597227096557617 and parameters: {'n_layers': 1, 'input_chunk_length': 52, 'hidden_dim': 192, 'learning_rate': 2.3760300651430327e-07, 'batch_size': 64, 'training_length': 415}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 428 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:30,815] Trial 368 finished with value: 21.980134963989258 and parameters: {'n_layers': 1, 'input_chunk_length': 56, 'hidden_dim': 197, 'learning_rate': 2.8408378477789256e-07, 'batch_size': 64, 'training_length': 425}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 429 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:32,194] Trial 369 finished with value: 16.239927291870117 and parameters: {'n_layers': 1, 'input_chunk_length': 58, 'hidden_dim': 200, 'learning_rate': 3.311443621993986e-07, 'batch_size': 16, 'training_length': 442}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 430 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:33,016] Trial 370 finished with value: 18.682777404785156 and parameters: {'n_layers': 1, 'input_chunk_length': 53, 'hidden_dim': 195, 'learning_rate': 2.267259348297902e-07, 'batch_size': 64, 'training_length': 403}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 431 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:33,847] Trial 371 finished with value: 18.8260440826416 and parameters: {'n_layers': 1, 'input_chunk_length': 55, 'hidden_dim': 198, 'learning_rate': 1.8012993126123383e-07, 'batch_size': 64, 'training_length': 432}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 432 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:34,527] Trial 372 finished with value: 24.944467544555664 and parameters: {'n_layers': 2, 'dropout': 0.11199766562392244, 'input_chunk_length': 54, 'hidden_dim': 122, 'learning_rate': 1.4852240843706078e-07, 'batch_size': 64, 'training_length': 396}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 433 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:35,349] Trial 373 finished with value: 20.804908752441406 and parameters: {'n_layers': 1, 'input_chunk_length': 51, 'hidden_dim': 194, 'learning_rate': 2.978514856514761e-07, 'batch_size': 64, 'training_length': 406}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 434 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:36,427] Trial 374 finished with value: 17.815322875976562 and parameters: {'n_layers': 1, 'input_chunk_length': 56, 'hidden_dim': 190, 'learning_rate': 1.2013206413634425e-07, 'batch_size': 64, 'training_length': 448}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 435 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:37,312] Trial 375 finished with value: 18.6414737701416 and parameters: {'n_layers': 1, 'input_chunk_length': 49, 'hidden_dim': 136, 'learning_rate': 2.0677950372157876e-07, 'batch_size': 64, 'training_length': 422}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 436 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:37,909] Trial 376 finished with value: 24.5283203125 and parameters: {'n_layers': 1, 'input_chunk_length': 92, 'hidden_dim': 109, 'learning_rate': 1.6184944706830248e-07, 'batch_size': 64, 'training_length': 440}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 437 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:38,710] Trial 377 finished with value: 16.243186950683594 and parameters: {'n_layers': 1, 'input_chunk_length': 44, 'hidden_dim': 200, 'learning_rate': 1.2533201132461663e-07, 'batch_size': 64, 'training_length': 391}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 438 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:39,314] Trial 378 finished with value: 18.74408721923828 and parameters: {'n_layers': 1, 'input_chunk_length': 47, 'hidden_dim': 113, 'learning_rate': 1.4206208275183115e-07, 'batch_size': 64, 'training_length': 455}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 439 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:39,888] Trial 379 finished with value: 47.21304702758789 and parameters: {'n_layers': 1, 'input_chunk_length': 75, 'hidden_dim': 79, 'learning_rate': 1.873750931456697e-07, 'batch_size': 64, 'training_length': 432}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 440 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:40,722] Trial 380 finished with value: 21.979753494262695 and parameters: {'n_layers': 1, 'input_chunk_length': 54, 'hidden_dim': 197, 'learning_rate': 1.1762298181355358e-07, 'batch_size': 64, 'training_length': 444}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 441 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:42,088] Trial 381 finished with value: 16.309846878051758 and parameters: {'n_layers': 1, 'input_chunk_length': 40, 'hidden_dim': 200, 'learning_rate': 1.5479454857750882e-07, 'batch_size': 16, 'training_length': 419}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 442 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:42,926] Trial 382 finished with value: 21.048702239990234 and parameters: {'n_layers': 1, 'input_chunk_length': 46, 'hidden_dim': 194, 'learning_rate': 0.0006740636883003197, 'batch_size': 64, 'training_length': 465}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 443 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:43,759] Trial 383 finished with value: 21.979509353637695 and parameters: {'n_layers': 1, 'input_chunk_length': 51, 'hidden_dim': 197, 'learning_rate': 2.488392964057799e-07, 'batch_size': 64, 'training_length': 451}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 444 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:44,530] Trial 384 finished with value: 16.234416961669922 and parameters: {'n_layers': 1, 'input_chunk_length': 49, 'hidden_dim': 200, 'learning_rate': 1.1724938591917253e-07, 'batch_size': 32, 'training_length': 137}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 445 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:45,373] Trial 385 finished with value: 21.986560821533203 and parameters: {'n_layers': 1, 'input_chunk_length': 50, 'hidden_dim': 197, 'learning_rate': 1.393024499199974e-07, 'batch_size': 32, 'training_length': 175}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 446 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:45,976] Trial 386 finished with value: 31.635417938232422 and parameters: {'n_layers': 1, 'input_chunk_length': 53, 'hidden_dim': 93, 'learning_rate': 1.0002836827975318e-07, 'batch_size': 64, 'training_length': 432}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 447 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:46,842] Trial 387 finished with value: 18.58876609802246 and parameters: {'n_layers': 1, 'input_chunk_length': 49, 'hidden_dim': 192, 'learning_rate': 1.6769331891218996e-07, 'batch_size': 32, 'training_length': 133}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 448 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:47,874] Trial 388 finished with value: 16.243682861328125 and parameters: {'n_layers': 1, 'input_chunk_length': 52, 'hidden_dim': 200, 'learning_rate': 1.8748892986863276e-07, 'batch_size': 32, 'training_length': 426}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 449 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:48,921] Trial 389 finished with value: 18.67266273498535 and parameters: {'n_layers': 1, 'input_chunk_length': 58, 'hidden_dim': 195, 'learning_rate': 1.1731130200286352e-07, 'batch_size': 32, 'training_length': 437}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 450 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:49,696] Trial 390 finished with value: 21.986051559448242 and parameters: {'n_layers': 1, 'input_chunk_length': 48, 'hidden_dim': 197, 'learning_rate': 1.3782839204704167e-07, 'batch_size': 32, 'training_length': 139}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 451 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:50,912] Trial 391 finished with value: 17.81431770324707 and parameters: {'n_layers': 1, 'input_chunk_length': 55, 'hidden_dim': 190, 'learning_rate': 2.1092963824811465e-07, 'batch_size': 32, 'training_length': 440}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 452 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:51,547] Trial 392 finished with value: 22.296796798706055 and parameters: {'n_layers': 1, 'input_chunk_length': 50, 'hidden_dim': 67, 'learning_rate': 1.6107356255187998e-07, 'batch_size': 32, 'training_length': 187}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 453 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:52,569] Trial 393 finished with value: 16.24323081970215 and parameters: {'n_layers': 1, 'input_chunk_length': 36, 'hidden_dim': 200, 'learning_rate': 1.1516564344925885e-07, 'batch_size': 32, 'training_length': 416}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 454 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:53,399] Trial 394 finished with value: 18.681617736816406 and parameters: {'n_layers': 1, 'input_chunk_length': 39, 'hidden_dim': 195, 'learning_rate': 1.3606821266485786e-07, 'batch_size': 64, 'training_length': 429}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 455 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:54,806] Trial 395 finished with value: 21.985944747924805 and parameters: {'n_layers': 1, 'input_chunk_length': 48, 'hidden_dim': 197, 'learning_rate': 1.1585997416522028e-07, 'batch_size': 16, 'training_length': 449}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 456 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:55,638] Trial 396 finished with value: 29.24772071838379 and parameters: {'n_layers': 1, 'input_chunk_length': 52, 'hidden_dim': 193, 'learning_rate': 2.410619000572029e-07, 'batch_size': 64, 'training_length': 437}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 457 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:56,461] Trial 397 finished with value: 16.233797073364258 and parameters: {'n_layers': 1, 'input_chunk_length': 56, 'hidden_dim': 200, 'learning_rate': 1.7945025351742344e-07, 'batch_size': 64, 'training_length': 446}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 458 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:57,021] Trial 398 finished with value: 17.818056106567383 and parameters: {'n_layers': 1, 'input_chunk_length': 56, 'hidden_dim': 57, 'learning_rate': 1.5780826277801064e-07, 'batch_size': 64, 'training_length': 454}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 459 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:57,853] Trial 399 finished with value: 21.997629165649414 and parameters: {'n_layers': 1, 'input_chunk_length': 54, 'hidden_dim': 197, 'learning_rate': 6.216771250073376e-05, 'batch_size': 64, 'training_length': 442}. Best is trial 255 with value: 16.23333740234375.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 460 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:58,687] Trial 400 finished with value: 16.23319435119629 and parameters: {'n_layers': 1, 'input_chunk_length': 46, 'hidden_dim': 200, 'learning_rate': 1.01969280979366e-07, 'batch_size': 64, 'training_length': 459}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 461 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:31:59,520] Trial 401 finished with value: 16.23322868347168 and parameters: {'n_layers': 1, 'input_chunk_length': 46, 'hidden_dim': 200, 'learning_rate': 1.1660938945485212e-07, 'batch_size': 64, 'training_length': 459}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 462 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:00,367] Trial 402 finished with value: 20.808351516723633 and parameters: {'n_layers': 1, 'input_chunk_length': 44, 'hidden_dim': 194, 'learning_rate': 1.0392818249215983e-07, 'batch_size': 64, 'training_length': 461}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 463 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:01,437] Trial 403 finished with value: 24.953590393066406 and parameters: {'n_layers': 1, 'input_chunk_length': 46, 'hidden_dim': 188, 'learning_rate': 1.0012925922411257e-07, 'batch_size': 64, 'training_length': 456}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 464 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:02,277] Trial 404 finished with value: 21.98023223876953 and parameters: {'n_layers': 1, 'input_chunk_length': 47, 'hidden_dim': 197, 'learning_rate': 1.2087541127716028e-07, 'batch_size': 64, 'training_length': 448}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 465 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:03,334] Trial 405 finished with value: 16.233415603637695 and parameters: {'n_layers': 1, 'input_chunk_length': 46, 'hidden_dim': 200, 'learning_rate': 1.3124415514090667e-07, 'batch_size': 32, 'training_length': 456}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 466 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:04,126] Trial 406 finished with value: 21.979496002197266 and parameters: {'n_layers': 1, 'input_chunk_length': 46, 'hidden_dim': 197, 'learning_rate': 1.0091663339156907e-07, 'batch_size': 32, 'training_length': 153}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 467 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:05,401] Trial 407 finished with value: 18.59747314453125 and parameters: {'n_layers': 1, 'input_chunk_length': 44, 'hidden_dim': 192, 'learning_rate': 1.2622526859303574e-07, 'batch_size': 32, 'training_length': 466}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 468 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:06,459] Trial 408 finished with value: 16.23438262939453 and parameters: {'n_layers': 1, 'input_chunk_length': 49, 'hidden_dim': 200, 'learning_rate': 1.320892775152058e-07, 'batch_size': 32, 'training_length': 456}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 469 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:07,517] Trial 409 finished with value: 21.980289459228516 and parameters: {'n_layers': 1, 'input_chunk_length': 49, 'hidden_dim': 197, 'learning_rate': 1.1646174438521372e-07, 'batch_size': 32, 'training_length': 461}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 470 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:08,571] Trial 410 finished with value: 16.24326515197754 and parameters: {'n_layers': 1, 'input_chunk_length': 48, 'hidden_dim': 200, 'learning_rate': 1.0080172690265408e-07, 'batch_size': 32, 'training_length': 452}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 471 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:09,627] Trial 411 finished with value: 20.80949592590332 and parameters: {'n_layers': 1, 'input_chunk_length': 50, 'hidden_dim': 194, 'learning_rate': 1.3202878893611304e-07, 'batch_size': 32, 'training_length': 461}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 472 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:10,685] Trial 412 finished with value: 21.97950553894043 and parameters: {'n_layers': 1, 'input_chunk_length': 46, 'hidden_dim': 197, 'learning_rate': 1.3140108461949418e-07, 'batch_size': 32, 'training_length': 460}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 473 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:12,498] Trial 413 finished with value: 21.195493698120117 and parameters: {'n_layers': 2, 'dropout': 0.0017137061777859341, 'input_chunk_length': 44, 'hidden_dim': 200, 'learning_rate': 1.2055987500993883e-07, 'batch_size': 32, 'training_length': 472}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 474 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:13,552] Trial 414 finished with value: 20.802576065063477 and parameters: {'n_layers': 1, 'input_chunk_length': 51, 'hidden_dim': 194, 'learning_rate': 1.0059398054158108e-07, 'batch_size': 32, 'training_length': 454}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 475 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:14,609] Trial 415 finished with value: 31.113882064819336 and parameters: {'n_layers': 1, 'input_chunk_length': 48, 'hidden_dim': 131, 'learning_rate': 1.3807792547006148e-07, 'batch_size': 32, 'training_length': 447}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 476 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:15,666] Trial 416 finished with value: 21.979692459106445 and parameters: {'n_layers': 1, 'input_chunk_length': 46, 'hidden_dim': 197, 'learning_rate': 1.182528448276871e-07, 'batch_size': 32, 'training_length': 453}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 477 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:16,932] Trial 417 finished with value: 19.73609161376953 and parameters: {'n_layers': 1, 'input_chunk_length': 42, 'hidden_dim': 191, 'learning_rate': 1.4473893555053593e-07, 'batch_size': 32, 'training_length': 468}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 478 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:17,968] Trial 418 finished with value: 16.24338722229004 and parameters: {'n_layers': 1, 'input_chunk_length': 50, 'hidden_dim': 200, 'learning_rate': 1.1791638949009024e-07, 'batch_size': 32, 'training_length': 434}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 479 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:19,020] Trial 419 finished with value: 18.68149185180664 and parameters: {'n_layers': 1, 'input_chunk_length': 48, 'hidden_dim': 195, 'learning_rate': 1.466744618473452e-07, 'batch_size': 32, 'training_length': 448}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 480 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:20,084] Trial 420 finished with value: 18.834457397460938 and parameters: {'n_layers': 1, 'input_chunk_length': 52, 'hidden_dim': 198, 'learning_rate': 1.1684596659355735e-07, 'batch_size': 32, 'training_length': 458}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 481 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:21,119] Trial 421 finished with value: 16.243507385253906 and parameters: {'n_layers': 1, 'input_chunk_length': 44, 'hidden_dim': 200, 'learning_rate': 1.8050007182551524e-07, 'batch_size': 32, 'training_length': 424}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 482 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:22,507] Trial 422 finished with value: 18.674631118774414 and parameters: {'n_layers': 1, 'input_chunk_length': 47, 'hidden_dim': 195, 'learning_rate': 1.387587895962756e-07, 'batch_size': 16, 'training_length': 443}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 483 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:23,221] Trial 423 finished with value: 18.82550621032715 and parameters: {'n_layers': 1, 'input_chunk_length': 45, 'hidden_dim': 198, 'learning_rate': 1.0220340983623262e-07, 'batch_size': 32, 'training_length': 63}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 484 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:24,897] Trial 424 finished with value: 19.12859344482422 and parameters: {'n_layers': 1, 'input_chunk_length': 49, 'hidden_dim': 192, 'learning_rate': 2.7950789565670445e-05, 'batch_size': 16, 'training_length': 434}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 485 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:25,973] Trial 425 finished with value: 16.24180030822754 and parameters: {'n_layers': 1, 'input_chunk_length': 42, 'hidden_dim': 200, 'learning_rate': 1.6496856105554646e-07, 'batch_size': 32, 'training_length': 475}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 486 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:26,812] Trial 426 finished with value: 18.689815521240234 and parameters: {'n_layers': 1, 'input_chunk_length': 53, 'hidden_dim': 195, 'learning_rate': 1.53642851309054e-05, 'batch_size': 64, 'training_length': 447}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 487 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:27,656] Trial 427 finished with value: 21.979862213134766 and parameters: {'n_layers': 1, 'input_chunk_length': 51, 'hidden_dim': 197, 'learning_rate': 1.3804738258110036e-07, 'batch_size': 64, 'training_length': 458}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 488 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:28,478] Trial 428 finished with value: 16.234174728393555 and parameters: {'n_layers': 1, 'input_chunk_length': 47, 'hidden_dim': 200, 'learning_rate': 2.0668819219671344e-07, 'batch_size': 64, 'training_length': 439}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 489 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:29,518] Trial 429 finished with value: 24.95499610900879 and parameters: {'n_layers': 1, 'input_chunk_length': 47, 'hidden_dim': 188, 'learning_rate': 2.1085994178035154e-07, 'batch_size': 64, 'training_length': 409}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 490 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:30,356] Trial 430 finished with value: 21.983524322509766 and parameters: {'n_layers': 1, 'input_chunk_length': 45, 'hidden_dim': 197, 'learning_rate': 2.7197875303598583e-07, 'batch_size': 64, 'training_length': 430}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 491 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:31,201] Trial 431 finished with value: 16.23434829711914 and parameters: {'n_layers': 1, 'input_chunk_length': 49, 'hidden_dim': 200, 'learning_rate': 1.9593632848366522e-07, 'batch_size': 64, 'training_length': 439}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 492 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:32,247] Trial 432 finished with value: 29.50473976135254 and parameters: {'n_layers': 1, 'input_chunk_length': 49, 'hidden_dim': 174, 'learning_rate': 2.908949537862158e-07, 'batch_size': 64, 'training_length': 423}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 493 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:33,287] Trial 433 finished with value: 29.24863624572754 and parameters: {'n_layers': 1, 'input_chunk_length': 50, 'hidden_dim': 193, 'learning_rate': 2.0828804659442493e-07, 'batch_size': 32, 'training_length': 439}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 494 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:34,124] Trial 434 finished with value: 16.234127044677734 and parameters: {'n_layers': 1, 'input_chunk_length': 47, 'hidden_dim': 200, 'learning_rate': 1.943563694753125e-07, 'batch_size': 64, 'training_length': 447}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 495 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:34,959] Trial 435 finished with value: 18.674501419067383 and parameters: {'n_layers': 1, 'input_chunk_length': 47, 'hidden_dim': 195, 'learning_rate': 3.2284319135507847e-07, 'batch_size': 64, 'training_length': 442}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 496 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:36,354] Trial 436 finished with value: 21.978954315185547 and parameters: {'n_layers': 1, 'input_chunk_length': 46, 'hidden_dim': 197, 'learning_rate': 2.2765923835051163e-07, 'batch_size': 16, 'training_length': 429}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 497 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:37,412] Trial 437 finished with value: 17.82295036315918 and parameters: {'n_layers': 1, 'input_chunk_length': 43, 'hidden_dim': 190, 'learning_rate': 1.9471123551055648e-07, 'batch_size': 64, 'training_length': 417}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 498 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:38,243] Trial 438 finished with value: 16.234481811523438 and parameters: {'n_layers': 1, 'input_chunk_length': 49, 'hidden_dim': 200, 'learning_rate': 2.5073416427161243e-07, 'batch_size': 64, 'training_length': 448}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 499 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:39,296] Trial 439 finished with value: 23.985172271728516 and parameters: {'n_layers': 1, 'input_chunk_length': 51, 'hidden_dim': 184, 'learning_rate': 1.9008627766095442e-07, 'batch_size': 64, 'training_length': 438}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 500 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:40,122] Trial 440 finished with value: 20.809782028198242 and parameters: {'n_layers': 1, 'input_chunk_length': 48, 'hidden_dim': 194, 'learning_rate': 2.1734272847728878e-07, 'batch_size': 64, 'training_length': 431}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 501 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:40,963] Trial 441 finished with value: 18.825824737548828 and parameters: {'n_layers': 1, 'input_chunk_length': 45, 'hidden_dim': 198, 'learning_rate': 1.8308947173440893e-07, 'batch_size': 64, 'training_length': 453}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 502 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:42,008] Trial 442 finished with value: 21.980545043945312 and parameters: {'n_layers': 1, 'input_chunk_length': 53, 'hidden_dim': 197, 'learning_rate': 2.5449766945834813e-07, 'batch_size': 32, 'training_length': 443}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 503 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:42,847] Trial 443 finished with value: 16.234167098999023 and parameters: {'n_layers': 1, 'input_chunk_length': 47, 'hidden_dim': 200, 'learning_rate': 1.715763089430928e-07, 'batch_size': 64, 'training_length': 465}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 504 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:43,951] Trial 444 finished with value: 18.597929000854492 and parameters: {'n_layers': 1, 'input_chunk_length': 44, 'hidden_dim': 192, 'learning_rate': 3.2001853355590206e-07, 'batch_size': 64, 'training_length': 466}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 505 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:44,803] Trial 445 finished with value: 16.23426628112793 and parameters: {'n_layers': 1, 'input_chunk_length': 47, 'hidden_dim': 200, 'learning_rate': 2.269623560001296e-07, 'batch_size': 64, 'training_length': 474}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 506 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:45,648] Trial 446 finished with value: 18.677824020385742 and parameters: {'n_layers': 1, 'input_chunk_length': 46, 'hidden_dim': 195, 'learning_rate': 2.561372526209565e-07, 'batch_size': 64, 'training_length': 471}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 507 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:46,498] Trial 447 finished with value: 21.984203338623047 and parameters: {'n_layers': 1, 'input_chunk_length': 42, 'hidden_dim': 197, 'learning_rate': 3.4878749290143914e-07, 'batch_size': 64, 'training_length': 472}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 508 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:47,742] Trial 448 finished with value: 21.188982009887695 and parameters: {'n_layers': 2, 'dropout': 0.3143897521454982, 'input_chunk_length': 47, 'hidden_dim': 200, 'learning_rate': 2.2416963256171542e-07, 'batch_size': 64, 'training_length': 477}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 509 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:48,590] Trial 449 finished with value: 18.681617736816406 and parameters: {'n_layers': 1, 'input_chunk_length': 44, 'hidden_dim': 195, 'learning_rate': 2.8528799574332135e-07, 'batch_size': 64, 'training_length': 464}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 510 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:49,430] Trial 450 finished with value: 22.021251678466797 and parameters: {'n_layers': 1, 'input_chunk_length': 72, 'hidden_dim': 197, 'learning_rate': 1.9302269740572077e-07, 'batch_size': 64, 'training_length': 447}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 511 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:50,493] Trial 451 finished with value: 19.732831954956055 and parameters: {'n_layers': 1, 'input_chunk_length': 46, 'hidden_dim': 191, 'learning_rate': 2.3834299176829374e-07, 'batch_size': 64, 'training_length': 422}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 512 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:51,320] Trial 452 finished with value: 16.233823776245117 and parameters: {'n_layers': 1, 'input_chunk_length': 56, 'hidden_dim': 200, 'learning_rate': 1.695613933853928e-07, 'batch_size': 64, 'training_length': 437}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 513 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:52,167] Trial 453 finished with value: 20.809185028076172 and parameters: {'n_layers': 1, 'input_chunk_length': 60, 'hidden_dim': 194, 'learning_rate': 1.7698076150704848e-07, 'batch_size': 64, 'training_length': 461}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 514 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:53,002] Trial 454 finished with value: 21.980161666870117 and parameters: {'n_layers': 1, 'input_chunk_length': 56, 'hidden_dim': 197, 'learning_rate': 1.6649821028281494e-07, 'batch_size': 64, 'training_length': 434}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 515 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:53,815] Trial 455 finished with value: 16.848787307739258 and parameters: {'n_layers': 1, 'input_chunk_length': 55, 'hidden_dim': 200, 'learning_rate': 0.0004484381550144833, 'batch_size': 64, 'training_length': 403}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 516 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:54,733] Trial 456 finished with value: 27.5069637298584 and parameters: {'n_layers': 1, 'input_chunk_length': 57, 'hidden_dim': 142, 'learning_rate': 1.6816791352226326e-07, 'batch_size': 64, 'training_length': 453}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 517 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:55,588] Trial 457 finished with value: 21.986663818359375 and parameters: {'n_layers': 1, 'input_chunk_length': 43, 'hidden_dim': 197, 'learning_rate': 2.1959506346177514e-07, 'batch_size': 64, 'training_length': 476}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 518 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:56,421] Trial 458 finished with value: 20.80120086669922 and parameters: {'n_layers': 1, 'input_chunk_length': 55, 'hidden_dim': 194, 'learning_rate': 1.6092915382171558e-07, 'batch_size': 64, 'training_length': 428}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 519 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:57,254] Trial 459 finished with value: 16.234786987304688 and parameters: {'n_layers': 1, 'input_chunk_length': 53, 'hidden_dim': 200, 'learning_rate': 1.638895168624364e-07, 'batch_size': 64, 'training_length': 446}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 520 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:58,298] Trial 460 finished with value: 24.9550838470459 and parameters: {'n_layers': 1, 'input_chunk_length': 41, 'hidden_dim': 188, 'learning_rate': 2.18563779602867e-07, 'batch_size': 64, 'training_length': 412}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 521 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:32:59,147] Trial 461 finished with value: 21.98352813720703 and parameters: {'n_layers': 1, 'input_chunk_length': 45, 'hidden_dim': 197, 'learning_rate': 2.684458982488574e-07, 'batch_size': 64, 'training_length': 465}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 522 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:00,250] Trial 462 finished with value: 18.5887393951416 and parameters: {'n_layers': 1, 'input_chunk_length': 47, 'hidden_dim': 192, 'learning_rate': 1.4685401099153868e-07, 'batch_size': 64, 'training_length': 456}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 523 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:01,084] Trial 463 finished with value: 16.623355865478516 and parameters: {'n_layers': 1, 'input_chunk_length': 51, 'hidden_dim': 200, 'learning_rate': 0.00011882110455056397, 'batch_size': 64, 'training_length': 438}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 524 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:01,926] Trial 464 finished with value: 21.998048782348633 and parameters: {'n_layers': 1, 'input_chunk_length': 59, 'hidden_dim': 197, 'learning_rate': 1.8802390845901925e-07, 'batch_size': 64, 'training_length': 447}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 525 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:02,754] Trial 465 finished with value: 20.808855056762695 and parameters: {'n_layers': 1, 'input_chunk_length': 44, 'hidden_dim': 194, 'learning_rate': 1.448697479726703e-07, 'batch_size': 64, 'training_length': 421}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 526 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:04,139] Trial 466 finished with value: 16.243785858154297 and parameters: {'n_layers': 1, 'input_chunk_length': 57, 'hidden_dim': 200, 'learning_rate': 1.761850302135407e-07, 'batch_size': 16, 'training_length': 432}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 527 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:04,994] Trial 467 finished with value: 21.979507446289062 and parameters: {'n_layers': 1, 'input_chunk_length': 54, 'hidden_dim': 197, 'learning_rate': 1.3993449255900948e-07, 'batch_size': 64, 'training_length': 481}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 528 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:05,829] Trial 468 finished with value: 18.674978256225586 and parameters: {'n_layers': 1, 'input_chunk_length': 47, 'hidden_dim': 195, 'learning_rate': 2.2202878719642835e-07, 'batch_size': 64, 'training_length': 452}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 529 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:06,667] Trial 469 finished with value: 16.241884231567383 and parameters: {'n_layers': 1, 'input_chunk_length': 42, 'hidden_dim': 200, 'learning_rate': 2.9338051904626814e-07, 'batch_size': 64, 'training_length': 469}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 530 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:07,690] Trial 470 finished with value: 20.365638732910156 and parameters: {'n_layers': 1, 'input_chunk_length': 52, 'hidden_dim': 161, 'learning_rate': 1.5936374544167006e-07, 'batch_size': 64, 'training_length': 441}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 531 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:08,789] Trial 471 finished with value: 19.735166549682617 and parameters: {'n_layers': 1, 'input_chunk_length': 45, 'hidden_dim': 191, 'learning_rate': 1.0018711260062024e-07, 'batch_size': 64, 'training_length': 463}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 532 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:09,620] Trial 472 finished with value: 21.986387252807617 and parameters: {'n_layers': 1, 'input_chunk_length': 48, 'hidden_dim': 197, 'learning_rate': 1.9694934587130214e-07, 'batch_size': 64, 'training_length': 426}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 533 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:10,459] Trial 473 finished with value: 16.243209838867188 and parameters: {'n_layers': 1, 'input_chunk_length': 50, 'hidden_dim': 200, 'learning_rate': 1.3503812751360632e-07, 'batch_size': 64, 'training_length': 456}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 534 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:11,292] Trial 474 finished with value: 20.801515579223633 and parameters: {'n_layers': 1, 'input_chunk_length': 46, 'hidden_dim': 194, 'learning_rate': 1.3027107098601412e-07, 'batch_size': 64, 'training_length': 435}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 535 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:12,126] Trial 475 finished with value: 21.98670196533203 and parameters: {'n_layers': 1, 'input_chunk_length': 43, 'hidden_dim': 197, 'learning_rate': 1.566809323568461e-07, 'batch_size': 64, 'training_length': 418}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 536 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:12,972] Trial 476 finished with value: 21.97951316833496 and parameters: {'n_layers': 1, 'input_chunk_length': 54, 'hidden_dim': 197, 'learning_rate': 1.9817252754290777e-07, 'batch_size': 64, 'training_length': 447}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 537 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:14,354] Trial 477 finished with value: 16.234033584594727 and parameters: {'n_layers': 1, 'input_chunk_length': 51, 'hidden_dim': 200, 'learning_rate': 1.1847704336475361e-07, 'batch_size': 16, 'training_length': 439}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 538 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:16,064] Trial 478 finished with value: 18.590330123901367 and parameters: {'n_layers': 1, 'input_chunk_length': 56, 'hidden_dim': 192, 'learning_rate': 1.0045134347453592e-07, 'batch_size': 16, 'training_length': 459}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 539 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:16,935] Trial 479 finished with value: 22.652973175048828 and parameters: {'n_layers': 1, 'input_chunk_length': 63, 'hidden_dim': 103, 'learning_rate': 1.1489812189329216e-07, 'batch_size': 16, 'training_length': 447}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 540 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:18,394] Trial 480 finished with value: 18.679672241210938 and parameters: {'n_layers': 1, 'input_chunk_length': 51, 'hidden_dim': 195, 'learning_rate': 1.1951881161169938e-07, 'batch_size': 16, 'training_length': 469}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 541 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:19,771] Trial 481 finished with value: 19.02832794189453 and parameters: {'n_layers': 1, 'input_chunk_length': 54, 'hidden_dim': 149, 'learning_rate': 1.1939578908228787e-07, 'batch_size': 16, 'training_length': 444}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 542 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:21,158] Trial 482 finished with value: 16.65159797668457 and parameters: {'n_layers': 1, 'input_chunk_length': 52, 'hidden_dim': 200, 'learning_rate': 4.18456482111598e-05, 'batch_size': 16, 'training_length': 428}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 543 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:22,582] Trial 483 finished with value: 21.97955322265625 and parameters: {'n_layers': 1, 'input_chunk_length': 41, 'hidden_dim': 197, 'learning_rate': 1.3449233539064697e-07, 'batch_size': 16, 'training_length': 460}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 544 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:24,311] Trial 484 finished with value: 27.139266967773438 and parameters: {'n_layers': 1, 'input_chunk_length': 47, 'hidden_dim': 189, 'learning_rate': 1.0055165246411301e-07, 'batch_size': 16, 'training_length': 478}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 545 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:25,723] Trial 485 finished with value: 20.80739974975586 and parameters: {'n_layers': 1, 'input_chunk_length': 45, 'hidden_dim': 194, 'learning_rate': 3.562556601265745e-07, 'batch_size': 16, 'training_length': 453}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 546 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:27,107] Trial 486 finished with value: 16.239524841308594 and parameters: {'n_layers': 1, 'input_chunk_length': 58, 'hidden_dim': 200, 'learning_rate': 2.465935173996636e-07, 'batch_size': 16, 'training_length': 438}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 547 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:27,940] Trial 487 finished with value: 21.986454010009766 and parameters: {'n_layers': 1, 'input_chunk_length': 48, 'hidden_dim': 197, 'learning_rate': 1.709589973085664e-07, 'batch_size': 64, 'training_length': 430}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 548 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:28,774] Trial 488 finished with value: 16.23369598388672 and parameters: {'n_layers': 1, 'input_chunk_length': 51, 'hidden_dim': 200, 'learning_rate': 1.3856267815987296e-07, 'batch_size': 64, 'training_length': 451}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 549 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:31,776] Trial 489 finished with value: 24.21407127380371 and parameters: {'n_layers': 2, 'dropout': 0.2211260014451638, 'input_chunk_length': 52, 'hidden_dim': 192, 'learning_rate': 1.3707111870008726e-07, 'batch_size': 16, 'training_length': 443}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 550 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:32,628] Trial 490 finished with value: 21.979692459106445 and parameters: {'n_layers': 1, 'input_chunk_length': 54, 'hidden_dim': 197, 'learning_rate': 1.2790983927683079e-07, 'batch_size': 64, 'training_length': 452}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 551 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:33,470] Trial 491 finished with value: 18.681509017944336 and parameters: {'n_layers': 1, 'input_chunk_length': 50, 'hidden_dim': 195, 'learning_rate': 1.1850695454443672e-07, 'batch_size': 64, 'training_length': 438}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 552 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:34,314] Trial 492 finished with value: 16.23372459411621 and parameters: {'n_layers': 1, 'input_chunk_length': 51, 'hidden_dim': 200, 'learning_rate': 1.5012655766276486e-07, 'batch_size': 64, 'training_length': 451}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 553 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:35,157] Trial 493 finished with value: 21.980121612548828 and parameters: {'n_layers': 1, 'input_chunk_length': 56, 'hidden_dim': 197, 'learning_rate': 1.490999578306249e-07, 'batch_size': 64, 'training_length': 450}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 554 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:36,004] Trial 494 finished with value: 16.234682083129883 and parameters: {'n_layers': 1, 'input_chunk_length': 53, 'hidden_dim': 200, 'learning_rate': 1.1751525422623523e-07, 'batch_size': 64, 'training_length': 462}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 555 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:36,841] Trial 495 finished with value: 20.802318572998047 and parameters: {'n_layers': 1, 'input_chunk_length': 51, 'hidden_dim': 194, 'learning_rate': 1.0032002530054354e-07, 'batch_size': 64, 'training_length': 443}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 556 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:37,685] Trial 496 finished with value: 21.72991180419922 and parameters: {'n_layers': 1, 'input_chunk_length': 53, 'hidden_dim': 197, 'learning_rate': 0.00026793877900967573, 'batch_size': 64, 'training_length': 455}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 557 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:38,753] Trial 497 finished with value: 31.719005584716797 and parameters: {'n_layers': 1, 'input_chunk_length': 55, 'hidden_dim': 186, 'learning_rate': 1.4734376937188998e-07, 'batch_size': 64, 'training_length': 434}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 558 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:39,822] Trial 498 finished with value: 19.73383903503418 and parameters: {'n_layers': 1, 'input_chunk_length': 51, 'hidden_dim': 191, 'learning_rate': 1.1922383373656242e-07, 'batch_size': 64, 'training_length': 425}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 559 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:41,187] Trial 499 finished with value: 16.24408721923828 and parameters: {'n_layers': 1, 'input_chunk_length': 50, 'hidden_dim': 200, 'learning_rate': 1.645642375089178e-07, 'batch_size': 16, 'training_length': 414}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 560 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:42,031] Trial 500 finished with value: 21.986614227294922 and parameters: {'n_layers': 1, 'input_chunk_length': 57, 'hidden_dim': 197, 'learning_rate': 1.4152278864610216e-07, 'batch_size': 64, 'training_length': 448}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 561 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:42,867] Trial 501 finished with value: 20.808542251586914 and parameters: {'n_layers': 1, 'input_chunk_length': 60, 'hidden_dim': 194, 'learning_rate': 1.209528119769714e-07, 'batch_size': 64, 'training_length': 441}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 562 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:43,714] Trial 502 finished with value: 18.834354400634766 and parameters: {'n_layers': 1, 'input_chunk_length': 52, 'hidden_dim': 198, 'learning_rate': 1.6936399948383147e-07, 'batch_size': 64, 'training_length': 458}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 563 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:44,552] Trial 503 finished with value: 16.233430862426758 and parameters: {'n_layers': 1, 'input_chunk_length': 54, 'hidden_dim': 200, 'learning_rate': 1.3695749296322155e-07, 'batch_size': 64, 'training_length': 434}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 564 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:45,386] Trial 504 finished with value: 18.676254272460938 and parameters: {'n_layers': 1, 'input_chunk_length': 55, 'hidden_dim': 195, 'learning_rate': 1.8264394660379364e-07, 'batch_size': 64, 'training_length': 422}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 565 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:46,222] Trial 505 finished with value: 16.23343849182129 and parameters: {'n_layers': 1, 'input_chunk_length': 54, 'hidden_dim': 200, 'learning_rate': 1.4839280680429948e-07, 'batch_size': 64, 'training_length': 433}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 566 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:47,286] Trial 506 finished with value: 17.822635650634766 and parameters: {'n_layers': 1, 'input_chunk_length': 57, 'hidden_dim': 190, 'learning_rate': 1.4097768332544893e-07, 'batch_size': 64, 'training_length': 429}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 567 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:48,113] Trial 507 finished with value: 21.97977638244629 and parameters: {'n_layers': 1, 'input_chunk_length': 54, 'hidden_dim': 197, 'learning_rate': 1.422508482067377e-07, 'batch_size': 64, 'training_length': 412}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 568 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:49,460] Trial 508 finished with value: 29.247140884399414 and parameters: {'n_layers': 1, 'input_chunk_length': 56, 'hidden_dim': 193, 'learning_rate': 1.61951010936789e-07, 'batch_size': 16, 'training_length': 400}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 569 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:50,291] Trial 509 finished with value: 16.238441467285156 and parameters: {'n_layers': 1, 'input_chunk_length': 58, 'hidden_dim': 200, 'learning_rate': 1.3276447419521657e-07, 'batch_size': 64, 'training_length': 436}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 570 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:51,120] Trial 510 finished with value: 21.97964096069336 and parameters: {'n_layers': 1, 'input_chunk_length': 54, 'hidden_dim': 197, 'learning_rate': 1.1744449636708985e-07, 'batch_size': 64, 'training_length': 419}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 571 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:51,951] Trial 511 finished with value: 18.682649612426758 and parameters: {'n_layers': 1, 'input_chunk_length': 53, 'hidden_dim': 195, 'learning_rate': 1.6224742141383455e-07, 'batch_size': 64, 'training_length': 430}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 572 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:52,795] Trial 512 finished with value: 16.233461380004883 and parameters: {'n_layers': 1, 'input_chunk_length': 55, 'hidden_dim': 200, 'learning_rate': 1.3870480734620252e-07, 'batch_size': 64, 'training_length': 449}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 573 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:53,633] Trial 513 finished with value: 21.998193740844727 and parameters: {'n_layers': 1, 'input_chunk_length': 59, 'hidden_dim': 197, 'learning_rate': 1.1548697303239738e-07, 'batch_size': 64, 'training_length': 446}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 574 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:54,469] Trial 514 finished with value: 16.243297576904297 and parameters: {'n_layers': 1, 'input_chunk_length': 57, 'hidden_dim': 200, 'learning_rate': 1.4005849439668256e-07, 'batch_size': 64, 'training_length': 435}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 575 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:55,576] Trial 515 finished with value: 18.588632583618164 and parameters: {'n_layers': 1, 'input_chunk_length': 55, 'hidden_dim': 192, 'learning_rate': 1.1847639849424921e-07, 'batch_size': 64, 'training_length': 448}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 576 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:56,611] Trial 516 finished with value: 18.590356826782227 and parameters: {'n_layers': 1, 'input_chunk_length': 56, 'hidden_dim': 169, 'learning_rate': 1.4173085275516617e-07, 'batch_size': 64, 'training_length': 427}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 577 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:58,001] Trial 517 finished with value: 18.676288604736328 and parameters: {'n_layers': 1, 'input_chunk_length': 54, 'hidden_dim': 195, 'learning_rate': 1.1717410187396633e-07, 'batch_size': 16, 'training_length': 442}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 578 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:58,829] Trial 518 finished with value: 21.98640251159668 and parameters: {'n_layers': 1, 'input_chunk_length': 52, 'hidden_dim': 197, 'learning_rate': 1.006503286456392e-07, 'batch_size': 64, 'training_length': 420}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 579 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:33:59,668] Trial 519 finished with value: 16.23480224609375 and parameters: {'n_layers': 1, 'input_chunk_length': 53, 'hidden_dim': 200, 'learning_rate': 1.441400210774571e-07, 'batch_size': 64, 'training_length': 452}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 580 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:00,502] Trial 520 finished with value: 20.875808715820312 and parameters: {'n_layers': 1, 'input_chunk_length': 61, 'hidden_dim': 194, 'learning_rate': 1.731931498552623e-07, 'batch_size': 64, 'training_length': 434}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 581 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:01,081] Trial 521 finished with value: 18.323455810546875 and parameters: {'n_layers': 1, 'input_chunk_length': 58, 'hidden_dim': 51, 'learning_rate': 1.0036781182528657e-07, 'batch_size': 64, 'training_length': 453}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 582 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:02,180] Trial 522 finished with value: 27.13932991027832 and parameters: {'n_layers': 1, 'input_chunk_length': 55, 'hidden_dim': 189, 'learning_rate': 1.3281675188395635e-07, 'batch_size': 64, 'training_length': 441}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 583 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:03,037] Trial 523 finished with value: 21.986331939697266 and parameters: {'n_layers': 1, 'input_chunk_length': 52, 'hidden_dim': 197, 'learning_rate': 1.7147911078637297e-07, 'batch_size': 64, 'training_length': 427}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 584 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:03,873] Trial 524 finished with value: 16.233362197875977 and parameters: {'n_layers': 1, 'input_chunk_length': 55, 'hidden_dim': 200, 'learning_rate': 1.221658250594521e-07, 'batch_size': 64, 'training_length': 447}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 585 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:05,289] Trial 525 finished with value: 21.979372024536133 and parameters: {'n_layers': 1, 'input_chunk_length': 56, 'hidden_dim': 197, 'learning_rate': 1.4793686314172872e-07, 'batch_size': 16, 'training_length': 457}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 586 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:06,132] Trial 526 finished with value: 29.266857147216797 and parameters: {'n_layers': 1, 'input_chunk_length': 59, 'hidden_dim': 193, 'learning_rate': 1.835035035669733e-07, 'batch_size': 64, 'training_length': 452}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 587 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:06,966] Trial 527 finished with value: 16.233692169189453 and parameters: {'n_layers': 1, 'input_chunk_length': 56, 'hidden_dim': 200, 'learning_rate': 1.308906735466871e-07, 'batch_size': 64, 'training_length': 446}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 588 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:08,675] Trial 528 finished with value: 20.893741607666016 and parameters: {'n_layers': 2, 'dropout': 0.49945116840171, 'input_chunk_length': 57, 'hidden_dim': 180, 'learning_rate': 1.3170744983727252e-07, 'batch_size': 64, 'training_length': 439}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 589 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:09,524] Trial 529 finished with value: 21.979650497436523 and parameters: {'n_layers': 1, 'input_chunk_length': 55, 'hidden_dim': 197, 'learning_rate': 1.24758877661112e-07, 'batch_size': 64, 'training_length': 460}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 590 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:10,339] Trial 530 finished with value: 16.33314323425293 and parameters: {'n_layers': 1, 'input_chunk_length': 61, 'hidden_dim': 200, 'learning_rate': 1.4950563711385335e-07, 'batch_size': 64, 'training_length': 409}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 591 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:11,177] Trial 531 finished with value: 20.802465438842773 and parameters: {'n_layers': 1, 'input_chunk_length': 56, 'hidden_dim': 194, 'learning_rate': 1.1848674026514126e-07, 'batch_size': 64, 'training_length': 431}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 592 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:12,021] Trial 532 finished with value: 21.982681274414062 and parameters: {'n_layers': 1, 'input_chunk_length': 58, 'hidden_dim': 197, 'learning_rate': 1.1882092256580744e-07, 'batch_size': 64, 'training_length': 447}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 593 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:12,866] Trial 533 finished with value: 16.234827041625977 and parameters: {'n_layers': 1, 'input_chunk_length': 53, 'hidden_dim': 200, 'learning_rate': 1.5149255337360324e-07, 'batch_size': 64, 'training_length': 464}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 594 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:14,776] Trial 534 finished with value: 19.732192993164062 and parameters: {'n_layers': 1, 'input_chunk_length': 55, 'hidden_dim': 191, 'learning_rate': 1.3777037275238418e-07, 'batch_size': 16, 'training_length': 434}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 595 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:15,620] Trial 535 finished with value: 18.715808868408203 and parameters: {'n_layers': 1, 'input_chunk_length': 59, 'hidden_dim': 195, 'learning_rate': 1.0045817199172101e-07, 'batch_size': 64, 'training_length': 444}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 596 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:16,469] Trial 536 finished with value: 20.41324806213379 and parameters: {'n_layers': 1, 'input_chunk_length': 54, 'hidden_dim': 198, 'learning_rate': 0.0008881520310547039, 'batch_size': 64, 'training_length': 454}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 597 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:17,301] Trial 537 finished with value: 21.986364364624023 and parameters: {'n_layers': 1, 'input_chunk_length': 57, 'hidden_dim': 197, 'learning_rate': 1.6242919353457778e-07, 'batch_size': 64, 'training_length': 421}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 598 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:18,131] Trial 538 finished with value: 16.233402252197266 and parameters: {'n_layers': 1, 'input_chunk_length': 55, 'hidden_dim': 200, 'learning_rate': 1.2007994788016291e-07, 'batch_size': 64, 'training_length': 435}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 599 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:18,970] Trial 539 finished with value: 29.24476432800293 and parameters: {'n_layers': 1, 'input_chunk_length': 56, 'hidden_dim': 193, 'learning_rate': 1.786777855730503e-07, 'batch_size': 64, 'training_length': 423}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 600 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:19,801] Trial 540 finished with value: 16.261478424072266 and parameters: {'n_layers': 1, 'input_chunk_length': 59, 'hidden_dim': 200, 'learning_rate': 1.34396548719253e-07, 'batch_size': 64, 'training_length': 433}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 601 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:20,630] Trial 541 finished with value: 18.6762638092041 and parameters: {'n_layers': 1, 'input_chunk_length': 55, 'hidden_dim': 195, 'learning_rate': 1.179754499657392e-07, 'batch_size': 64, 'training_length': 408}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 602 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:21,476] Trial 542 finished with value: 21.98687744140625 and parameters: {'n_layers': 1, 'input_chunk_length': 62, 'hidden_dim': 197, 'learning_rate': 1.525974754613682e-07, 'batch_size': 64, 'training_length': 448}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 603 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:22,575] Trial 543 finished with value: 19.732515335083008 and parameters: {'n_layers': 1, 'input_chunk_length': 54, 'hidden_dim': 191, 'learning_rate': 1.9628172954368113e-07, 'batch_size': 64, 'training_length': 458}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 604 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:23,151] Trial 544 finished with value: 24.151023864746094 and parameters: {'n_layers': 1, 'input_chunk_length': 53, 'hidden_dim': 94, 'learning_rate': 1.2938407561396765e-07, 'batch_size': 64, 'training_length': 467}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 605 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:23,984] Trial 545 finished with value: 16.2431697845459 and parameters: {'n_layers': 1, 'input_chunk_length': 57, 'hidden_dim': 200, 'learning_rate': 1.0008788532354954e-07, 'batch_size': 64, 'training_length': 439}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 606 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:24,823] Trial 546 finished with value: 18.672807693481445 and parameters: {'n_layers': 1, 'input_chunk_length': 58, 'hidden_dim': 195, 'learning_rate': 1.5649225288572532e-07, 'batch_size': 64, 'training_length': 428}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 607 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:25,876] Trial 547 finished with value: 25.011375427246094 and parameters: {'n_layers': 1, 'input_chunk_length': 55, 'hidden_dim': 188, 'learning_rate': 9.98775928656938e-06, 'batch_size': 64, 'training_length': 416}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 608 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:26,486] Trial 548 finished with value: 18.386924743652344 and parameters: {'n_layers': 1, 'input_chunk_length': 40, 'hidden_dim': 126, 'learning_rate': 1.212660737862531e-07, 'batch_size': 64, 'training_length': 387}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 609 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:27,066] Trial 549 finished with value: 18.266483306884766 and parameters: {'n_layers': 1, 'input_chunk_length': 53, 'hidden_dim': 74, 'learning_rate': 1.7435316412118875e-07, 'batch_size': 64, 'training_length': 451}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 610 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:27,906] Trial 550 finished with value: 21.986495971679688 and parameters: {'n_layers': 1, 'input_chunk_length': 60, 'hidden_dim': 197, 'learning_rate': 1.379791006465083e-07, 'batch_size': 64, 'training_length': 442}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 611 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:28,753] Trial 551 finished with value: 16.233694076538086 and parameters: {'n_layers': 1, 'input_chunk_length': 56, 'hidden_dim': 200, 'learning_rate': 1.1635177594506183e-07, 'batch_size': 64, 'training_length': 461}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 612 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:29,604] Trial 552 finished with value: 18.828319549560547 and parameters: {'n_layers': 1, 'input_chunk_length': 56, 'hidden_dim': 198, 'learning_rate': 1.782715897497941e-07, 'batch_size': 64, 'training_length': 462}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 613 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:30,461] Trial 553 finished with value: 29.242292404174805 and parameters: {'n_layers': 1, 'input_chunk_length': 58, 'hidden_dim': 193, 'learning_rate': 1.4687511747007557e-07, 'batch_size': 64, 'training_length': 469}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 614 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:31,301] Trial 554 finished with value: 16.243452072143555 and parameters: {'n_layers': 1, 'input_chunk_length': 57, 'hidden_dim': 200, 'learning_rate': 2.1086977345058728e-07, 'batch_size': 64, 'training_length': 456}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 615 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:32,163] Trial 555 finished with value: 18.67629051208496 and parameters: {'n_layers': 1, 'input_chunk_length': 55, 'hidden_dim': 195, 'learning_rate': 1.5277173187190193e-07, 'batch_size': 64, 'training_length': 467}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 616 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:33,010] Trial 556 finished with value: 21.98641014099121 and parameters: {'n_layers': 1, 'input_chunk_length': 60, 'hidden_dim': 197, 'learning_rate': 1.2039394558127334e-07, 'batch_size': 64, 'training_length': 455}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 617 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:33,846] Trial 557 finished with value: 16.233789443969727 and parameters: {'n_layers': 1, 'input_chunk_length': 56, 'hidden_dim': 200, 'learning_rate': 1.7216095945494128e-07, 'batch_size': 64, 'training_length': 432}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 618 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:34,936] Trial 558 finished with value: 18.5969181060791 and parameters: {'n_layers': 1, 'input_chunk_length': 57, 'hidden_dim': 192, 'learning_rate': 1.336470285146018e-07, 'batch_size': 64, 'training_length': 433}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 619 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:35,784] Trial 559 finished with value: 21.98649024963379 and parameters: {'n_layers': 1, 'input_chunk_length': 80, 'hidden_dim': 197, 'learning_rate': 1.8400077827945215e-07, 'batch_size': 64, 'training_length': 446}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 620 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:36,618] Trial 560 finished with value: 16.243417739868164 and parameters: {'n_layers': 1, 'input_chunk_length': 63, 'hidden_dim': 200, 'learning_rate': 1.5799020067530621e-07, 'batch_size': 64, 'training_length': 438}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 621 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:37,465] Trial 561 finished with value: 18.676599502563477 and parameters: {'n_layers': 1, 'input_chunk_length': 54, 'hidden_dim': 195, 'learning_rate': 1.2061293890541894e-07, 'batch_size': 64, 'training_length': 451}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 622 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:38,314] Trial 562 finished with value: 16.261478424072266 and parameters: {'n_layers': 1, 'input_chunk_length': 59, 'hidden_dim': 200, 'learning_rate': 1.3904674238708128e-07, 'batch_size': 64, 'training_length': 460}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 623 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:39,155] Trial 563 finished with value: 21.98063850402832 and parameters: {'n_layers': 1, 'input_chunk_length': 53, 'hidden_dim': 197, 'learning_rate': 1.636719676878966e-07, 'batch_size': 64, 'training_length': 427}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 624 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:39,993] Trial 564 finished with value: 20.802608489990234 and parameters: {'n_layers': 1, 'input_chunk_length': 56, 'hidden_dim': 194, 'learning_rate': 1.15834121879288e-07, 'batch_size': 64, 'training_length': 445}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 625 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:40,973] Trial 565 finished with value: 19.56377601623535 and parameters: {'n_layers': 1, 'input_chunk_length': 52, 'hidden_dim': 157, 'learning_rate': 1.9619752341919018e-07, 'batch_size': 64, 'training_length': 474}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 626 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:42,056] Trial 566 finished with value: 27.142213821411133 and parameters: {'n_layers': 1, 'input_chunk_length': 58, 'hidden_dim': 189, 'learning_rate': 1.3852061639062553e-07, 'batch_size': 64, 'training_length': 435}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 627 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:42,908] Trial 567 finished with value: 21.97970962524414 and parameters: {'n_layers': 1, 'input_chunk_length': 54, 'hidden_dim': 197, 'learning_rate': 1.1484116218099304e-07, 'batch_size': 64, 'training_length': 452}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 628 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:43,758] Trial 568 finished with value: 16.233795166015625 and parameters: {'n_layers': 1, 'input_chunk_length': 56, 'hidden_dim': 200, 'learning_rate': 1.5761643888636416e-07, 'batch_size': 64, 'training_length': 463}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 629 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:45,068] Trial 569 finished with value: 22.21319580078125 and parameters: {'n_layers': 2, 'dropout': 0.2625315384280978, 'input_chunk_length': 41, 'hidden_dim': 193, 'learning_rate': 1.369202201868925e-07, 'batch_size': 64, 'training_length': 481}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 630 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:45,924] Trial 570 finished with value: 21.986515045166016 and parameters: {'n_layers': 1, 'input_chunk_length': 52, 'hidden_dim': 197, 'learning_rate': 1.1387230273005304e-07, 'batch_size': 64, 'training_length': 469}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 631 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:46,770] Trial 571 finished with value: 16.23365592956543 and parameters: {'n_layers': 1, 'input_chunk_length': 56, 'hidden_dim': 200, 'learning_rate': 1.0050278577945519e-07, 'batch_size': 64, 'training_length': 463}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 632 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:47,656] Trial 572 finished with value: 16.24321937561035 and parameters: {'n_layers': 1, 'input_chunk_length': 60, 'hidden_dim': 200, 'learning_rate': 1.0015215644756688e-07, 'batch_size': 64, 'training_length': 478}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 633 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:48,537] Trial 573 finished with value: 21.979660034179688 and parameters: {'n_layers': 1, 'input_chunk_length': 54, 'hidden_dim': 197, 'learning_rate': 1.0208163243421854e-07, 'batch_size': 64, 'training_length': 472}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 634 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:49,620] Trial 574 finished with value: 24.030563354492188 and parameters: {'n_layers': 1, 'input_chunk_length': 40, 'hidden_dim': 184, 'learning_rate': 1.1513597156262763e-07, 'batch_size': 64, 'training_length': 464}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 635 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:50,473] Trial 575 finished with value: 20.799619674682617 and parameters: {'n_layers': 1, 'input_chunk_length': 58, 'hidden_dim': 194, 'learning_rate': 1.2855470006511518e-07, 'batch_size': 64, 'training_length': 462}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 636 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:51,328] Trial 576 finished with value: 21.979772567749023 and parameters: {'n_layers': 1, 'input_chunk_length': 55, 'hidden_dim': 197, 'learning_rate': 1.1369439972174063e-07, 'batch_size': 64, 'training_length': 466}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 637 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:51,915] Trial 577 finished with value: 19.813108444213867 and parameters: {'n_layers': 1, 'input_chunk_length': 51, 'hidden_dim': 63, 'learning_rate': 1.3883838474757689e-07, 'batch_size': 64, 'training_length': 483}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 638 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:52,533] Trial 578 finished with value: 22.023324966430664 and parameters: {'n_layers': 1, 'input_chunk_length': 53, 'hidden_dim': 114, 'learning_rate': 1.0050355325605163e-07, 'batch_size': 64, 'training_length': 459}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 639 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:53,644] Trial 579 finished with value: 19.74184799194336 and parameters: {'n_layers': 1, 'input_chunk_length': 57, 'hidden_dim': 191, 'learning_rate': 1.3441497712351088e-07, 'batch_size': 64, 'training_length': 469}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 640 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:54,514] Trial 580 finished with value: 16.241432189941406 and parameters: {'n_layers': 1, 'input_chunk_length': 42, 'hidden_dim': 200, 'learning_rate': 1.0065313007188005e-07, 'batch_size': 64, 'training_length': 488}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 641 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:55,367] Trial 581 finished with value: 18.67641258239746 and parameters: {'n_layers': 1, 'input_chunk_length': 55, 'hidden_dim': 195, 'learning_rate': 1.5547564677296812e-07, 'batch_size': 64, 'training_length': 455}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 642 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:56,214] Trial 582 finished with value: 16.333030700683594 and parameters: {'n_layers': 1, 'input_chunk_length': 61, 'hidden_dim': 200, 'learning_rate': 1.2014696255583487e-07, 'batch_size': 64, 'training_length': 459}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 643 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:57,077] Trial 583 finished with value: 21.979930877685547 and parameters: {'n_layers': 1, 'input_chunk_length': 51, 'hidden_dim': 197, 'learning_rate': 1.538443072273167e-07, 'batch_size': 64, 'training_length': 473}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 644 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:57,930] Trial 584 finished with value: 20.80432891845703 and parameters: {'n_layers': 1, 'input_chunk_length': 53, 'hidden_dim': 194, 'learning_rate': 1.3086406801002258e-07, 'batch_size': 64, 'training_length': 458}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 645 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:58,783] Trial 585 finished with value: 18.83407974243164 and parameters: {'n_layers': 1, 'input_chunk_length': 57, 'hidden_dim': 198, 'learning_rate': 1.1644732245958441e-07, 'batch_size': 64, 'training_length': 448}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 646 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:34:59,880] Trial 586 finished with value: 19.732419967651367 and parameters: {'n_layers': 1, 'input_chunk_length': 55, 'hidden_dim': 191, 'learning_rate': 1.5523006884016195e-07, 'batch_size': 64, 'training_length': 450}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 647 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:00,738] Trial 587 finished with value: 16.2430419921875 and parameters: {'n_layers': 1, 'input_chunk_length': 43, 'hidden_dim': 200, 'learning_rate': 1.2528647140902563e-07, 'batch_size': 64, 'training_length': 477}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 648 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:01,594] Trial 588 finished with value: 18.68165397644043 and parameters: {'n_layers': 1, 'input_chunk_length': 52, 'hidden_dim': 195, 'learning_rate': 1.0032633872231853e-07, 'batch_size': 64, 'training_length': 464}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 649 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:02,443] Trial 589 finished with value: 21.982839584350586 and parameters: {'n_layers': 1, 'input_chunk_length': 58, 'hidden_dim': 197, 'learning_rate': 1.7575635371372575e-07, 'batch_size': 64, 'training_length': 443}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 650 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:03,289] Trial 590 finished with value: 16.233396530151367 and parameters: {'n_layers': 1, 'input_chunk_length': 54, 'hidden_dim': 200, 'learning_rate': 1.435811092132171e-07, 'batch_size': 64, 'training_length': 456}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 651 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:04,381] Trial 591 finished with value: 18.596952438354492 and parameters: {'n_layers': 1, 'input_chunk_length': 50, 'hidden_dim': 192, 'learning_rate': 1.3502585980404624e-07, 'batch_size': 64, 'training_length': 426}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 652 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:05,231] Trial 592 finished with value: 21.98060417175293 and parameters: {'n_layers': 1, 'input_chunk_length': 53, 'hidden_dim': 197, 'learning_rate': 1.1603627461707336e-07, 'batch_size': 64, 'training_length': 451}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 653 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:06,067] Trial 593 finished with value: 16.251529693603516 and parameters: {'n_layers': 1, 'input_chunk_length': 51, 'hidden_dim': 200, 'learning_rate': 7.2410563177601475e-06, 'batch_size': 64, 'training_length': 437}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 654 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:06,913] Trial 594 finished with value: 19.026697158813477 and parameters: {'n_layers': 1, 'input_chunk_length': 67, 'hidden_dim': 195, 'learning_rate': 0.00016169370351126354, 'batch_size': 64, 'training_length': 445}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 655 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:07,978] Trial 595 finished with value: 24.954275131225586 and parameters: {'n_layers': 1, 'input_chunk_length': 54, 'hidden_dim': 188, 'learning_rate': 1.9506008411973215e-07, 'batch_size': 64, 'training_length': 429}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 656 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:08,813] Trial 596 finished with value: 21.980018615722656 and parameters: {'n_layers': 1, 'input_chunk_length': 41, 'hidden_dim': 197, 'learning_rate': 1.0058119944447037e-07, 'batch_size': 64, 'training_length': 421}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 657 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:09,656] Trial 597 finished with value: 16.24329948425293 and parameters: {'n_layers': 1, 'input_chunk_length': 52, 'hidden_dim': 200, 'learning_rate': 1.3900356781644832e-07, 'batch_size': 64, 'training_length': 455}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 658 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:10,512] Trial 598 finished with value: 20.808683395385742 and parameters: {'n_layers': 1, 'input_chunk_length': 39, 'hidden_dim': 194, 'learning_rate': 1.521528816215545e-07, 'batch_size': 64, 'training_length': 474}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 659 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:11,356] Trial 599 finished with value: 21.979616165161133 and parameters: {'n_layers': 1, 'input_chunk_length': 54, 'hidden_dim': 197, 'learning_rate': 1.1937385425913143e-07, 'batch_size': 64, 'training_length': 440}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 660 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:12,203] Trial 600 finished with value: 16.243104934692383 and parameters: {'n_layers': 1, 'input_chunk_length': 43, 'hidden_dim': 200, 'learning_rate': 1.342400810014939e-07, 'batch_size': 64, 'training_length': 454}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 661 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:13,310] Trial 601 finished with value: 18.589900970458984 and parameters: {'n_layers': 1, 'input_chunk_length': 56, 'hidden_dim': 192, 'learning_rate': 1.925559985974727e-07, 'batch_size': 64, 'training_length': 445}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 662 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:14,160] Trial 602 finished with value: 21.986486434936523 and parameters: {'n_layers': 1, 'input_chunk_length': 50, 'hidden_dim': 197, 'learning_rate': 1.5986063480963938e-07, 'batch_size': 64, 'training_length': 433}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 663 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:15,013] Trial 603 finished with value: 16.2431583404541 and parameters: {'n_layers': 1, 'input_chunk_length': 52, 'hidden_dim': 200, 'learning_rate': 1.1545660808689301e-07, 'batch_size': 64, 'training_length': 462}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 664 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:15,868] Trial 604 finished with value: 18.71585464477539 and parameters: {'n_layers': 1, 'input_chunk_length': 59, 'hidden_dim': 195, 'learning_rate': 1.3390823724183876e-07, 'batch_size': 64, 'training_length': 451}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 665 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:16,712] Trial 605 finished with value: 21.979509353637695 and parameters: {'n_layers': 1, 'input_chunk_length': 55, 'hidden_dim': 197, 'learning_rate': 1.7806778638370457e-07, 'batch_size': 64, 'training_length': 440}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 666 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:17,561] Trial 606 finished with value: 29.242860794067383 and parameters: {'n_layers': 1, 'input_chunk_length': 54, 'hidden_dim': 193, 'learning_rate': 1.0120306944318455e-07, 'batch_size': 64, 'training_length': 453}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 667 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:18,414] Trial 607 finished with value: 16.243249893188477 and parameters: {'n_layers': 1, 'input_chunk_length': 50, 'hidden_dim': 200, 'learning_rate': 1.5202252827572e-07, 'batch_size': 64, 'training_length': 469}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 668 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:19,256] Trial 608 finished with value: 21.986478805541992 and parameters: {'n_layers': 1, 'input_chunk_length': 57, 'hidden_dim': 197, 'learning_rate': 1.1919363289675108e-07, 'batch_size': 64, 'training_length': 431}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 669 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:20,498] Trial 609 finished with value: 23.949626922607422 and parameters: {'n_layers': 2, 'dropout': 0.11179336720169342, 'input_chunk_length': 43, 'hidden_dim': 194, 'learning_rate': 1.0041074885970825e-07, 'batch_size': 64, 'training_length': 421}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 670 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:21,335] Trial 610 finished with value: 16.234947204589844 and parameters: {'n_layers': 1, 'input_chunk_length': 53, 'hidden_dim': 200, 'learning_rate': 2.060801772775695e-07, 'batch_size': 64, 'training_length': 444}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 671 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:22,445] Trial 611 finished with value: 17.8153018951416 and parameters: {'n_layers': 1, 'input_chunk_length': 51, 'hidden_dim': 190, 'learning_rate': 1.355257611159858e-07, 'batch_size': 64, 'training_length': 462}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 672 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:23,285] Trial 612 finished with value: 18.681482315063477 and parameters: {'n_layers': 1, 'input_chunk_length': 57, 'hidden_dim': 195, 'learning_rate': 1.6355233796059228e-07, 'batch_size': 64, 'training_length': 437}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 673 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:24,141] Trial 613 finished with value: 18.980281829833984 and parameters: {'n_layers': 1, 'input_chunk_length': 91, 'hidden_dim': 198, 'learning_rate': 3.220134872661451e-05, 'batch_size': 64, 'training_length': 449}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 674 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:25,005] Trial 614 finished with value: 16.23356819152832 and parameters: {'n_layers': 1, 'input_chunk_length': 41, 'hidden_dim': 200, 'learning_rate': 1.229146886184142e-07, 'batch_size': 64, 'training_length': 483}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 675 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:25,880] Trial 615 finished with value: 21.98650550842285 and parameters: {'n_layers': 1, 'input_chunk_length': 39, 'hidden_dim': 197, 'learning_rate': 1.1729575740474952e-07, 'batch_size': 64, 'training_length': 492}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 676 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:26,745] Trial 616 finished with value: 20.80048370361328 and parameters: {'n_layers': 1, 'input_chunk_length': 42, 'hidden_dim': 194, 'learning_rate': 1.1738194573824693e-07, 'batch_size': 64, 'training_length': 486}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 677 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:27,843] Trial 617 finished with value: 18.15804100036621 and parameters: {'n_layers': 1, 'input_chunk_length': 41, 'hidden_dim': 177, 'learning_rate': 1.0052762655859231e-07, 'batch_size': 64, 'training_length': 481}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 678 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:28,710] Trial 618 finished with value: 16.309173583984375 and parameters: {'n_layers': 1, 'input_chunk_length': 40, 'hidden_dim': 200, 'learning_rate': 1.3426907072537753e-07, 'batch_size': 64, 'training_length': 492}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 679 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:29,570] Trial 619 finished with value: 21.9866943359375 and parameters: {'n_layers': 1, 'input_chunk_length': 44, 'hidden_dim': 197, 'learning_rate': 1.1799983730011303e-07, 'batch_size': 64, 'training_length': 477}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 680 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:30,677] Trial 620 finished with value: 18.18351173400879 and parameters: {'n_layers': 1, 'input_chunk_length': 40, 'hidden_dim': 187, 'learning_rate': 1.454420163258167e-07, 'batch_size': 64, 'training_length': 473}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 681 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:31,815] Trial 621 finished with value: 19.7362003326416 and parameters: {'n_layers': 1, 'input_chunk_length': 42, 'hidden_dim': 191, 'learning_rate': 1.0059399505033561e-07, 'batch_size': 64, 'training_length': 493}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 682 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:32,681] Trial 622 finished with value: 21.986648559570312 and parameters: {'n_layers': 1, 'input_chunk_length': 44, 'hidden_dim': 197, 'learning_rate': 1.316338838399401e-07, 'batch_size': 64, 'training_length': 466}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 683 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:33,569] Trial 623 finished with value: 16.243059158325195 and parameters: {'n_layers': 1, 'input_chunk_length': 39, 'hidden_dim': 200, 'learning_rate': 1.196842601606083e-07, 'batch_size': 64, 'training_length': 468}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 684 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:34,463] Trial 624 finished with value: 20.800201416015625 and parameters: {'n_layers': 1, 'input_chunk_length': 49, 'hidden_dim': 194, 'learning_rate': 1.493330773910864e-07, 'batch_size': 64, 'training_length': 485}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 685 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:35,320] Trial 625 finished with value: 21.979982376098633 and parameters: {'n_layers': 1, 'input_chunk_length': 41, 'hidden_dim': 197, 'learning_rate': 1.1968590436926796e-07, 'batch_size': 64, 'training_length': 460}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 686 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:36,166] Trial 626 finished with value: 16.239967346191406 and parameters: {'n_layers': 1, 'input_chunk_length': 45, 'hidden_dim': 200, 'learning_rate': 1.5377686436725384e-07, 'batch_size': 64, 'training_length': 457}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 687 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:37,298] Trial 627 finished with value: 18.597543716430664 and parameters: {'n_layers': 1, 'input_chunk_length': 43, 'hidden_dim': 192, 'learning_rate': 1.938596359602966e-07, 'batch_size': 64, 'training_length': 479}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 688 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:38,150] Trial 628 finished with value: 18.68157196044922 and parameters: {'n_layers': 1, 'input_chunk_length': 50, 'hidden_dim': 195, 'learning_rate': 1.3400848005611547e-07, 'batch_size': 64, 'training_length': 455}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 689 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:39,010] Trial 629 finished with value: 21.983755111694336 and parameters: {'n_layers': 1, 'input_chunk_length': 45, 'hidden_dim': 197, 'learning_rate': 1.1764467652842743e-07, 'batch_size': 64, 'training_length': 469}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 690 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:40,068] Trial 630 finished with value: 16.243610382080078 and parameters: {'n_layers': 1, 'input_chunk_length': 52, 'hidden_dim': 200, 'learning_rate': 1.6516280633596966e-07, 'batch_size': 32, 'training_length': 445}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 691 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:40,920] Trial 631 finished with value: 21.979501724243164 and parameters: {'n_layers': 1, 'input_chunk_length': 54, 'hidden_dim': 197, 'learning_rate': 1.3952936757973252e-07, 'batch_size': 64, 'training_length': 451}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 692 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:41,767] Trial 632 finished with value: 16.49993133544922 and parameters: {'n_layers': 1, 'input_chunk_length': 49, 'hidden_dim': 200, 'learning_rate': 8.611383659584062e-05, 'batch_size': 64, 'training_length': 458}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 693 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:42,684] Trial 633 finished with value: 30.01399803161621 and parameters: {'n_layers': 1, 'input_chunk_length': 52, 'hidden_dim': 137, 'learning_rate': 1.0086663648905102e-07, 'batch_size': 64, 'training_length': 443}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 694 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:43,543] Trial 634 finished with value: 20.809873580932617 and parameters: {'n_layers': 1, 'input_chunk_length': 38, 'hidden_dim': 194, 'learning_rate': 1.1687747191843165e-07, 'batch_size': 64, 'training_length': 471}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 695 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:44,172] Trial 635 finished with value: 24.663021087646484 and parameters: {'n_layers': 1, 'input_chunk_length': 42, 'hidden_dim': 99, 'learning_rate': 2.0679410842492412e-07, 'batch_size': 64, 'training_length': 462}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 696 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:45,257] Trial 636 finished with value: 17.82280921936035 and parameters: {'n_layers': 1, 'input_chunk_length': 44, 'hidden_dim': 190, 'learning_rate': 1.655563191492263e-07, 'batch_size': 64, 'training_length': 437}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 697 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:46,110] Trial 637 finished with value: 21.979835510253906 and parameters: {'n_layers': 1, 'input_chunk_length': 54, 'hidden_dim': 197, 'learning_rate': 1.0104807342884044e-07, 'batch_size': 64, 'training_length': 450}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 698 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:46,947] Trial 638 finished with value: 16.24323844909668 and parameters: {'n_layers': 1, 'input_chunk_length': 50, 'hidden_dim': 200, 'learning_rate': 1.3184755507024836e-07, 'batch_size': 64, 'training_length': 438}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 699 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:47,809] Trial 639 finished with value: 18.715726852416992 and parameters: {'n_layers': 1, 'input_chunk_length': 59, 'hidden_dim': 195, 'learning_rate': 1.5099468366976258e-07, 'batch_size': 64, 'training_length': 500}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 700 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:48,655] Trial 640 finished with value: 21.9835205078125 and parameters: {'n_layers': 1, 'input_chunk_length': 45, 'hidden_dim': 197, 'learning_rate': 1.851466735038921e-07, 'batch_size': 64, 'training_length': 424}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 701 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:49,239] Trial 641 finished with value: 24.043746948242188 and parameters: {'n_layers': 1, 'input_chunk_length': 53, 'hidden_dim': 81, 'learning_rate': 1.3216843682531424e-07, 'batch_size': 64, 'training_length': 447}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 702 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:50,512] Trial 642 finished with value: 18.58910369873047 and parameters: {'n_layers': 1, 'input_chunk_length': 55, 'hidden_dim': 192, 'learning_rate': 1.1886869700257371e-07, 'batch_size': 32, 'training_length': 456}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 703 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:51,345] Trial 643 finished with value: 16.243263244628906 and parameters: {'n_layers': 1, 'input_chunk_length': 48, 'hidden_dim': 200, 'learning_rate': 1.5349945365134136e-07, 'batch_size': 64, 'training_length': 415}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 704 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:52,641] Trial 644 finished with value: 20.937938690185547 and parameters: {'n_layers': 2, 'dropout': 0.4514832427014408, 'input_chunk_length': 52, 'hidden_dim': 197, 'learning_rate': 2.25847346181206e-07, 'batch_size': 64, 'training_length': 463}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 705 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:53,484] Trial 645 finished with value: 20.802377700805664 and parameters: {'n_layers': 1, 'input_chunk_length': 56, 'hidden_dim': 194, 'learning_rate': 1.0043494594837186e-07, 'batch_size': 64, 'training_length': 443}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 706 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:54,326] Trial 646 finished with value: 16.393869400024414 and parameters: {'n_layers': 1, 'input_chunk_length': 51, 'hidden_dim': 200, 'learning_rate': 5.578946401182499e-05, 'batch_size': 64, 'training_length': 430}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 707 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:55,200] Trial 647 finished with value: 21.979711532592773 and parameters: {'n_layers': 1, 'input_chunk_length': 46, 'hidden_dim': 197, 'learning_rate': 1.7442989654739364e-07, 'batch_size': 64, 'training_length': 483}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 708 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:56,660] Trial 648 finished with value: 20.860980987548828 and parameters: {'n_layers': 1, 'input_chunk_length': 40, 'hidden_dim': 194, 'learning_rate': 1.3324114436483587e-07, 'batch_size': 16, 'training_length': 474}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 709 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:57,502] Trial 649 finished with value: 16.23420524597168 and parameters: {'n_layers': 1, 'input_chunk_length': 49, 'hidden_dim': 200, 'learning_rate': 1.1735261365735333e-07, 'batch_size': 64, 'training_length': 452}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 710 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:58,626] Trial 650 finished with value: 27.104352951049805 and parameters: {'n_layers': 1, 'input_chunk_length': 10, 'hidden_dim': 189, 'learning_rate': 2.3570091897666495e-05, 'batch_size': 64, 'training_length': 485}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 711 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:35:59,472] Trial 651 finished with value: 21.984771728515625 and parameters: {'n_layers': 1, 'input_chunk_length': 42, 'hidden_dim': 197, 'learning_rate': 1.4924702218483843e-07, 'batch_size': 64, 'training_length': 432}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 712 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:00,579] Trial 652 finished with value: 18.59385871887207 and parameters: {'n_layers': 1, 'input_chunk_length': 62, 'hidden_dim': 192, 'learning_rate': 1.7971331747990992e-07, 'batch_size': 64, 'training_length': 443}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 713 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:01,436] Trial 653 finished with value: 18.825986862182617 and parameters: {'n_layers': 1, 'input_chunk_length': 54, 'hidden_dim': 198, 'learning_rate': 1.0023138300950685e-07, 'batch_size': 64, 'training_length': 460}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 714 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:02,503] Trial 654 finished with value: 16.243398666381836 and parameters: {'n_layers': 1, 'input_chunk_length': 57, 'hidden_dim': 200, 'learning_rate': 1.2207275534701862e-07, 'batch_size': 32, 'training_length': 451}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 715 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:03,347] Trial 655 finished with value: 20.80294418334961 and parameters: {'n_layers': 1, 'input_chunk_length': 51, 'hidden_dim': 194, 'learning_rate': 1.418236766386618e-07, 'batch_size': 64, 'training_length': 438}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 716 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:04,214] Trial 656 finished with value: 21.979522705078125 and parameters: {'n_layers': 1, 'input_chunk_length': 55, 'hidden_dim': 197, 'learning_rate': 1.9101250680188201e-07, 'batch_size': 64, 'training_length': 467}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 717 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:04,965] Trial 657 finished with value: 16.261375427246094 and parameters: {'n_layers': 1, 'input_chunk_length': 59, 'hidden_dim': 200, 'learning_rate': 1.1587984293137235e-07, 'batch_size': 64, 'training_length': 269}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 718 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:05,800] Trial 658 finished with value: 18.681488037109375 and parameters: {'n_layers': 1, 'input_chunk_length': 44, 'hidden_dim': 195, 'learning_rate': 1.5107542508777853e-07, 'batch_size': 64, 'training_length': 419}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 719 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:06,652] Trial 659 finished with value: 18.83453369140625 and parameters: {'n_layers': 1, 'input_chunk_length': 48, 'hidden_dim': 198, 'learning_rate': 2.2505119269548584e-07, 'batch_size': 64, 'training_length': 457}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 720 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:08,318] Trial 660 finished with value: 17.54451560974121 and parameters: {'n_layers': 1, 'input_chunk_length': 53, 'hidden_dim': 185, 'learning_rate': 1.3375595469188784e-07, 'batch_size': 16, 'training_length': 445}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 721 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:09,159] Trial 661 finished with value: 18.68035125732422 and parameters: {'n_layers': 1, 'input_chunk_length': 41, 'hidden_dim': 195, 'learning_rate': 1.6081348167173728e-07, 'batch_size': 64, 'training_length': 427}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 722 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:10,015] Trial 662 finished with value: 16.233238220214844 and parameters: {'n_layers': 1, 'input_chunk_length': 46, 'hidden_dim': 200, 'learning_rate': 1.175751521663364e-07, 'batch_size': 64, 'training_length': 471}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 723 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:11,143] Trial 663 finished with value: 19.74294090270996 and parameters: {'n_layers': 1, 'input_chunk_length': 38, 'hidden_dim': 191, 'learning_rate': 1.1519672125506264e-07, 'batch_size': 64, 'training_length': 480}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 724 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:12,000] Trial 664 finished with value: 16.243457794189453 and parameters: {'n_layers': 1, 'input_chunk_length': 99, 'hidden_dim': 200, 'learning_rate': 1.1397026958457343e-07, 'batch_size': 64, 'training_length': 465}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 725 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:12,865] Trial 665 finished with value: 21.980026245117188 and parameters: {'n_layers': 1, 'input_chunk_length': 56, 'hidden_dim': 197, 'learning_rate': 1.0073317423657277e-07, 'batch_size': 64, 'training_length': 476}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 726 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:13,729] Trial 666 finished with value: 18.681509017944336 and parameters: {'n_layers': 1, 'input_chunk_length': 50, 'hidden_dim': 195, 'learning_rate': 1.0098210769109387e-07, 'batch_size': 64, 'training_length': 473}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 727 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:14,359] Trial 667 finished with value: 24.916393280029297 and parameters: {'n_layers': 1, 'input_chunk_length': 53, 'hidden_dim': 122, 'learning_rate': 1.2575659786220394e-07, 'batch_size': 64, 'training_length': 470}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 728 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:15,324] Trial 668 finished with value: 20.3760929107666 and parameters: {'n_layers': 1, 'input_chunk_length': 43, 'hidden_dim': 151, 'learning_rate': 1.3441072934612466e-07, 'batch_size': 64, 'training_length': 479}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 729 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:16,183] Trial 669 finished with value: 21.9826717376709 and parameters: {'n_layers': 1, 'input_chunk_length': 58, 'hidden_dim': 197, 'learning_rate': 1.187690616963899e-07, 'batch_size': 64, 'training_length': 460}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 730 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:17,035] Trial 670 finished with value: 16.233293533325195 and parameters: {'n_layers': 1, 'input_chunk_length': 46, 'hidden_dim': 200, 'learning_rate': 1.3911872649121127e-07, 'batch_size': 64, 'training_length': 471}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 731 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:18,164] Trial 671 finished with value: 18.59614372253418 and parameters: {'n_layers': 1, 'input_chunk_length': 45, 'hidden_dim': 192, 'learning_rate': 1.3926532758436358e-06, 'batch_size': 64, 'training_length': 473}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 732 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:19,046] Trial 672 finished with value: 16.243091583251953 and parameters: {'n_layers': 1, 'input_chunk_length': 43, 'hidden_dim': 200, 'learning_rate': 1.1696113142742091e-07, 'batch_size': 64, 'training_length': 480}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 733 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:19,942] Trial 673 finished with value: 21.979711532592773 and parameters: {'n_layers': 1, 'input_chunk_length': 46, 'hidden_dim': 197, 'learning_rate': 1.0034252277664814e-07, 'batch_size': 64, 'training_length': 495}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 734 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:20,812] Trial 674 finished with value: 18.6728572845459 and parameters: {'n_layers': 1, 'input_chunk_length': 45, 'hidden_dim': 195, 'learning_rate': 1.380207478052749e-07, 'batch_size': 64, 'training_length': 481}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 735 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:21,660] Trial 675 finished with value: 16.243318557739258 and parameters: {'n_layers': 1, 'input_chunk_length': 48, 'hidden_dim': 200, 'learning_rate': 1.7613482351515183e-07, 'batch_size': 64, 'training_length': 467}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 736 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:22,522] Trial 676 finished with value: 21.979883193969727 and parameters: {'n_layers': 1, 'input_chunk_length': 46, 'hidden_dim': 197, 'learning_rate': 1.0003564767920566e-07, 'batch_size': 64, 'training_length': 468}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 737 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:23,395] Trial 677 finished with value: 20.80489158630371 and parameters: {'n_layers': 1, 'input_chunk_length': 43, 'hidden_dim': 194, 'learning_rate': 1.3394163621980574e-07, 'batch_size': 64, 'training_length': 487}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 738 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:23,991] Trial 678 finished with value: 16.405763626098633 and parameters: {'n_layers': 1, 'input_chunk_length': 40, 'hidden_dim': 89, 'learning_rate': 1.6593457671629244e-07, 'batch_size': 64, 'training_length': 488}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 739 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:25,260] Trial 679 finished with value: 25.008094787597656 and parameters: {'n_layers': 1, 'input_chunk_length': 48, 'hidden_dim': 188, 'learning_rate': 5.27204551641109e-06, 'batch_size': 32, 'training_length': 462}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 740 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:26,109] Trial 680 finished with value: 16.243314743041992 and parameters: {'n_layers': 1, 'input_chunk_length': 60, 'hidden_dim': 200, 'learning_rate': 1.2444402906320226e-07, 'batch_size': 64, 'training_length': 457}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 741 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:27,235] Trial 681 finished with value: 18.597177505493164 and parameters: {'n_layers': 1, 'input_chunk_length': 44, 'hidden_dim': 192, 'learning_rate': 1.471937703286762e-07, 'batch_size': 64, 'training_length': 474}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 742 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:28,512] Trial 682 finished with value: 20.941646575927734 and parameters: {'n_layers': 2, 'dropout': 0.05179029078902614, 'input_chunk_length': 56, 'hidden_dim': 197, 'learning_rate': 2.014643565260772e-07, 'batch_size': 64, 'training_length': 435}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 743 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:29,375] Trial 683 finished with value: 16.233232498168945 and parameters: {'n_layers': 1, 'input_chunk_length': 46, 'hidden_dim': 200, 'learning_rate': 1.1537062666487768e-07, 'batch_size': 64, 'training_length': 493}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 744 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:30,254] Trial 684 finished with value: 18.6728458404541 and parameters: {'n_layers': 1, 'input_chunk_length': 42, 'hidden_dim': 195, 'learning_rate': 1.1635472201123172e-07, 'batch_size': 64, 'training_length': 495}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 745 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:31,347] Trial 685 finished with value: 21.323389053344727 and parameters: {'n_layers': 1, 'input_chunk_length': 45, 'hidden_dim': 165, 'learning_rate': 1.0016333326517171e-07, 'batch_size': 64, 'training_length': 497}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 746 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:32,225] Trial 686 finished with value: 21.986581802368164 and parameters: {'n_layers': 1, 'input_chunk_length': 44, 'hidden_dim': 197, 'learning_rate': 1.1729331046349173e-07, 'batch_size': 64, 'training_length': 494}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 747 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:33,091] Trial 687 finished with value: 16.233301162719727 and parameters: {'n_layers': 1, 'input_chunk_length': 46, 'hidden_dim': 200, 'learning_rate': 1.343002349523558e-07, 'batch_size': 64, 'training_length': 487}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 748 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:34,237] Trial 688 finished with value: 18.588794708251953 and parameters: {'n_layers': 1, 'input_chunk_length': 47, 'hidden_dim': 192, 'learning_rate': 1.663786860211628e-07, 'batch_size': 64, 'training_length': 486}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 749 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:35,101] Trial 689 finished with value: 21.979795455932617 and parameters: {'n_layers': 1, 'input_chunk_length': 46, 'hidden_dim': 197, 'learning_rate': 1.418489010737735e-07, 'batch_size': 64, 'training_length': 480}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 750 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:35,966] Trial 690 finished with value: 16.233348846435547 and parameters: {'n_layers': 1, 'input_chunk_length': 46, 'hidden_dim': 200, 'learning_rate': 1.7801048960866302e-07, 'batch_size': 64, 'training_length': 483}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 751 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:37,067] Trial 691 finished with value: 20.802471160888672 and parameters: {'n_layers': 1, 'input_chunk_length': 45, 'hidden_dim': 194, 'learning_rate': 2.1460775836344464e-07, 'batch_size': 32, 'training_length': 494}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 752 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:37,940] Trial 692 finished with value: 21.97994613647461 and parameters: {'n_layers': 1, 'input_chunk_length': 47, 'hidden_dim': 197, 'learning_rate': 1.8946427262327177e-07, 'batch_size': 64, 'training_length': 495}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 753 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:38,802] Trial 693 finished with value: 16.243410110473633 and parameters: {'n_layers': 1, 'input_chunk_length': 43, 'hidden_dim': 200, 'learning_rate': 2.44619455433632e-07, 'batch_size': 64, 'training_length': 493}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 754 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:39,926] Trial 694 finished with value: 17.81452751159668 and parameters: {'n_layers': 1, 'input_chunk_length': 46, 'hidden_dim': 190, 'learning_rate': 1.7528488187069493e-07, 'batch_size': 64, 'training_length': 487}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 755 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:40,788] Trial 695 finished with value: 18.680063247680664 and parameters: {'n_layers': 1, 'input_chunk_length': 41, 'hidden_dim': 195, 'learning_rate': 1.637916057163456e-07, 'batch_size': 64, 'training_length': 500}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 756 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:41,654] Trial 696 finished with value: 18.833919525146484 and parameters: {'n_layers': 1, 'input_chunk_length': 44, 'hidden_dim': 198, 'learning_rate': 1.5459744722999477e-07, 'batch_size': 64, 'training_length': 475}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 757 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:42,521] Trial 697 finished with value: 16.23345184326172 and parameters: {'n_layers': 1, 'input_chunk_length': 46, 'hidden_dim': 200, 'learning_rate': 1.9727755601461813e-07, 'batch_size': 64, 'training_length': 482}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 758 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:43,396] Trial 698 finished with value: 29.24386215209961 and parameters: {'n_layers': 1, 'input_chunk_length': 46, 'hidden_dim': 193, 'learning_rate': 2.481648999610806e-07, 'batch_size': 64, 'training_length': 490}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 759 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:44,271] Trial 699 finished with value: 21.986478805541992 and parameters: {'n_layers': 1, 'input_chunk_length': 48, 'hidden_dim': 197, 'learning_rate': 2.367621452333219e-07, 'batch_size': 64, 'training_length': 482}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 760 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:45,145] Trial 700 finished with value: 16.240036010742188 and parameters: {'n_layers': 1, 'input_chunk_length': 45, 'hidden_dim': 200, 'learning_rate': 2.093142984127756e-07, 'batch_size': 64, 'training_length': 490}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 761 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:46,015] Trial 701 finished with value: 18.67572784423828 and parameters: {'n_layers': 1, 'input_chunk_length': 43, 'hidden_dim': 195, 'learning_rate': 1.9521880346694745e-07, 'batch_size': 64, 'training_length': 486}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 762 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:46,891] Trial 702 finished with value: 21.979944229125977 and parameters: {'n_layers': 1, 'input_chunk_length': 47, 'hidden_dim': 197, 'learning_rate': 2.0535391304820684e-07, 'batch_size': 64, 'training_length': 491}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 763 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:47,993] Trial 703 finished with value: 16.243677139282227 and parameters: {'n_layers': 1, 'input_chunk_length': 48, 'hidden_dim': 200, 'learning_rate': 1.7877518351403143e-07, 'batch_size': 32, 'training_length': 484}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 764 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:49,136] Trial 704 finished with value: 17.817947387695312 and parameters: {'n_layers': 1, 'input_chunk_length': 42, 'hidden_dim': 190, 'learning_rate': 2.6339051426695105e-07, 'batch_size': 64, 'training_length': 496}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 765 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:50,006] Trial 705 finished with value: 20.800561904907227 and parameters: {'n_layers': 1, 'input_chunk_length': 45, 'hidden_dim': 194, 'learning_rate': 1.671493512760464e-07, 'batch_size': 64, 'training_length': 485}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 766 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:50,877] Trial 706 finished with value: 21.979780197143555 and parameters: {'n_layers': 1, 'input_chunk_length': 46, 'hidden_dim': 197, 'learning_rate': 1.8429166701479542e-07, 'batch_size': 64, 'training_length': 484}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 767 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:51,742] Trial 707 finished with value: 16.270954132080078 and parameters: {'n_layers': 1, 'input_chunk_length': 41, 'hidden_dim': 200, 'learning_rate': 1.3539146584505561e-05, 'batch_size': 64, 'training_length': 480}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 768 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:52,624] Trial 708 finished with value: 21.986326217651367 and parameters: {'n_layers': 1, 'input_chunk_length': 44, 'hidden_dim': 197, 'learning_rate': 1.5280619557599386e-07, 'batch_size': 64, 'training_length': 496}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 769 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:53,500] Trial 709 finished with value: 29.247882843017578 and parameters: {'n_layers': 1, 'input_chunk_length': 48, 'hidden_dim': 193, 'learning_rate': 2.1560833497011576e-07, 'batch_size': 64, 'training_length': 498}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 770 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:54,353] Trial 710 finished with value: 16.233253479003906 and parameters: {'n_layers': 1, 'input_chunk_length': 46, 'hidden_dim': 200, 'learning_rate': 1.4482728980961828e-07, 'batch_size': 64, 'training_length': 499}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 771 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:55,235] Trial 711 finished with value: 21.980104446411133 and parameters: {'n_layers': 1, 'input_chunk_length': 47, 'hidden_dim': 197, 'learning_rate': 1.3891509100612641e-07, 'batch_size': 64, 'training_length': 498}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 772 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:56,103] Trial 712 finished with value: 16.234342575073242 and parameters: {'n_layers': 1, 'input_chunk_length': 49, 'hidden_dim': 200, 'learning_rate': 1.6258551399559242e-07, 'batch_size': 64, 'training_length': 487}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 773 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:56,965] Trial 713 finished with value: 19.418684005737305 and parameters: {'n_layers': 1, 'input_chunk_length': 47, 'hidden_dim': 195, 'learning_rate': 0.0003647683613066763, 'batch_size': 64, 'training_length': 499}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 774 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:57,834] Trial 714 finished with value: 16.23988914489746 and parameters: {'n_layers': 1, 'input_chunk_length': 45, 'hidden_dim': 200, 'learning_rate': 1.3548882805838806e-07, 'batch_size': 64, 'training_length': 489}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 775 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:36:58,959] Trial 715 finished with value: 19.741907119750977 and parameters: {'n_layers': 1, 'input_chunk_length': 48, 'hidden_dim': 191, 'learning_rate': 2.0148301993325505e-07, 'batch_size': 64, 'training_length': 482}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 776 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:37:00,076] Trial 716 finished with value: 18.110183715820312 and parameters: {'n_layers': 1, 'input_chunk_length': 44, 'hidden_dim': 187, 'learning_rate': 3.941701919852404e-06, 'batch_size': 64, 'training_length': 480}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 777 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:37:01,174] Trial 717 finished with value: 21.979703903198242 and parameters: {'n_layers': 1, 'input_chunk_length': 46, 'hidden_dim': 197, 'learning_rate': 1.3637888473985242e-07, 'batch_size': 32, 'training_length': 488}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 778 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:37:02,043] Trial 718 finished with value: 20.80055809020996 and parameters: {'n_layers': 1, 'input_chunk_length': 49, 'hidden_dim': 194, 'learning_rate': 1.6216945657814656e-07, 'batch_size': 64, 'training_length': 491}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 779 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:37:02,904] Trial 719 finished with value: 21.98360252380371 and parameters: {'n_layers': 1, 'input_chunk_length': 45, 'hidden_dim': 197, 'learning_rate': 1.2500380993213717e-07, 'batch_size': 64, 'training_length': 474}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 780 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:37:03,530] Trial 720 finished with value: 24.5350341796875 and parameters: {'n_layers': 1, 'input_chunk_length': 48, 'hidden_dim': 109, 'learning_rate': 1.7838515517914276e-07, 'batch_size': 64, 'training_length': 481}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 781 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:37:04,430] Trial 721 finished with value: 16.233314514160156 and parameters: {'n_layers': 1, 'input_chunk_length': 46, 'hidden_dim': 200, 'learning_rate': 1.3973937623693652e-07, 'batch_size': 64, 'training_length': 496}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 782 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:37:05,323] Trial 722 finished with value: 16.23357391357422 and parameters: {'n_layers': 1, 'input_chunk_length': 46, 'hidden_dim': 200, 'learning_rate': 2.2849513197480798e-07, 'batch_size': 64, 'training_length': 497}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 783 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:37:06,185] Trial 723 finished with value: 21.97977066040039 and parameters: {'n_layers': 1, 'input_chunk_length': 47, 'hidden_dim': 197, 'learning_rate': 2.689631972778463e-07, 'batch_size': 64, 'training_length': 499}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 784 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:37:07,483] Trial 724 finished with value: 21.187198638916016 and parameters: {'n_layers': 2, 'dropout': 0.39818683250685977, 'input_chunk_length': 46, 'hidden_dim': 200, 'learning_rate': 2.8963017410398703e-07, 'batch_size': 64, 'training_length': 498}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 785 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:37:08,361] Trial 725 finished with value: 29.24262809753418 and parameters: {'n_layers': 1, 'input_chunk_length': 49, 'hidden_dim': 193, 'learning_rate': 2.5885168700983167e-07, 'batch_size': 64, 'training_length': 490}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 786 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:37:09,218] Trial 726 finished with value: 18.677640914916992 and parameters: {'n_layers': 1, 'input_chunk_length': 46, 'hidden_dim': 195, 'learning_rate': 2.2019897999679637e-07, 'batch_size': 64, 'training_length': 500}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 787 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:37:10,088] Trial 727 finished with value: 16.243741989135742 and parameters: {'n_layers': 1, 'input_chunk_length': 44, 'hidden_dim': 200, 'learning_rate': 3.308794136313e-07, 'batch_size': 64, 'training_length': 498}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 788 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:37:11,074] Trial 728 finished with value: 20.75505828857422 and parameters: {'n_layers': 1, 'input_chunk_length': 49, 'hidden_dim': 147, 'learning_rate': 2.537786941189992e-07, 'batch_size': 64, 'training_length': 498}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 789 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:37:12,175] Trial 729 finished with value: 21.979677200317383 and parameters: {'n_layers': 1, 'input_chunk_length': 47, 'hidden_dim': 197, 'learning_rate': 2.1854410390851923e-07, 'batch_size': 32, 'training_length': 489}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 790 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:37:13,315] Trial 730 finished with value: 18.597700119018555 and parameters: {'n_layers': 1, 'input_chunk_length': 46, 'hidden_dim': 192, 'learning_rate': 1.8609352365760715e-06, 'batch_size': 64, 'training_length': 488}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 791 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:37:14,199] Trial 731 finished with value: 21.98641586303711 and parameters: {'n_layers': 1, 'input_chunk_length': 44, 'hidden_dim': 197, 'learning_rate': 2.0873545358879346e-07, 'batch_size': 64, 'training_length': 489}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 792 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:37:15,051] Trial 732 finished with value: 16.234294891357422 and parameters: {'n_layers': 1, 'input_chunk_length': 49, 'hidden_dim': 200, 'learning_rate': 1.9220515520136125e-07, 'batch_size': 64, 'training_length': 500}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 793 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:37:15,917] Trial 733 finished with value: 20.809816360473633 and parameters: {'n_layers': 1, 'input_chunk_length': 48, 'hidden_dim': 194, 'learning_rate': 1.8264833680419887e-07, 'batch_size': 64, 'training_length': 479}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 794 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:37:16,853] Trial 734 finished with value: 17.407848358154297 and parameters: {'n_layers': 1, 'input_chunk_length': 45, 'hidden_dim': 133, 'learning_rate': 1.6635157585596515e-07, 'batch_size': 64, 'training_length': 500}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 795 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:37:17,954] Trial 735 finished with value: 22.53712272644043 and parameters: {'n_layers': 1, 'input_chunk_length': 43, 'hidden_dim': 182, 'learning_rate': 2.393704034058792e-07, 'batch_size': 64, 'training_length': 485}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 796 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:37:19,074] Trial 736 finished with value: 27.138029098510742 and parameters: {'n_layers': 1, 'input_chunk_length': 46, 'hidden_dim': 189, 'learning_rate': 3.8584883302503674e-07, 'batch_size': 64, 'training_length': 500}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 797 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:37:19,944] Trial 737 finished with value: 21.986557006835938 and parameters: {'n_layers': 1, 'input_chunk_length': 48, 'hidden_dim': 197, 'learning_rate': 1.5135639887545814e-07, 'batch_size': 64, 'training_length': 477}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 798 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:37:20,811] Trial 738 finished with value: 16.2432918548584 and parameters: {'n_layers': 1, 'input_chunk_length': 44, 'hidden_dim': 200, 'learning_rate': 1.8651925231098205e-07, 'batch_size': 64, 'training_length': 488}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 799 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:37:21,685] Trial 739 finished with value: 18.681514739990234 and parameters: {'n_layers': 1, 'input_chunk_length': 50, 'hidden_dim': 195, 'learning_rate': 1.5080004353098176e-07, 'batch_size': 64, 'training_length': 490}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 800 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:37:22,637] Trial 740 finished with value: 27.921741485595703 and parameters: {'n_layers': 1, 'input_chunk_length': 46, 'hidden_dim': 141, 'learning_rate': 2.221731566751682e-07, 'batch_size': 64, 'training_length': 473}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 801 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:37:23,741] Trial 741 finished with value: 18.834230422973633 and parameters: {'n_layers': 1, 'input_chunk_length': 48, 'hidden_dim': 198, 'learning_rate': 1.3458620801039775e-07, 'batch_size': 32, 'training_length': 480}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 802 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:37:24,614] Trial 742 finished with value: 16.24325180053711 and parameters: {'n_layers': 1, 'input_chunk_length': 43, 'hidden_dim': 200, 'learning_rate': 1.7053935953224895e-07, 'batch_size': 64, 'training_length': 487}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 803 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:37:25,483] Trial 743 finished with value: 18.869779586791992 and parameters: {'n_layers': 1, 'input_chunk_length': 46, 'hidden_dim': 195, 'learning_rate': 0.00022335894911430806, 'batch_size': 64, 'training_length': 476}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 804 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:37:26,114] Trial 744 finished with value: 29.890657424926758 and parameters: {'n_layers': 1, 'input_chunk_length': 49, 'hidden_dim': 118, 'learning_rate': 1.3168416423916472e-07, 'batch_size': 64, 'training_length': 491}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 805 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:37:26,972] Trial 745 finished with value: 21.986501693725586 and parameters: {'n_layers': 1, 'input_chunk_length': 44, 'hidden_dim': 197, 'learning_rate': 3.1455521907198033e-07, 'batch_size': 64, 'training_length': 500}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 806 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:37:28,117] Trial 746 finished with value: 18.58873176574707 and parameters: {'n_layers': 1, 'input_chunk_length': 47, 'hidden_dim': 192, 'learning_rate': 1.6214844056853075e-07, 'batch_size': 64, 'training_length': 487}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 807 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:37:28,974] Trial 747 finished with value: 16.243362426757812 and parameters: {'n_layers': 1, 'input_chunk_length': 50, 'hidden_dim': 200, 'learning_rate': 1.9537425643669174e-07, 'batch_size': 64, 'training_length': 476}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 808 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:37:29,846] Trial 748 finished with value: 21.983549118041992 and parameters: {'n_layers': 1, 'input_chunk_length': 45, 'hidden_dim': 197, 'learning_rate': 1.1959938400939714e-07, 'batch_size': 64, 'training_length': 481}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 809 records. Best score: -0.900. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-13 11:37:30,711] Trial 749 finished with value: 20.800745010375977 and parameters: {'n_layers': 1, 'input_chunk_length': 42, 'hidden_dim': 194, 'learning_rate': 1.4326247213117575e-07, 'batch_size': 64, 'training_length': 473}. Best is trial 400 with value: 16.23319435119629.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (17) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=150` reached.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
