GpuFreq=control_disabled
[I 2024-10-12 14:19:32,678] A new study created in memory with name: no-name-bd5c84c8-b15a-4303-9168-5c18f9a9f6a0
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/torch/random.py:167: UserWarning: CUDA reports that you have 4 available devices, and you have used fork_rng without explicitly specifying which devices are being used. For safety, we initialize *every* CUDA device by default, which can be quite slow if you have a lot of CUDAs. If you know that you are only making use of a few CUDA devices, set the environment variable CUDA_VISIBLE_DEVICES or the 'devices' keyword argument of fork_rng with the set of devices you are actually using. For example, if you are using CPU only, set device.upper()_VISIBLE_DEVICES= or devices=[]; if you are using device 0 only, set CUDA_VISIBLE_DEVICES=0 or devices=[0].  To initialize all devices and suppress this warning, set the 'devices' keyword argument to `range(torch.cuda.device_count())`.
  warnings.warn(message)
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 1 processes
----------------------------------------------------------------------------------------------------

LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Metric val_loss improved. New best score: 0.641
Metric val_loss improved by 0.033 >= min_delta = 0.0. New best score: 0.608
Metric val_loss improved by 0.039 >= min_delta = 0.0. New best score: 0.569
Metric val_loss improved by 0.044 >= min_delta = 0.0. New best score: 0.524
Metric val_loss improved by 0.045 >= min_delta = 0.0. New best score: 0.479
Metric val_loss improved by 0.039 >= min_delta = 0.0. New best score: 0.440
Metric val_loss improved by 0.037 >= min_delta = 0.0. New best score: 0.403
Metric val_loss improved by 0.036 >= min_delta = 0.0. New best score: 0.367
Metric val_loss improved by 0.034 >= min_delta = 0.0. New best score: 0.333
Metric val_loss improved by 0.033 >= min_delta = 0.0. New best score: 0.301
Metric val_loss improved by 0.032 >= min_delta = 0.0. New best score: 0.269
Metric val_loss improved by 0.032 >= min_delta = 0.0. New best score: 0.237
Metric val_loss improved by 0.031 >= min_delta = 0.0. New best score: 0.206
Metric val_loss improved by 0.032 >= min_delta = 0.0. New best score: 0.174
Metric val_loss improved by 0.031 >= min_delta = 0.0. New best score: 0.143
Metric val_loss improved by 0.025 >= min_delta = 0.0. New best score: 0.118
Metric val_loss improved by 0.024 >= min_delta = 0.0. New best score: 0.094
Metric val_loss improved by 0.025 >= min_delta = 0.0. New best score: 0.069
Metric val_loss improved by 0.023 >= min_delta = 0.0. New best score: 0.046
Metric val_loss improved by 0.022 >= min_delta = 0.0. New best score: 0.024
Metric val_loss improved by 0.022 >= min_delta = 0.0. New best score: 0.003
Metric val_loss improved by 0.041 >= min_delta = 0.0. New best score: -0.038
Metric val_loss improved by 0.062 >= min_delta = 0.0. New best score: -0.100
Metric val_loss improved by 0.021 >= min_delta = 0.0. New best score: -0.121
Metric val_loss improved by 0.012 >= min_delta = 0.0. New best score: -0.134
Metric val_loss improved by 0.018 >= min_delta = 0.0. New best score: -0.152
Metric val_loss improved by 0.027 >= min_delta = 0.0. New best score: -0.178
Metric val_loss improved by 0.042 >= min_delta = 0.0. New best score: -0.221
Metric val_loss improved by 0.083 >= min_delta = 0.0. New best score: -0.304
Metric val_loss improved by 0.009 >= min_delta = 0.0. New best score: -0.313
Metric val_loss improved by 0.021 >= min_delta = 0.0. New best score: -0.334
Metric val_loss improved by 0.090 >= min_delta = 0.0. New best score: -0.423
Metric val_loss improved by 0.107 >= min_delta = 0.0. New best score: -0.531
Metric val_loss improved by 0.000 >= min_delta = 0.0. New best score: -0.531
Metric val_loss improved by 0.013 >= min_delta = 0.0. New best score: -0.544
Metric val_loss improved by 0.005 >= min_delta = 0.0. New best score: -0.549
Metric val_loss improved by 0.004 >= min_delta = 0.0. New best score: -0.553
Metric val_loss improved by 0.118 >= min_delta = 0.0. New best score: -0.671
Monitored metric val_loss did not improve in the last 60 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:20:20,747] Trial 0 finished with value: 425.4556884765625 and parameters: {'n_layers': 1, 'input_chunk_length': 34, 'hidden_dim': 57, 'learning_rate': 5.413994638726308e-05, 'batch_size': 32, 'training_length': 365}. Best is trial 0 with value: 425.4556884765625.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 61 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:20:21,640] Trial 1 finished with value: 374.0963134765625 and parameters: {'n_layers': 1, 'input_chunk_length': 65, 'hidden_dim': 146, 'learning_rate': 7.080274878551031e-05, 'batch_size': 64, 'training_length': 426}. Best is trial 1 with value: 374.0963134765625.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 62 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:20:22,236] Trial 2 finished with value: 701.3267822265625 and parameters: {'n_layers': 1, 'input_chunk_length': 26, 'hidden_dim': 103, 'learning_rate': 4.816075322742919e-07, 'batch_size': 32, 'training_length': 62}. Best is trial 1 with value: 374.0963134765625.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 63 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:20:23,412] Trial 3 finished with value: 555.0691528320312 and parameters: {'n_layers': 2, 'dropout': 0.26469314057145316, 'input_chunk_length': 13, 'hidden_dim': 83, 'learning_rate': 7.53564857019233e-05, 'batch_size': 32, 'training_length': 389}. Best is trial 1 with value: 374.0963134765625.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 64 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:20:23,947] Trial 4 finished with value: 662.0313720703125 and parameters: {'n_layers': 1, 'input_chunk_length': 78, 'hidden_dim': 51, 'learning_rate': 1.4845851807669453e-06, 'batch_size': 64, 'training_length': 279}. Best is trial 1 with value: 374.0963134765625.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 65 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:20:24,786] Trial 5 finished with value: 373.1131896972656 and parameters: {'n_layers': 1, 'input_chunk_length': 69, 'hidden_dim': 161, 'learning_rate': 1.260209768433081e-06, 'batch_size': 32, 'training_length': 181}. Best is trial 5 with value: 373.1131896972656.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 66 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:20:25,537] Trial 6 finished with value: 500.6008605957031 and parameters: {'n_layers': 2, 'dropout': 0.20894438020508987, 'input_chunk_length': 75, 'hidden_dim': 53, 'learning_rate': 2.0665156240217105e-07, 'batch_size': 16, 'training_length': 250}. Best is trial 5 with value: 373.1131896972656.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 67 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:20:26,298] Trial 7 finished with value: 534.313720703125 and parameters: {'n_layers': 2, 'dropout': 0.06470052661018516, 'input_chunk_length': 78, 'hidden_dim': 90, 'learning_rate': 0.00056192699290771, 'batch_size': 16, 'training_length': 132}. Best is trial 5 with value: 373.1131896972656.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 68 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:20:26,835] Trial 8 finished with value: 527.81396484375 and parameters: {'n_layers': 1, 'input_chunk_length': 43, 'hidden_dim': 68, 'learning_rate': 5.526027879757461e-05, 'batch_size': 64, 'training_length': 254}. Best is trial 5 with value: 373.1131896972656.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 69 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:20:27,466] Trial 9 finished with value: 452.58795166015625 and parameters: {'n_layers': 2, 'dropout': 0.20321187070095342, 'input_chunk_length': 100, 'hidden_dim': 88, 'learning_rate': 3.2233123980030203e-07, 'batch_size': 32, 'training_length': 445}. Best is trial 5 with value: 373.1131896972656.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 70 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:20:28,649] Trial 10 finished with value: 561.6217041015625 and parameters: {'n_layers': 1, 'input_chunk_length': 53, 'hidden_dim': 193, 'learning_rate': 3.0064432263722926e-06, 'batch_size': 32, 'training_length': 163}. Best is trial 5 with value: 373.1131896972656.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 71 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:20:29,591] Trial 11 finished with value: 657.54150390625 and parameters: {'n_layers': 1, 'input_chunk_length': 64, 'hidden_dim': 157, 'learning_rate': 9.684886357881925e-06, 'batch_size': 64, 'training_length': 488}. Best is trial 5 with value: 373.1131896972656.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 72 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:20:30,413] Trial 12 finished with value: 644.2725830078125 and parameters: {'n_layers': 1, 'input_chunk_length': 95, 'hidden_dim': 145, 'learning_rate': 0.0008769845522568378, 'batch_size': 64, 'training_length': 337}. Best is trial 5 with value: 373.1131896972656.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 73 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:20:31,174] Trial 13 finished with value: 562.404541015625 and parameters: {'n_layers': 1, 'input_chunk_length': 63, 'hidden_dim': 175, 'learning_rate': 8.080267656825974e-06, 'batch_size': 64, 'training_length': 176}. Best is trial 5 with value: 373.1131896972656.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 74 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:20:31,931] Trial 14 finished with value: 617.24462890625 and parameters: {'n_layers': 1, 'input_chunk_length': 52, 'hidden_dim': 126, 'learning_rate': 0.00013771545961640226, 'batch_size': 16, 'training_length': 214}. Best is trial 5 with value: 373.1131896972656.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 75 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:20:32,929] Trial 15 finished with value: 631.0322265625 and parameters: {'n_layers': 1, 'input_chunk_length': 88, 'hidden_dim': 131, 'learning_rate': 1.3131940825547806e-06, 'batch_size': 32, 'training_length': 412}. Best is trial 5 with value: 373.1131896972656.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 76 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:20:33,801] Trial 16 finished with value: 349.7977294921875 and parameters: {'n_layers': 1, 'input_chunk_length': 66, 'hidden_dim': 164, 'learning_rate': 1.912160016514393e-05, 'batch_size': 64, 'training_length': 305}. Best is trial 16 with value: 349.7977294921875.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 77 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:20:35,221] Trial 17 finished with value: 515.5891723632812 and parameters: {'n_layers': 2, 'dropout': 0.4928335273855824, 'input_chunk_length': 86, 'hidden_dim': 197, 'learning_rate': 1.7236360019890153e-05, 'batch_size': 32, 'training_length': 320}. Best is trial 16 with value: 349.7977294921875.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 78 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:20:35,878] Trial 18 finished with value: 471.36090087890625 and parameters: {'n_layers': 1, 'input_chunk_length': 43, 'hidden_dim': 178, 'learning_rate': 1.1234691603303513e-07, 'batch_size': 64, 'training_length': 85}. Best is trial 16 with value: 349.7977294921875.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 79 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:20:36,905] Trial 19 finished with value: 410.9697570800781 and parameters: {'n_layers': 1, 'input_chunk_length': 73, 'hidden_dim': 155, 'learning_rate': 4.155282297549815e-06, 'batch_size': 16, 'training_length': 207}. Best is trial 16 with value: 349.7977294921875.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 80 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:20:38,261] Trial 20 finished with value: 472.1701354980469 and parameters: {'n_layers': 2, 'dropout': 0.49329842026479775, 'input_chunk_length': 59, 'hidden_dim': 173, 'learning_rate': 2.284596221105885e-05, 'batch_size': 64, 'training_length': 311}. Best is trial 16 with value: 349.7977294921875.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 81 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:20:39,338] Trial 21 finished with value: 470.6072998046875 and parameters: {'n_layers': 1, 'input_chunk_length': 67, 'hidden_dim': 140, 'learning_rate': 0.00024104805871729592, 'batch_size': 64, 'training_length': 496}. Best is trial 16 with value: 349.7977294921875.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 82 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:20:40,240] Trial 22 finished with value: 587.4611206054688 and parameters: {'n_layers': 1, 'input_chunk_length': 49, 'hidden_dim': 159, 'learning_rate': 2.277747377034585e-05, 'batch_size': 64, 'training_length': 442}. Best is trial 16 with value: 349.7977294921875.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 83 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:20:40,817] Trial 23 finished with value: 398.1641845703125 and parameters: {'n_layers': 1, 'input_chunk_length': 71, 'hidden_dim': 108, 'learning_rate': 8.663614813578383e-07, 'batch_size': 64, 'training_length': 361}. Best is trial 16 with value: 349.7977294921875.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 84 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:20:41,659] Trial 24 finished with value: 348.0141906738281 and parameters: {'n_layers': 1, 'input_chunk_length': 87, 'hidden_dim': 164, 'learning_rate': 3.930541375454938e-06, 'batch_size': 64, 'training_length': 279}. Best is trial 24 with value: 348.0141906738281.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 85 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:20:42,652] Trial 25 finished with value: 651.1151733398438 and parameters: {'n_layers': 1, 'input_chunk_length': 86, 'hidden_dim': 187, 'learning_rate': 3.7578842935482126e-06, 'batch_size': 32, 'training_length': 282}. Best is trial 24 with value: 348.0141906738281.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 86 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:20:43,465] Trial 26 finished with value: 469.06048583984375 and parameters: {'n_layers': 1, 'input_chunk_length': 91, 'hidden_dim': 165, 'learning_rate': 1.7379080506417383e-06, 'batch_size': 64, 'training_length': 231}. Best is trial 24 with value: 348.0141906738281.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 87 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:20:44,189] Trial 27 finished with value: 361.5704650878906 and parameters: {'n_layers': 1, 'input_chunk_length': 78, 'hidden_dim': 185, 'learning_rate': 7.037867583313908e-06, 'batch_size': 64, 'training_length': 135}. Best is trial 24 with value: 348.0141906738281.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 88 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:20:44,925] Trial 28 finished with value: 361.2328796386719 and parameters: {'n_layers': 1, 'input_chunk_length': 80, 'hidden_dim': 185, 'learning_rate': 6.2780098997347014e-06, 'batch_size': 64, 'training_length': 147}. Best is trial 24 with value: 348.0141906738281.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 89 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:20:45,494] Trial 29 finished with value: 592.3578491210938 and parameters: {'n_layers': 1, 'input_chunk_length': 83, 'hidden_dim': 115, 'learning_rate': 1.4889186123493851e-05, 'batch_size': 64, 'training_length': 354}. Best is trial 24 with value: 348.0141906738281.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 90 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:20:46,359] Trial 30 finished with value: 502.090087890625 and parameters: {'n_layers': 1, 'input_chunk_length': 96, 'hidden_dim': 170, 'learning_rate': 2.737538448235266e-05, 'batch_size': 64, 'training_length': 289}. Best is trial 24 with value: 348.0141906738281.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 91 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:20:47,055] Trial 31 finished with value: 411.9459228515625 and parameters: {'n_layers': 1, 'input_chunk_length': 82, 'hidden_dim': 184, 'learning_rate': 5.859435344753081e-06, 'batch_size': 64, 'training_length': 120}. Best is trial 24 with value: 348.0141906738281.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 92 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:20:47,697] Trial 32 finished with value: 535.8123779296875 and parameters: {'n_layers': 1, 'input_chunk_length': 58, 'hidden_dim': 198, 'learning_rate': 3.5746145385560436e-05, 'batch_size': 64, 'training_length': 132}. Best is trial 24 with value: 348.0141906738281.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 93 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:20:48,443] Trial 33 finished with value: 357.70050048828125 and parameters: {'n_layers': 1, 'input_chunk_length': 78, 'hidden_dim': 183, 'learning_rate': 2.3787470784845216e-06, 'batch_size': 64, 'training_length': 152}. Best is trial 24 with value: 348.0141906738281.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 94 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:20:49,175] Trial 34 finished with value: 619.608642578125 and parameters: {'n_layers': 1, 'input_chunk_length': 91, 'hidden_dim': 145, 'learning_rate': 2.525206162610907e-06, 'batch_size': 64, 'training_length': 208}. Best is trial 24 with value: 348.0141906738281.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 95 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:20:49,841] Trial 35 finished with value: 540.9054565429688 and parameters: {'n_layers': 1, 'input_chunk_length': 81, 'hidden_dim': 180, 'learning_rate': 6.846823181094214e-07, 'batch_size': 64, 'training_length': 98}. Best is trial 24 with value: 348.0141906738281.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 96 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:20:50,583] Trial 36 finished with value: 511.4145202636719 and parameters: {'n_layers': 1, 'input_chunk_length': 73, 'hidden_dim': 168, 'learning_rate': 1.0634890332670741e-05, 'batch_size': 64, 'training_length': 170}. Best is trial 24 with value: 348.0141906738281.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 97 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:20:51,189] Trial 37 finished with value: 909.504150390625 and parameters: {'n_layers': 1, 'input_chunk_length': 25, 'hidden_dim': 150, 'learning_rate': 4.953183780930407e-06, 'batch_size': 64, 'training_length': 56}. Best is trial 24 with value: 348.0141906738281.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 98 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:20:51,935] Trial 38 finished with value: 492.2421875 and parameters: {'n_layers': 1, 'input_chunk_length': 10, 'hidden_dim': 139, 'learning_rate': 2.282921057530685e-06, 'batch_size': 16, 'training_length': 14}. Best is trial 24 with value: 348.0141906738281.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 99 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:20:53,271] Trial 39 finished with value: 501.18182373046875 and parameters: {'n_layers': 2, 'dropout': 0.01938044109459225, 'input_chunk_length': 77, 'hidden_dim': 189, 'learning_rate': 0.00012430296613270483, 'batch_size': 64, 'training_length': 267}. Best is trial 24 with value: 348.0141906738281.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 100 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:20:54,099] Trial 40 finished with value: 478.681884765625 and parameters: {'n_layers': 1, 'input_chunk_length': 68, 'hidden_dim': 165, 'learning_rate': 4.2810709684490026e-05, 'batch_size': 64, 'training_length': 244}. Best is trial 24 with value: 348.0141906738281.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 101 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:20:54,754] Trial 41 finished with value: 391.7631530761719 and parameters: {'n_layers': 1, 'input_chunk_length': 79, 'hidden_dim': 200, 'learning_rate': 6.832773171720399e-06, 'batch_size': 64, 'training_length': 154}. Best is trial 24 with value: 348.0141906738281.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 102 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:20:55,544] Trial 42 finished with value: 359.9488220214844 and parameters: {'n_layers': 1, 'input_chunk_length': 76, 'hidden_dim': 183, 'learning_rate': 1.2913447791934136e-05, 'batch_size': 64, 'training_length': 193}. Best is trial 24 with value: 348.0141906738281.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 103 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:20:56,326] Trial 43 finished with value: 541.6707153320312 and parameters: {'n_layers': 1, 'input_chunk_length': 62, 'hidden_dim': 180, 'learning_rate': 1.3000963644279968e-05, 'batch_size': 64, 'training_length': 190}. Best is trial 24 with value: 348.0141906738281.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 104 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:20:57,344] Trial 44 finished with value: 496.4892272949219 and parameters: {'n_layers': 1, 'input_chunk_length': 71, 'hidden_dim': 189, 'learning_rate': 2.0341485442370376e-06, 'batch_size': 64, 'training_length': 391}. Best is trial 24 with value: 348.0141906738281.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 105 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:20:58,271] Trial 45 finished with value: 463.6435241699219 and parameters: {'n_layers': 1, 'input_chunk_length': 92, 'hidden_dim': 152, 'learning_rate': 3.70668348569201e-06, 'batch_size': 16, 'training_length': 148}. Best is trial 24 with value: 348.0141906738281.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 106 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:20:59,254] Trial 46 finished with value: 493.17657470703125 and parameters: {'n_layers': 1, 'input_chunk_length': 84, 'hidden_dim': 174, 'learning_rate': 9.123934788569192e-07, 'batch_size': 64, 'training_length': 190}. Best is trial 24 with value: 348.0141906738281.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 107 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:00,061] Trial 47 finished with value: 557.665283203125 and parameters: {'n_layers': 1, 'input_chunk_length': 100, 'hidden_dim': 163, 'learning_rate': 4.90447533595288e-07, 'batch_size': 64, 'training_length': 228}. Best is trial 24 with value: 348.0141906738281.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 108 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:00,992] Trial 48 finished with value: 358.6681823730469 and parameters: {'n_layers': 1, 'input_chunk_length': 75, 'hidden_dim': 192, 'learning_rate': 7.519753877028353e-05, 'batch_size': 64, 'training_length': 312}. Best is trial 24 with value: 348.0141906738281.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 109 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:01,624] Trial 49 finished with value: 421.9837341308594 and parameters: {'n_layers': 2, 'dropout': 0.3538523883564971, 'input_chunk_length': 75, 'hidden_dim': 62, 'learning_rate': 7.312959119072966e-05, 'batch_size': 32, 'training_length': 307}. Best is trial 24 with value: 348.0141906738281.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 110 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:02,822] Trial 50 finished with value: 505.15008544921875 and parameters: {'n_layers': 1, 'input_chunk_length': 67, 'hidden_dim': 194, 'learning_rate': 0.0001119846911795153, 'batch_size': 16, 'training_length': 320}. Best is trial 24 with value: 348.0141906738281.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 111 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:03,798] Trial 51 finished with value: 401.23284912109375 and parameters: {'n_layers': 1, 'input_chunk_length': 75, 'hidden_dim': 192, 'learning_rate': 0.00028348193392835433, 'batch_size': 64, 'training_length': 347}. Best is trial 24 with value: 348.0141906738281.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 112 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:04,756] Trial 52 finished with value: 360.73675537109375 and parameters: {'n_layers': 1, 'input_chunk_length': 88, 'hidden_dim': 176, 'learning_rate': 9.687913646803616e-06, 'batch_size': 64, 'training_length': 385}. Best is trial 24 with value: 348.0141906738281.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 113 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:05,731] Trial 53 finished with value: 566.2337036132812 and parameters: {'n_layers': 1, 'input_chunk_length': 89, 'hidden_dim': 177, 'learning_rate': 5.138098502837882e-05, 'batch_size': 64, 'training_length': 389}. Best is trial 24 with value: 348.0141906738281.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 114 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:06,754] Trial 54 finished with value: 344.3180236816406 and parameters: {'n_layers': 1, 'input_chunk_length': 86, 'hidden_dim': 172, 'learning_rate': 1.849858902739364e-05, 'batch_size': 64, 'training_length': 468}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 115 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:07,683] Trial 55 finished with value: 587.0914916992188 and parameters: {'n_layers': 1, 'input_chunk_length': 94, 'hidden_dim': 159, 'learning_rate': 3.216357902862682e-05, 'batch_size': 64, 'training_length': 474}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 116 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:08,558] Trial 56 finished with value: 500.767333984375 and parameters: {'n_layers': 1, 'input_chunk_length': 62, 'hidden_dim': 170, 'learning_rate': 1.7399915972362704e-05, 'batch_size': 64, 'training_length': 293}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 117 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:09,419] Trial 57 finished with value: 453.2509765625 and parameters: {'n_layers': 1, 'input_chunk_length': 85, 'hidden_dim': 181, 'learning_rate': 9.329022130746339e-05, 'batch_size': 64, 'training_length': 257}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 118 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:10,029] Trial 58 finished with value: 662.80810546875 and parameters: {'n_layers': 1, 'input_chunk_length': 71, 'hidden_dim': 78, 'learning_rate': 0.00017905819680326003, 'batch_size': 32, 'training_length': 332}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 119 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:10,755] Trial 59 finished with value: 568.7103271484375 and parameters: {'n_layers': 1, 'input_chunk_length': 56, 'hidden_dim': 193, 'learning_rate': 6.158110845255491e-05, 'batch_size': 64, 'training_length': 271}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 120 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:11,582] Trial 60 finished with value: 500.4646301269531 and parameters: {'n_layers': 1, 'input_chunk_length': 97, 'hidden_dim': 170, 'learning_rate': 2.2780687361762057e-05, 'batch_size': 64, 'training_length': 229}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 121 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:12,544] Trial 61 finished with value: 571.6431274414062 and parameters: {'n_layers': 1, 'input_chunk_length': 88, 'hidden_dim': 175, 'learning_rate': 9.718797827294023e-06, 'batch_size': 64, 'training_length': 377}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 122 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:13,513] Trial 62 finished with value: 373.47796630859375 and parameters: {'n_layers': 1, 'input_chunk_length': 87, 'hidden_dim': 161, 'learning_rate': 3.058059812156388e-06, 'batch_size': 64, 'training_length': 409}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 123 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:14,554] Trial 63 finished with value: 457.37890625 and parameters: {'n_layers': 1, 'input_chunk_length': 75, 'hidden_dim': 182, 'learning_rate': 1.2232394360908322e-05, 'batch_size': 64, 'training_length': 445}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 124 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:15,475] Trial 64 finished with value: 571.22314453125 and parameters: {'n_layers': 1, 'input_chunk_length': 82, 'hidden_dim': 156, 'learning_rate': 1.8552950642532438e-05, 'batch_size': 64, 'training_length': 462}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 125 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:16,464] Trial 65 finished with value: 497.3512268066406 and parameters: {'n_layers': 1, 'input_chunk_length': 80, 'hidden_dim': 189, 'learning_rate': 9.819932858121513e-06, 'batch_size': 64, 'training_length': 375}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 126 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:17,262] Trial 66 finished with value: 463.80987548828125 and parameters: {'n_layers': 1, 'input_chunk_length': 90, 'hidden_dim': 97, 'learning_rate': 4.6705965038089575e-06, 'batch_size': 16, 'training_length': 425}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 127 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:18,179] Trial 67 finished with value: 506.7557373046875 and parameters: {'n_layers': 1, 'input_chunk_length': 66, 'hidden_dim': 168, 'learning_rate': 1.4518266785942898e-06, 'batch_size': 64, 'training_length': 336}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 128 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:19,096] Trial 68 finished with value: 549.5556030273438 and parameters: {'n_layers': 1, 'input_chunk_length': 77, 'hidden_dim': 177, 'learning_rate': 8.48514537019946e-06, 'batch_size': 64, 'training_length': 305}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 129 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:20,028] Trial 69 finished with value: 382.7684020996094 and parameters: {'n_layers': 1, 'input_chunk_length': 93, 'hidden_dim': 133, 'learning_rate': 4.3086032895124484e-05, 'batch_size': 32, 'training_length': 325}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 130 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:21,356] Trial 70 finished with value: 540.2536010742188 and parameters: {'n_layers': 2, 'dropout': 0.3757463019161974, 'input_chunk_length': 84, 'hidden_dim': 149, 'learning_rate': 0.0004497170720619107, 'batch_size': 64, 'training_length': 408}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 131 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:22,115] Trial 71 finished with value: 548.560791015625 and parameters: {'n_layers': 1, 'input_chunk_length': 79, 'hidden_dim': 186, 'learning_rate': 5.995198907939591e-06, 'batch_size': 64, 'training_length': 159}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 132 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:22,821] Trial 72 finished with value: 418.5533752441406 and parameters: {'n_layers': 1, 'input_chunk_length': 72, 'hidden_dim': 196, 'learning_rate': 2.7889144053491137e-06, 'batch_size': 64, 'training_length': 107}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 133 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:23,617] Trial 73 finished with value: 361.4588317871094 and parameters: {'n_layers': 1, 'input_chunk_length': 81, 'hidden_dim': 185, 'learning_rate': 7.2959637462332946e-06, 'batch_size': 64, 'training_length': 187}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 134 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:24,503] Trial 74 finished with value: 396.088623046875 and parameters: {'n_layers': 1, 'input_chunk_length': 69, 'hidden_dim': 171, 'learning_rate': 1.4913491938817215e-05, 'batch_size': 64, 'training_length': 297}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 135 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:25,071] Trial 75 finished with value: 438.5242614746094 and parameters: {'n_layers': 1, 'input_chunk_length': 84, 'hidden_dim': 119, 'learning_rate': 2.8864534515973316e-05, 'batch_size': 64, 'training_length': 124}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 136 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:25,809] Trial 76 finished with value: 454.2904052734375 and parameters: {'n_layers': 1, 'input_chunk_length': 97, 'hidden_dim': 182, 'learning_rate': 3.462411259023212e-06, 'batch_size': 64, 'training_length': 143}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 137 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:26,578] Trial 77 finished with value: 455.11669921875 and parameters: {'n_layers': 1, 'input_chunk_length': 75, 'hidden_dim': 166, 'learning_rate': 2.2221561681047586e-05, 'batch_size': 64, 'training_length': 179}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 138 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:27,353] Trial 78 finished with value: 436.8536682128906 and parameters: {'n_layers': 1, 'input_chunk_length': 87, 'hidden_dim': 191, 'learning_rate': 5.204480753570923e-06, 'batch_size': 64, 'training_length': 166}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 139 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:28,185] Trial 79 finished with value: 506.7777404785156 and parameters: {'n_layers': 1, 'input_chunk_length': 26, 'hidden_dim': 173, 'learning_rate': 1.2960986803580247e-05, 'batch_size': 64, 'training_length': 243}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 140 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:29,436] Trial 80 finished with value: 535.5703735351562 and parameters: {'n_layers': 1, 'input_chunk_length': 77, 'hidden_dim': 198, 'learning_rate': 1.669843380973916e-06, 'batch_size': 16, 'training_length': 347}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 141 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:30,238] Trial 81 finished with value: 360.9739990234375 and parameters: {'n_layers': 1, 'input_chunk_length': 81, 'hidden_dim': 185, 'learning_rate': 6.72247665141614e-06, 'batch_size': 64, 'training_length': 192}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 142 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:31,051] Trial 82 finished with value: 473.0662536621094 and parameters: {'n_layers': 1, 'input_chunk_length': 82, 'hidden_dim': 178, 'learning_rate': 4.286098448972758e-06, 'batch_size': 64, 'training_length': 209}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 143 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:31,860] Trial 83 finished with value: 361.8990478515625 and parameters: {'n_layers': 1, 'input_chunk_length': 79, 'hidden_dim': 185, 'learning_rate': 8.037973620047792e-06, 'batch_size': 64, 'training_length': 198}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 144 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:32,647] Trial 84 finished with value: 497.2649841308594 and parameters: {'n_layers': 1, 'input_chunk_length': 69, 'hidden_dim': 189, 'learning_rate': 5.7532187582474944e-06, 'batch_size': 64, 'training_length': 174}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 145 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:33,515] Trial 85 finished with value: 572.756591796875 and parameters: {'n_layers': 1, 'input_chunk_length': 90, 'hidden_dim': 175, 'learning_rate': 1.049926564688058e-05, 'batch_size': 64, 'training_length': 273}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 146 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:34,376] Trial 86 finished with value: 453.8860778808594 and parameters: {'n_layers': 1, 'input_chunk_length': 47, 'hidden_dim': 182, 'learning_rate': 2.069141382801484e-06, 'batch_size': 64, 'training_length': 259}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 147 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:35,450] Trial 87 finished with value: 708.1780395507812 and parameters: {'n_layers': 1, 'input_chunk_length': 73, 'hidden_dim': 195, 'learning_rate': 1.079865350136242e-06, 'batch_size': 32, 'training_length': 500}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 148 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:36,182] Trial 88 finished with value: 395.54290771484375 and parameters: {'n_layers': 1, 'input_chunk_length': 31, 'hidden_dim': 200, 'learning_rate': 1.7121435356164118e-05, 'batch_size': 64, 'training_length': 280}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 149 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:36,878] Trial 89 finished with value: 618.7561645507812 and parameters: {'n_layers': 1, 'input_chunk_length': 18, 'hidden_dim': 179, 'learning_rate': 4.101143277293298e-06, 'batch_size': 64, 'training_length': 110}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 150 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:37,661] Trial 90 finished with value: 384.0667419433594 and parameters: {'n_layers': 1, 'input_chunk_length': 86, 'hidden_dim': 161, 'learning_rate': 3.775060627100395e-05, 'batch_size': 64, 'training_length': 197}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 151 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:38,494] Trial 91 finished with value: 650.4539184570312 and parameters: {'n_layers': 1, 'input_chunk_length': 83, 'hidden_dim': 187, 'learning_rate': 6.987859019970422e-06, 'batch_size': 64, 'training_length': 217}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 152 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:39,230] Trial 92 finished with value: 411.1503601074219 and parameters: {'n_layers': 1, 'input_chunk_length': 80, 'hidden_dim': 184, 'learning_rate': 7.3547654438240745e-06, 'batch_size': 64, 'training_length': 142}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 153 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:40,019] Trial 93 finished with value: 469.1543884277344 and parameters: {'n_layers': 1, 'input_chunk_length': 81, 'hidden_dim': 165, 'learning_rate': 3.036380403057307e-06, 'batch_size': 64, 'training_length': 190}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 154 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:40,779] Trial 94 finished with value: 437.7747497558594 and parameters: {'n_layers': 1, 'input_chunk_length': 77, 'hidden_dim': 191, 'learning_rate': 8.728286981859333e-06, 'batch_size': 64, 'training_length': 154}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 155 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:41,601] Trial 95 finished with value: 506.6565246582031 and parameters: {'n_layers': 1, 'input_chunk_length': 60, 'hidden_dim': 173, 'learning_rate': 1.2087032895611134e-05, 'batch_size': 64, 'training_length': 219}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 156 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:42,453] Trial 96 finished with value: 475.6917724609375 and parameters: {'n_layers': 1, 'input_chunk_length': 86, 'hidden_dim': 178, 'learning_rate': 1.978159470560719e-05, 'batch_size': 64, 'training_length': 239}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 157 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:43,242] Trial 97 finished with value: 410.24188232421875 and parameters: {'n_layers': 1, 'input_chunk_length': 92, 'hidden_dim': 184, 'learning_rate': 2.637332876631202e-05, 'batch_size': 64, 'training_length': 184}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 158 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:44,938] Trial 98 finished with value: 436.8661193847656 and parameters: {'n_layers': 1, 'input_chunk_length': 74, 'hidden_dim': 188, 'learning_rate': 6.046787654301937e-06, 'batch_size': 16, 'training_length': 481}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 159 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:45,646] Trial 99 finished with value: 435.60736083984375 and parameters: {'n_layers': 1, 'input_chunk_length': 81, 'hidden_dim': 153, 'learning_rate': 1.5984671825842064e-05, 'batch_size': 64, 'training_length': 163}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 160 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:46,594] Trial 100 finished with value: 490.4667663574219 and parameters: {'n_layers': 1, 'input_chunk_length': 65, 'hidden_dim': 169, 'learning_rate': 1.1338894653814357e-05, 'batch_size': 64, 'training_length': 364}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 161 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:47,256] Trial 101 finished with value: 486.7205505371094 and parameters: {'n_layers': 1, 'input_chunk_length': 78, 'hidden_dim': 194, 'learning_rate': 5.112997312503929e-06, 'batch_size': 64, 'training_length': 138}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 162 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:48,014] Trial 102 finished with value: 453.9635925292969 and parameters: {'n_layers': 1, 'input_chunk_length': 88, 'hidden_dim': 181, 'learning_rate': 6.648365238188681e-06, 'batch_size': 64, 'training_length': 153}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 163 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:48,733] Trial 103 finished with value: 438.41558837890625 and parameters: {'n_layers': 1, 'input_chunk_length': 76, 'hidden_dim': 191, 'learning_rate': 8.579171215842364e-06, 'batch_size': 64, 'training_length': 123}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 164 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:49,760] Trial 104 finished with value: 413.81597900390625 and parameters: {'n_layers': 1, 'input_chunk_length': 84, 'hidden_dim': 184, 'learning_rate': 3.4439312975130746e-06, 'batch_size': 64, 'training_length': 428}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 165 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:50,544] Trial 105 finished with value: 507.97235107421875 and parameters: {'n_layers': 1, 'input_chunk_length': 71, 'hidden_dim': 173, 'learning_rate': 1.3498898292239635e-05, 'batch_size': 32, 'training_length': 128}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 166 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:52,295] Trial 106 finished with value: 486.72235107421875 and parameters: {'n_layers': 2, 'dropout': 0.11752329634612879, 'input_chunk_length': 80, 'hidden_dim': 186, 'learning_rate': 2.4141401866387473e-06, 'batch_size': 64, 'training_length': 467}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 167 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:53,094] Trial 107 finished with value: 404.51702880859375 and parameters: {'n_layers': 1, 'input_chunk_length': 89, 'hidden_dim': 197, 'learning_rate': 4.4159413587130855e-06, 'batch_size': 64, 'training_length': 399}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 168 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:54,013] Trial 108 finished with value: 570.3609619140625 and parameters: {'n_layers': 1, 'input_chunk_length': 95, 'hidden_dim': 175, 'learning_rate': 1.0072830390586643e-05, 'batch_size': 64, 'training_length': 317}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 169 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:54,745] Trial 109 finished with value: 598.8641357421875 and parameters: {'n_layers': 1, 'input_chunk_length': 83, 'hidden_dim': 177, 'learning_rate': 8.956484622689537e-05, 'batch_size': 64, 'training_length': 135}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 170 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:55,565] Trial 110 finished with value: 587.8803100585938 and parameters: {'n_layers': 1, 'input_chunk_length': 78, 'hidden_dim': 159, 'learning_rate': 7.55885171776015e-06, 'batch_size': 64, 'training_length': 299}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 171 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:56,367] Trial 111 finished with value: 411.30596923828125 and parameters: {'n_layers': 1, 'input_chunk_length': 80, 'hidden_dim': 184, 'learning_rate': 8.07569785454653e-06, 'batch_size': 64, 'training_length': 194}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 172 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:57,190] Trial 112 finished with value: 650.807861328125 and parameters: {'n_layers': 1, 'input_chunk_length': 85, 'hidden_dim': 187, 'learning_rate': 2.0588850982055064e-07, 'batch_size': 64, 'training_length': 206}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 173 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:57,964] Trial 113 finished with value: 541.591552734375 and parameters: {'n_layers': 1, 'input_chunk_length': 73, 'hidden_dim': 180, 'learning_rate': 5.495686450139644e-06, 'batch_size': 64, 'training_length': 172}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 174 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:58,796] Trial 114 finished with value: 383.6299743652344 and parameters: {'n_layers': 1, 'input_chunk_length': 78, 'hidden_dim': 192, 'learning_rate': 0.00016364198895302875, 'batch_size': 64, 'training_length': 200}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 175 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:21:59,582] Trial 115 finished with value: 410.737548828125 and parameters: {'n_layers': 1, 'input_chunk_length': 70, 'hidden_dim': 184, 'learning_rate': 1.3874093348972118e-05, 'batch_size': 64, 'training_length': 181}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 176 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:22:00,451] Trial 116 finished with value: 508.8271484375 and parameters: {'n_layers': 1, 'input_chunk_length': 82, 'hidden_dim': 168, 'learning_rate': 3.608578461986146e-06, 'batch_size': 64, 'training_length': 286}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 177 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:22:02,088] Trial 117 finished with value: 554.2052001953125 and parameters: {'n_layers': 1, 'input_chunk_length': 76, 'hidden_dim': 177, 'learning_rate': 6.472061955230994e-06, 'batch_size': 16, 'training_length': 452}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 178 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:22:02,747] Trial 118 finished with value: 396.81402587890625 and parameters: {'n_layers': 1, 'input_chunk_length': 74, 'hidden_dim': 171, 'learning_rate': 2.031423101183901e-05, 'batch_size': 64, 'training_length': 83}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 179 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:22:03,499] Trial 119 finished with value: 497.2332763671875 and parameters: {'n_layers': 1, 'input_chunk_length': 86, 'hidden_dim': 189, 'learning_rate': 1.8307710701267077e-06, 'batch_size': 64, 'training_length': 147}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 180 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:22:04,353] Trial 120 finished with value: 454.5715637207031 and parameters: {'n_layers': 1, 'input_chunk_length': 82, 'hidden_dim': 181, 'learning_rate': 2.6559978693341374e-06, 'batch_size': 64, 'training_length': 234}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 181 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:22:05,266] Trial 121 finished with value: 373.6739807128906 and parameters: {'n_layers': 1, 'input_chunk_length': 67, 'hidden_dim': 161, 'learning_rate': 1.1594585901983076e-06, 'batch_size': 32, 'training_length': 223}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 182 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:22:06,100] Trial 122 finished with value: 558.21875 and parameters: {'n_layers': 1, 'input_chunk_length': 79, 'hidden_dim': 166, 'learning_rate': 0.0008542103527339257, 'batch_size': 32, 'training_length': 164}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 183 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:22:06,961] Trial 123 finished with value: 348.0966491699219 and parameters: {'n_layers': 1, 'input_chunk_length': 72, 'hidden_dim': 164, 'learning_rate': 7.113835397605594e-07, 'batch_size': 32, 'training_length': 185}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 184 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:22:07,852] Trial 124 finished with value: 558.0416870117188 and parameters: {'n_layers': 1, 'input_chunk_length': 76, 'hidden_dim': 163, 'learning_rate': 4.4080306932975495e-07, 'batch_size': 32, 'training_length': 207}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 185 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:22:08,654] Trial 125 finished with value: 453.136474609375 and parameters: {'n_layers': 1, 'input_chunk_length': 73, 'hidden_dim': 140, 'learning_rate': 6.871086583970715e-07, 'batch_size': 32, 'training_length': 182}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 186 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:22:09,473] Trial 126 finished with value: 486.7264709472656 and parameters: {'n_layers': 1, 'input_chunk_length': 79, 'hidden_dim': 194, 'learning_rate': 1.0063520181179181e-07, 'batch_size': 32, 'training_length': 200}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 187 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:22:10,467] Trial 127 finished with value: 550.619873046875 and parameters: {'n_layers': 1, 'input_chunk_length': 84, 'hidden_dim': 186, 'learning_rate': 9.356582456452874e-06, 'batch_size': 64, 'training_length': 378}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 188 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:22:11,136] Trial 128 finished with value: 656.246826171875 and parameters: {'n_layers': 1, 'input_chunk_length': 88, 'hidden_dim': 157, 'learning_rate': 2.5819124376863213e-07, 'batch_size': 64, 'training_length': 114}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 189 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:22:12,073] Trial 129 finished with value: 492.2391052246094 and parameters: {'n_layers': 1, 'input_chunk_length': 71, 'hidden_dim': 174, 'learning_rate': 1.167176175156547e-05, 'batch_size': 64, 'training_length': 344}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
/pfs/data5/home/tu/tu_tu/tu_zxoul27/micromamba/envs/power/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss did not improve in the last 190 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:22:12,754] Trial 130 finished with value: 400.71771240234375 and parameters: {'n_layers': 1, 'input_chunk_length': 64, 'hidden_dim': 200, 'learning_rate': 2.621685379730929e-05, 'batch_size': 64, 'training_length': 171}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 191 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:22:13,627] Trial 131 finished with value: 394.1368408203125 and parameters: {'n_layers': 1, 'input_chunk_length': 76, 'hidden_dim': 171, 'learning_rate': 5.296370218428486e-07, 'batch_size': 32, 'training_length': 188}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
Monitored metric val_loss did not improve in the last 192 records. Best score: -0.671. Signaling Trainer to stop.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
[I 2024-10-12 14:22:14,453] Trial 132 finished with value: 557.9988403320312 and parameters: {'n_layers': 1, 'input_chunk_length': 69, 'hidden_dim': 163, 'learning_rate': 8.444808670438666e-07, 'batch_size': 32, 'training_length': 155}. Best is trial 54 with value: 344.3180236816406.
Specified past encoders in `add_encoders` at model creation but model does not accept past covariates. past encoders will be ignored.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
