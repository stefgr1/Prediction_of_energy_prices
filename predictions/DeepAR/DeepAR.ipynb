{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepAR / Probalistic RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data \n",
    "def load_and_prepare_data(file_path):\n",
    "    \"\"\"\n",
    "    Load energy prices data from a CSV file, ensure chronological order, and convert 'Date' to datetime.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    df.sort_values('Date', inplace=True)\n",
    "    # Convert 'date' column to datetime\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    #df.set_index('Date', inplace=True)\n",
    "    df = pd.DataFrame(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Day_ahead_price (€/MWh)</th>\n",
       "      <th>Solar_radiation (W/m2)</th>\n",
       "      <th>Wind_speed (m/s)</th>\n",
       "      <th>Temperature (°C)</th>\n",
       "      <th>Biomass (GWh)</th>\n",
       "      <th>Hard_coal (GWh)</th>\n",
       "      <th>Hydro (GWh)</th>\n",
       "      <th>Lignite (GWh)</th>\n",
       "      <th>Natural_gas (GWh)</th>\n",
       "      <th>Other (GWh)</th>\n",
       "      <th>Pumped_storage_generation (GWh)</th>\n",
       "      <th>Solar_energy (GWh)</th>\n",
       "      <th>Wind_offshore (GWh)</th>\n",
       "      <th>Wind_onshore (GWh)</th>\n",
       "      <th>Net_total_export_import (GWh)</th>\n",
       "      <th>BEV_vehicles</th>\n",
       "      <th>Oil_price (EUR)</th>\n",
       "      <th>TTF_gas_price (€/MWh)</th>\n",
       "      <th>Nuclear_energy (GWh)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>18.19</td>\n",
       "      <td>14.75</td>\n",
       "      <td>4.95</td>\n",
       "      <td>8.39</td>\n",
       "      <td>98.605</td>\n",
       "      <td>108.454</td>\n",
       "      <td>51.011</td>\n",
       "      <td>325.337</td>\n",
       "      <td>188.811</td>\n",
       "      <td>54.040</td>\n",
       "      <td>19.314</td>\n",
       "      <td>6.263</td>\n",
       "      <td>3.404</td>\n",
       "      <td>235.467</td>\n",
       "      <td>54.662</td>\n",
       "      <td>6</td>\n",
       "      <td>99.64</td>\n",
       "      <td>21.10</td>\n",
       "      <td>250.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-01-02</td>\n",
       "      <td>33.82</td>\n",
       "      <td>15.12</td>\n",
       "      <td>5.00</td>\n",
       "      <td>7.41</td>\n",
       "      <td>98.605</td>\n",
       "      <td>222.656</td>\n",
       "      <td>51.862</td>\n",
       "      <td>343.168</td>\n",
       "      <td>229.293</td>\n",
       "      <td>54.166</td>\n",
       "      <td>28.892</td>\n",
       "      <td>6.312</td>\n",
       "      <td>3.350</td>\n",
       "      <td>231.772</td>\n",
       "      <td>-64.477</td>\n",
       "      <td>6</td>\n",
       "      <td>100.04</td>\n",
       "      <td>20.00</td>\n",
       "      <td>258.671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-01-03</td>\n",
       "      <td>35.03</td>\n",
       "      <td>31.88</td>\n",
       "      <td>7.77</td>\n",
       "      <td>5.23</td>\n",
       "      <td>98.605</td>\n",
       "      <td>162.204</td>\n",
       "      <td>48.851</td>\n",
       "      <td>336.773</td>\n",
       "      <td>241.297</td>\n",
       "      <td>53.518</td>\n",
       "      <td>21.072</td>\n",
       "      <td>24.226</td>\n",
       "      <td>7.292</td>\n",
       "      <td>504.484</td>\n",
       "      <td>-35.078</td>\n",
       "      <td>6</td>\n",
       "      <td>100.44</td>\n",
       "      <td>20.90</td>\n",
       "      <td>271.495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>32.16</td>\n",
       "      <td>25.21</td>\n",
       "      <td>8.04</td>\n",
       "      <td>4.78</td>\n",
       "      <td>98.605</td>\n",
       "      <td>189.633</td>\n",
       "      <td>47.101</td>\n",
       "      <td>323.976</td>\n",
       "      <td>252.289</td>\n",
       "      <td>52.194</td>\n",
       "      <td>28.300</td>\n",
       "      <td>14.157</td>\n",
       "      <td>7.828</td>\n",
       "      <td>541.528</td>\n",
       "      <td>22.924</td>\n",
       "      <td>6</td>\n",
       "      <td>103.15</td>\n",
       "      <td>21.40</td>\n",
       "      <td>270.613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>20.35</td>\n",
       "      <td>13.46</td>\n",
       "      <td>9.98</td>\n",
       "      <td>4.23</td>\n",
       "      <td>98.605</td>\n",
       "      <td>175.733</td>\n",
       "      <td>45.854</td>\n",
       "      <td>327.502</td>\n",
       "      <td>259.018</td>\n",
       "      <td>52.179</td>\n",
       "      <td>31.887</td>\n",
       "      <td>4.728</td>\n",
       "      <td>8.280</td>\n",
       "      <td>572.819</td>\n",
       "      <td>35.618</td>\n",
       "      <td>6</td>\n",
       "      <td>103.92</td>\n",
       "      <td>21.30</td>\n",
       "      <td>287.555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>2024-07-24</td>\n",
       "      <td>66.61</td>\n",
       "      <td>225.04</td>\n",
       "      <td>3.47</td>\n",
       "      <td>17.54</td>\n",
       "      <td>110.007</td>\n",
       "      <td>43.469</td>\n",
       "      <td>85.857</td>\n",
       "      <td>199.246</td>\n",
       "      <td>194.291</td>\n",
       "      <td>54.026</td>\n",
       "      <td>20.934</td>\n",
       "      <td>325.285</td>\n",
       "      <td>49.360</td>\n",
       "      <td>179.921</td>\n",
       "      <td>-168.705</td>\n",
       "      <td>992</td>\n",
       "      <td>75.75</td>\n",
       "      <td>32.63</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>2024-07-25</td>\n",
       "      <td>78.34</td>\n",
       "      <td>272.71</td>\n",
       "      <td>2.12</td>\n",
       "      <td>17.85</td>\n",
       "      <td>110.410</td>\n",
       "      <td>50.676</td>\n",
       "      <td>82.632</td>\n",
       "      <td>195.983</td>\n",
       "      <td>209.610</td>\n",
       "      <td>52.963</td>\n",
       "      <td>18.766</td>\n",
       "      <td>394.116</td>\n",
       "      <td>51.053</td>\n",
       "      <td>42.885</td>\n",
       "      <td>-194.496</td>\n",
       "      <td>992</td>\n",
       "      <td>76.36</td>\n",
       "      <td>31.70</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>2024-07-26</td>\n",
       "      <td>93.04</td>\n",
       "      <td>172.33</td>\n",
       "      <td>2.60</td>\n",
       "      <td>19.09</td>\n",
       "      <td>110.852</td>\n",
       "      <td>42.333</td>\n",
       "      <td>79.531</td>\n",
       "      <td>205.273</td>\n",
       "      <td>205.773</td>\n",
       "      <td>52.616</td>\n",
       "      <td>19.081</td>\n",
       "      <td>256.246</td>\n",
       "      <td>40.449</td>\n",
       "      <td>129.267</td>\n",
       "      <td>-241.786</td>\n",
       "      <td>993</td>\n",
       "      <td>75.21</td>\n",
       "      <td>32.20</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>2024-07-27</td>\n",
       "      <td>80.74</td>\n",
       "      <td>176.67</td>\n",
       "      <td>2.05</td>\n",
       "      <td>19.63</td>\n",
       "      <td>110.479</td>\n",
       "      <td>33.307</td>\n",
       "      <td>74.958</td>\n",
       "      <td>184.012</td>\n",
       "      <td>216.412</td>\n",
       "      <td>50.927</td>\n",
       "      <td>18.856</td>\n",
       "      <td>244.051</td>\n",
       "      <td>2.180</td>\n",
       "      <td>32.001</td>\n",
       "      <td>-251.655</td>\n",
       "      <td>992</td>\n",
       "      <td>74.79</td>\n",
       "      <td>32.90</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>2024-07-28</td>\n",
       "      <td>43.96</td>\n",
       "      <td>235.92</td>\n",
       "      <td>3.48</td>\n",
       "      <td>18.17</td>\n",
       "      <td>110.731</td>\n",
       "      <td>11.629</td>\n",
       "      <td>74.669</td>\n",
       "      <td>141.084</td>\n",
       "      <td>158.503</td>\n",
       "      <td>51.515</td>\n",
       "      <td>12.365</td>\n",
       "      <td>345.645</td>\n",
       "      <td>24.192</td>\n",
       "      <td>171.537</td>\n",
       "      <td>-65.418</td>\n",
       "      <td>992</td>\n",
       "      <td>74.37</td>\n",
       "      <td>33.25</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4593 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Day_ahead_price (€/MWh)  Solar_radiation (W/m2)  \\\n",
       "0   2012-01-01                    18.19                   14.75   \n",
       "1   2012-01-02                    33.82                   15.12   \n",
       "2   2012-01-03                    35.03                   31.88   \n",
       "3   2012-01-04                    32.16                   25.21   \n",
       "4   2012-01-05                    20.35                   13.46   \n",
       "..         ...                      ...                     ...   \n",
       "754 2024-07-24                    66.61                  225.04   \n",
       "755 2024-07-25                    78.34                  272.71   \n",
       "756 2024-07-26                    93.04                  172.33   \n",
       "757 2024-07-27                    80.74                  176.67   \n",
       "758 2024-07-28                    43.96                  235.92   \n",
       "\n",
       "     Wind_speed (m/s)  Temperature (°C)  Biomass (GWh)  Hard_coal (GWh)  \\\n",
       "0                4.95              8.39         98.605          108.454   \n",
       "1                5.00              7.41         98.605          222.656   \n",
       "2                7.77              5.23         98.605          162.204   \n",
       "3                8.04              4.78         98.605          189.633   \n",
       "4                9.98              4.23         98.605          175.733   \n",
       "..                ...               ...            ...              ...   \n",
       "754              3.47             17.54        110.007           43.469   \n",
       "755              2.12             17.85        110.410           50.676   \n",
       "756              2.60             19.09        110.852           42.333   \n",
       "757              2.05             19.63        110.479           33.307   \n",
       "758              3.48             18.17        110.731           11.629   \n",
       "\n",
       "     Hydro (GWh)  Lignite (GWh)  Natural_gas (GWh)  Other (GWh)  \\\n",
       "0         51.011        325.337            188.811       54.040   \n",
       "1         51.862        343.168            229.293       54.166   \n",
       "2         48.851        336.773            241.297       53.518   \n",
       "3         47.101        323.976            252.289       52.194   \n",
       "4         45.854        327.502            259.018       52.179   \n",
       "..           ...            ...                ...          ...   \n",
       "754       85.857        199.246            194.291       54.026   \n",
       "755       82.632        195.983            209.610       52.963   \n",
       "756       79.531        205.273            205.773       52.616   \n",
       "757       74.958        184.012            216.412       50.927   \n",
       "758       74.669        141.084            158.503       51.515   \n",
       "\n",
       "     Pumped_storage_generation (GWh)  Solar_energy (GWh)  Wind_offshore (GWh)  \\\n",
       "0                             19.314               6.263                3.404   \n",
       "1                             28.892               6.312                3.350   \n",
       "2                             21.072              24.226                7.292   \n",
       "3                             28.300              14.157                7.828   \n",
       "4                             31.887               4.728                8.280   \n",
       "..                               ...                 ...                  ...   \n",
       "754                           20.934             325.285               49.360   \n",
       "755                           18.766             394.116               51.053   \n",
       "756                           19.081             256.246               40.449   \n",
       "757                           18.856             244.051                2.180   \n",
       "758                           12.365             345.645               24.192   \n",
       "\n",
       "     Wind_onshore (GWh)  Net_total_export_import (GWh)  BEV_vehicles  \\\n",
       "0               235.467                         54.662             6   \n",
       "1               231.772                        -64.477             6   \n",
       "2               504.484                        -35.078             6   \n",
       "3               541.528                         22.924             6   \n",
       "4               572.819                         35.618             6   \n",
       "..                  ...                            ...           ...   \n",
       "754             179.921                       -168.705           992   \n",
       "755              42.885                       -194.496           992   \n",
       "756             129.267                       -241.786           993   \n",
       "757              32.001                       -251.655           992   \n",
       "758             171.537                        -65.418           992   \n",
       "\n",
       "     Oil_price (EUR)  TTF_gas_price (€/MWh)  Nuclear_energy (GWh)  \n",
       "0              99.64                  21.10               250.979  \n",
       "1             100.04                  20.00               258.671  \n",
       "2             100.44                  20.90               271.495  \n",
       "3             103.15                  21.40               270.613  \n",
       "4             103.92                  21.30               287.555  \n",
       "..               ...                    ...                   ...  \n",
       "754            75.75                  32.63                 0.000  \n",
       "755            76.36                  31.70                 0.000  \n",
       "756            75.21                  32.20                 0.000  \n",
       "757            74.79                  32.90                 0.000  \n",
       "758            74.37                  33.25                 0.000  \n",
       "\n",
       "[4593 rows x 20 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in the train and test data\n",
    "train_df = load_and_prepare_data('../../data/Final_data/train_df.csv')\n",
    "test_df = load_and_prepare_data('../../data/Final_data/test_df.csv')\n",
    "\n",
    "# Concatenate the train and test data\n",
    "df = pd.concat([train_df, test_df])\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Create a time series object\n",
    "#series_train = TimeSeries.from_dataframe(train_df, 'Date', 'Day_ahead_price (€/MWh)').astype('float32')\n",
    "#series_test = TimeSeries.from_dataframe(test_df, 'Date', 'Day_ahead_price (€/MWh)').astype('float32')\n",
    "\n",
    "# Show \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the future covariates columns from your dataframe\n",
    "future_covariates_columns = ['Solar_radiation (W/m2)', 'Wind_speed (m/s)', 'Temperature (°C)', \n",
    "                             'Biomass (GWh)', 'Hard_coal (GWh)', 'Hydro (GWh)', 'Lignite (GWh)', \n",
    "                             'Natural_gas (GWh)', 'Other (GWh)', 'Pumped_storage_generation (GWh)', \n",
    "                             'Solar_energy (GWh)', 'Wind_offshore (GWh)', 'Wind_onshore (GWh)', \n",
    "                             'Net_total_export_import (GWh)', 'BEV_vehicles', 'Oil_price (EUR)', \n",
    "                             'TTF_gas_price (€/MWh)', 'Nuclear_energy (GWh)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import optuna\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from darts import TimeSeries\n",
    "from darts.utils.callbacks import TFMProgressBar\n",
    "from darts.utils.statistics import check_seasonality, plot_acf\n",
    "import darts.utils.timeseries_generation as tg\n",
    "from darts.utils.likelihood_models import GaussianLikelihood\n",
    "from darts.models import RNNModel\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "from darts.timeseries import concatenate\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-19 11:07:45,760] A new study created in memory with name: no-name-6e30a061-fa4c-4829-a140-3032af822e01\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n",
      "ValueError: For the given forecasting case, the provided future covariates at dataset index `0` do not extend far enough into the past. The future covariates must start at time step `2022-05-16 00:00:00`, whereas now they start at time step `2022-07-01 00:00:00`.\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/8w/b_0gc01d70g6h4k62sb7ytyw0000gn/T/ipykernel_47611/2817176609.py\", line 104, in objective\n",
      "    forecast_val = model.predict(\n",
      "  File \"/Users/skyfano/Documents/Masterarbeit/Prediction_of_energy_prices/master_thesis/lib/python3.10/site-packages/darts/utils/torch.py\", line 103, in decorator\n",
      "    return decorated(self, *args, **kwargs)\n",
      "  File \"/Users/skyfano/Documents/Masterarbeit/Prediction_of_energy_prices/master_thesis/lib/python3.10/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 1465, in predict\n",
      "    predictions = self.predict_from_dataset(\n",
      "  File \"/Users/skyfano/Documents/Masterarbeit/Prediction_of_energy_prices/master_thesis/lib/python3.10/site-packages/darts/utils/torch.py\", line 103, in decorator\n",
      "    return decorated(self, *args, **kwargs)\n",
      "  File \"/Users/skyfano/Documents/Masterarbeit/Prediction_of_energy_prices/master_thesis/lib/python3.10/site-packages/darts/models/forecasting/torch_forecasting_model.py\", line 1559, in predict_from_dataset\n",
      "    self._verify_predict_sample(input_series_dataset[0])\n",
      "  File \"/Users/skyfano/Documents/Masterarbeit/Prediction_of_energy_prices/master_thesis/lib/python3.10/site-packages/darts/utils/data/inference_dataset.py\", line 599, in __getitem__\n",
      "    ) = self.ds_past[idx]\n",
      "  File \"/Users/skyfano/Documents/Masterarbeit/Prediction_of_energy_prices/master_thesis/lib/python3.10/site-packages/darts/utils/data/inference_dataset.py\", line 418, in __getitem__\n",
      "    return self.ds[idx]\n",
      "  File \"/Users/skyfano/Documents/Masterarbeit/Prediction_of_energy_prices/master_thesis/lib/python3.10/site-packages/darts/utils/data/inference_dataset.py\", line 291, in __getitem__\n",
      "    covariate_start, covariate_end = self._covariate_indexer(\n",
      "  File \"/Users/skyfano/Documents/Masterarbeit/Prediction_of_energy_prices/master_thesis/lib/python3.10/site-packages/darts/utils/data/inference_dataset.py\", line 98, in _covariate_indexer\n",
      "    raise_log(\n",
      "  File \"/Users/skyfano/Documents/Masterarbeit/Prediction_of_energy_prices/master_thesis/lib/python3.10/site-packages/darts/logging.py\", line 132, in raise_log\n",
      "    raise exception\n",
      "ValueError: For the given forecasting case, the provided future covariates at dataset index `0` do not extend far enough into the past. The future covariates must start at time step `2022-05-16 00:00:00`, whereas now they start at time step `2022-07-01 00:00:00`.\n",
      "[I 2024-09-19 11:07:51,867] Trial 0 finished with value: inf and parameters: {'hidden_dim': 21, 'n_layers': 1, 'dropout': 0.44776392192658937, 'batch_size': 64, 'learning_rate': 0.0078545751357899, 'input_chunk_length': 46}. Best is trial 0 with value: inf.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | rnn             | LSTM             | 3.5 K  | train\n",
      "6 | V               | Linear           | 44     | train\n",
      "-------------------------------------------------------------\n",
      "3.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.6 K     Total params\n",
      "0.014     Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception during model training: For the given forecasting case, the provided future covariates at dataset index `0` do not extend far enough into the past. The future covariates must start at time step `2022-05-16 00:00:00`, whereas now they start at time step `2022-07-01 00:00:00`.\n",
      "Best hyperparameters:\n",
      "  hidden_dim: 21\n",
      "  n_layers: 1\n",
      "  dropout: 0.44776392192658937\n",
      "  batch_size: 64\n",
      "  learning_rate: 0.0078545751357899\n",
      "  input_chunk_length: 46\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b52c836fdf3a49b083873259e7eb8601",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "ValueError: For the given forecasting case, the provided future covariates at dataset index `0` do not extend far enough into the past. The future covariates must start at time step `2022-05-16 00:00:00`, whereas now they start at time step `2022-07-01 00:00:00`.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "For the given forecasting case, the provided future covariates at dataset index `0` do not extend far enough into the past. The future covariates must start at time step `2022-05-16 00:00:00`, whereas now they start at time step `2022-07-01 00:00:00`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 164\u001b[0m\n\u001b[1;32m    161\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mlen\u001b[39m(series_test_scaled), max_n)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;66;03m# Make predictions on the test set\u001b[39;00m\n\u001b[0;32m--> 164\u001b[0m forecast \u001b[38;5;241m=\u001b[39m \u001b[43mbest_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfuture_covariates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfuture_covariates_test_scaled\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m# Adjust test_series to match forecast length\u001b[39;00m\n\u001b[1;32m    170\u001b[0m test_series \u001b[38;5;241m=\u001b[39m test_series[:n]\n",
      "File \u001b[0;32m~/Documents/Masterarbeit/Prediction_of_energy_prices/master_thesis/lib/python3.10/site-packages/darts/utils/torch.py:103\u001b[0m, in \u001b[0;36mrandom_method.<locals>.decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m fork_rng():\n\u001b[1;32m    102\u001b[0m     manual_seed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_random_instance\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, high\u001b[38;5;241m=\u001b[39mMAX_TORCH_SEED_VALUE))\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdecorated\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Masterarbeit/Prediction_of_energy_prices/master_thesis/lib/python3.10/site-packages/darts/models/forecasting/torch_forecasting_model.py:1465\u001b[0m, in \u001b[0;36mTorchForecastingModel.predict\u001b[0;34m(self, n, series, past_covariates, future_covariates, trainer, batch_size, verbose, n_jobs, roll_size, num_samples, dataloader_kwargs, mc_dropout, predict_likelihood_parameters, show_warnings)\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[1;32m   1447\u001b[0m     n,\n\u001b[1;32m   1448\u001b[0m     series,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1453\u001b[0m     show_warnings\u001b[38;5;241m=\u001b[39mshow_warnings,\n\u001b[1;32m   1454\u001b[0m )\n\u001b[1;32m   1456\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_inference_dataset(\n\u001b[1;32m   1457\u001b[0m     target\u001b[38;5;241m=\u001b[39mseries,\n\u001b[1;32m   1458\u001b[0m     n\u001b[38;5;241m=\u001b[39mn,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1462\u001b[0m     bounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1463\u001b[0m )\n\u001b[0;32m-> 1465\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_from_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1466\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1467\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1468\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1469\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1470\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1471\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1472\u001b[0m \u001b[43m    \u001b[49m\u001b[43mroll_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mroll_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1473\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1474\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataloader_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloader_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmc_dropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmc_dropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpredict_likelihood_parameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredict_likelihood_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1477\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1479\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predictions[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m called_with_single_series \u001b[38;5;28;01melse\u001b[39;00m predictions\n",
      "File \u001b[0;32m~/Documents/Masterarbeit/Prediction_of_energy_prices/master_thesis/lib/python3.10/site-packages/darts/utils/torch.py:103\u001b[0m, in \u001b[0;36mrandom_method.<locals>.decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m fork_rng():\n\u001b[1;32m    102\u001b[0m     manual_seed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_random_instance\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, high\u001b[38;5;241m=\u001b[39mMAX_TORCH_SEED_VALUE))\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdecorated\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Masterarbeit/Prediction_of_energy_prices/master_thesis/lib/python3.10/site-packages/darts/models/forecasting/torch_forecasting_model.py:1559\u001b[0m, in \u001b[0;36mTorchForecastingModel.predict_from_dataset\u001b[0;34m(self, n, input_series_dataset, trainer, batch_size, verbose, n_jobs, roll_size, num_samples, dataloader_kwargs, mc_dropout, predict_likelihood_parameters)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verify_inference_dataset_type(input_series_dataset)\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# check that covariates and dimensions are matching what we had during training\u001b[39;00m\n\u001b[0;32m-> 1559\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verify_predict_sample(\u001b[43minput_series_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m   1561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m roll_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1562\u001b[0m     roll_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_chunk_length\n",
      "File \u001b[0;32m~/Documents/Masterarbeit/Prediction_of_energy_prices/master_thesis/lib/python3.10/site-packages/darts/utils/data/inference_dataset.py:599\u001b[0m, in \u001b[0;36mDualCovariatesInferenceDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;28mself\u001b[39m, idx\n\u001b[1;32m    584\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    590\u001b[0m     Union[pd\u001b[38;5;241m.\u001b[39mTimestamp, \u001b[38;5;28mint\u001b[39m],\n\u001b[1;32m    591\u001b[0m ]:\n\u001b[1;32m    592\u001b[0m     (\n\u001b[1;32m    593\u001b[0m         past_target,\n\u001b[1;32m    594\u001b[0m         historic_future_covariate,\n\u001b[1;32m    595\u001b[0m         _,\n\u001b[1;32m    596\u001b[0m         static_covariate,\n\u001b[1;32m    597\u001b[0m         ts_target,\n\u001b[1;32m    598\u001b[0m         pred_point,\n\u001b[0;32m--> 599\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mds_past\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    600\u001b[0m     _, future_covariate, _, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds_future[idx]\n\u001b[1;32m    601\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    602\u001b[0m         past_target,\n\u001b[1;32m    603\u001b[0m         historic_future_covariate,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    607\u001b[0m         pred_point,\n\u001b[1;32m    608\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/Masterarbeit/Prediction_of_energy_prices/master_thesis/lib/python3.10/site-packages/darts/utils/data/inference_dataset.py:418\u001b[0m, in \u001b[0;36mPastCovariatesInferenceDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;28mself\u001b[39m, idx: \u001b[38;5;28mint\u001b[39m\n\u001b[1;32m    410\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    416\u001b[0m     Union[pd\u001b[38;5;241m.\u001b[39mTimestamp, \u001b[38;5;28mint\u001b[39m],\n\u001b[1;32m    417\u001b[0m ]:\n\u001b[0;32m--> 418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mds\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Masterarbeit/Prediction_of_energy_prices/master_thesis/lib/python3.10/site-packages/darts/utils/data/inference_dataset.py:291\u001b[0m, in \u001b[0;36mGenericInferenceDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    286\u001b[0m covariate_series \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcovariates \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcovariates[series_idx]\n\u001b[1;32m    288\u001b[0m )\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m covariate_series \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;66;03m# get start and end indices (integer) of the covariates including historic and future parts\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m     covariate_start, covariate_end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_covariate_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseries_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_series\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime_index\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtarget_start_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_end\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_end\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcovariate_series\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcovariate_series\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcovariate_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcovariate_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_chunk_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_chunk_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_chunk_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_chunk_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_chunk_shift\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_chunk_shift\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;66;03m# extract covariate values and split into a past (historic) and future part\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     covariate \u001b[38;5;241m=\u001b[39m covariate_series\u001b[38;5;241m.\u001b[39mrandom_component_values(copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[\n\u001b[1;32m    305\u001b[0m         covariate_start:covariate_end\n\u001b[1;32m    306\u001b[0m     ]\n",
      "File \u001b[0;32m~/Documents/Masterarbeit/Prediction_of_energy_prices/master_thesis/lib/python3.10/site-packages/darts/utils/data/inference_dataset.py:98\u001b[0m, in \u001b[0;36mInferenceDataset._covariate_indexer\u001b[0;34m(target_idx, past_start, past_end, covariate_series, covariate_type, input_chunk_length, output_chunk_length, output_chunk_shift, n)\u001b[0m\n\u001b[1;32m     94\u001b[0m case_start \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     95\u001b[0m     future_start \u001b[38;5;28;01mif\u001b[39;00m covariate_type \u001b[38;5;129;01mis\u001b[39;00m CovariateType\u001b[38;5;241m.\u001b[39mFUTURE \u001b[38;5;28;01melse\u001b[39;00m past_start\n\u001b[1;32m     96\u001b[0m )\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m covariate_series\u001b[38;5;241m.\u001b[39mstart_time() \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m case_start:\n\u001b[0;32m---> 98\u001b[0m     \u001b[43mraise_log\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;167;43;01mValueError\u001b[39;49;00m\u001b[43m(\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFor the given forecasting case, the provided \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmain_covariate_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m covariates at \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    101\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdataset index `\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtarget_idx\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m` do not extend far enough into the past. The \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    102\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmain_covariate_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m covariates must start at time step `\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcase_start\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m`, whereas now \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    103\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthey start at time step `\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcovariate_series\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m`.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    104\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m covariate_series\u001b[38;5;241m.\u001b[39mend_time() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m future_end:\n\u001b[1;32m    108\u001b[0m     raise_log(\n\u001b[1;32m    109\u001b[0m         \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    110\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor the given forecasting horizon `n=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`, the provided \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmain_covariate_type\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m covariates \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    116\u001b[0m         logger\u001b[38;5;241m=\u001b[39mlogger,\n\u001b[1;32m    117\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/Masterarbeit/Prediction_of_energy_prices/master_thesis/lib/python3.10/site-packages/darts/logging.py:132\u001b[0m, in \u001b[0;36mraise_log\u001b[0;34m(exception, logger)\u001b[0m\n\u001b[1;32m    129\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(exception)\n\u001b[1;32m    130\u001b[0m logger\u001b[38;5;241m.\u001b[39merror(exception_type \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m message)\n\u001b[0;32m--> 132\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mValueError\u001b[0m: For the given forecasting case, the provided future covariates at dataset index `0` do not extend far enough into the past. The future covariates must start at time step `2022-05-16 00:00:00`, whereas now they start at time step `2022-07-01 00:00:00`."
     ]
    }
   ],
   "source": [
    "import traceback  # Add this import at the beginning\n",
    "import pandas as pd\n",
    "from darts import TimeSeries\n",
    "from darts.models import RNNModel\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "from darts.metrics import mape, mae, rmse, mse\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "# Create a time series object\n",
    "series_train = TimeSeries.from_dataframe(train_df, 'Date', 'Day_ahead_price (€/MWh)').astype('float32')\n",
    "series_test = TimeSeries.from_dataframe(test_df, 'Date', 'Day_ahead_price (€/MWh)').astype('float32')\n",
    "\n",
    "# Convert future covariates to TimeSeries objects\n",
    "future_covariates_train = TimeSeries.from_dataframe(train_df, 'Date', future_covariates_columns).astype('float32')\n",
    "future_covariates_test = TimeSeries.from_dataframe(test_df, 'Date', future_covariates_columns).astype('float32')\n",
    "\n",
    "# Determine required start date for future covariates\n",
    "max_input_chunk_length = 200  # Maximum input_chunk_length from your hyperparameter search\n",
    "required_start_date = series_test.start_time() - pd.DateOffset(days=(max_input_chunk_length - 1))\n",
    "\n",
    "# Ensure future_covariates_full covers the required range\n",
    "required_end_date = pd.Timestamp(test_df['Date'].iloc[0]) + pd.DateOffset(days=len(series_test)-1)\n",
    "\n",
    "# Check if future_covariates_full has sufficient data\n",
    "if future_covariates_full.start_time() > required_start_date or future_covariates_full.end_time() < required_end_date:\n",
    "    print(\"Warning: The future_covariates_full is not long enough to cover the required input chunk length and prediction range.\")\n",
    "    \n",
    "# Slice the future covariates to the required range, including data from the training period\n",
    "future_covariates_test = future_covariates_full.slice(required_start_date, required_end_date)\n",
    "\n",
    "# Scaling the data\n",
    "scaler_series = Scaler(MaxAbsScaler())\n",
    "scaler_covariates = Scaler(MaxAbsScaler())\n",
    "\n",
    "# Fit the scaler on the training data\n",
    "series_train_scaled = scaler_series.fit_transform(series_train)\n",
    "future_covariates_train_scaled = scaler_covariates.fit_transform(future_covariates_train)\n",
    "\n",
    "# Transform the test series and future covariates using the same scaler\n",
    "series_test_scaled = scaler_series.transform(series_test)\n",
    "future_covariates_test_scaled = scaler_covariates.transform(future_covariates_test)\n",
    "\n",
    "# Slice the future covariates to the required range, including data from the training period\n",
    "future_covariates_train = future_covariates_full.slice(required_start_date, series_train.end_time())\n",
    "future_covariates_test = future_covariates_full.slice(series_train.end_time() + pd.DateOffset(days=1), required_end_date)\n",
    "\n",
    "# Scaling the data\n",
    "scaler_series = Scaler(MaxAbsScaler())\n",
    "scaler_covariates = Scaler(MaxAbsScaler())\n",
    "\n",
    "# Fit the scaler on the training data\n",
    "series_train_scaled = scaler_series.fit_transform(series_train)\n",
    "future_covariates_train_scaled = scaler_covariates.fit_transform(future_covariates_train)\n",
    "\n",
    "# Transform the test series and future covariates using the same scaler\n",
    "series_test_scaled = scaler_series.transform(series_test)\n",
    "future_covariates_test_scaled = scaler_covariates.transform(future_covariates_test)\n",
    "\n",
    "# Define the Optuna objective function without backtesting\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 10, 100)\n",
    "    n_layers = trial.suggest_int('n_layers', 1, 5)\n",
    "    dropout = trial.suggest_uniform('dropout', 0.0, 0.5)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64])\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
    "    input_chunk_length = trial.suggest_int('input_chunk_length', 30, 200)\n",
    "    n_epochs = 3  # Adjust epochs for optimization\n",
    "\n",
    "    # Ensure training_length >= input_chunk_length\n",
    "    training_length = max(200, input_chunk_length)\n",
    "\n",
    "    # Define the model\n",
    "    model = RNNModel(\n",
    "        model='LSTM',\n",
    "        input_chunk_length=input_chunk_length,\n",
    "        training_length=training_length,\n",
    "        hidden_dim=hidden_dim,\n",
    "        n_rnn_layers=n_layers,\n",
    "        dropout=dropout,\n",
    "        likelihood=GaussianLikelihood(),\n",
    "        batch_size=batch_size,\n",
    "        n_epochs=n_epochs,\n",
    "        optimizer_kwargs={'lr': learning_rate},\n",
    "        random_state=42,\n",
    "        pl_trainer_kwargs={\n",
    "            'accelerator': 'gpu',  # Use GPU\n",
    "            'devices': 1,\n",
    "            'enable_progress_bar': True,\n",
    "            'logger': False,\n",
    "            'enable_model_summary': False,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Fit the model on the training data\n",
    "        model.fit(\n",
    "            series_train_scaled,\n",
    "            future_covariates=future_covariates_full,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        # Make predictions\n",
    "        forecast_val = model.predict(\n",
    "            n=1,\n",
    "            future_covariates=future_covariates_test_scaled\n",
    "        )\n",
    "\n",
    "        # Calculate MAPE on the validation set\n",
    "        error = mape(series_test_scaled, forecast_val)\n",
    "    except Exception as e:\n",
    "        print(f'Exception during model training: {e}')\n",
    "        traceback.print_exc()\n",
    "        return float('inf')\n",
    "\n",
    "    return error\n",
    "\n",
    "# Run Optuna optimization\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=1)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = study.best_params\n",
    "print('Best hyperparameters:')\n",
    "for key, value in best_params.items():\n",
    "    print(f'  {key}: {value}')\n",
    "\n",
    "# Ensure training_length >= input_chunk_length\n",
    "best_training_length = max(200, best_params['input_chunk_length'])\n",
    "\n",
    "# Train the best model on the full training data\n",
    "best_model = RNNModel(\n",
    "    model='LSTM',\n",
    "    input_chunk_length=best_params['input_chunk_length'],\n",
    "    training_length=best_training_length,\n",
    "    hidden_dim=best_params['hidden_dim'],\n",
    "    n_rnn_layers=best_params['n_layers'],\n",
    "    dropout=best_params['dropout'],\n",
    "    likelihood=GaussianLikelihood(),\n",
    "    batch_size=best_params['batch_size'],\n",
    "    n_epochs=10,  # Increase epochs for final training\n",
    "    optimizer_kwargs={'lr': best_params['learning_rate']},\n",
    "    random_state=42,\n",
    "    pl_trainer_kwargs={\n",
    "        'accelerator': 'gpu',  # Use GPU\n",
    "        'devices': 1,\n",
    "        'enable_progress_bar': True,\n",
    "        'logger': False,\n",
    "        'enable_model_summary': False,\n",
    "    }\n",
    ")\n",
    "\n",
    "best_model.fit(\n",
    "    series_train_scaled,\n",
    "    future_covariates=future_covariates_full,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Determine forecast horizon based on available covariates\n",
    "max_n = (future_covariates_test.end_time() - series_test.start_time()).days + 1\n",
    "n = min(len(series_test_scaled), max_n)\n",
    "\n",
    "# Make predictions on the test set\n",
    "forecast = best_model.predict(\n",
    "    n=n,\n",
    "    future_covariates=future_covariates_test_scaled\n",
    ")\n",
    "\n",
    "# Adjust test_series to match forecast length\n",
    "test_series = test_series[:n]\n",
    "\n",
    "# Continue with inverse transformation, plotting, and error metrics as before\n",
    "\n",
    "# Inverse transform the forecast and test_series\n",
    "forecast = scaler_series.inverse_transform(forecast)\n",
    "test_series = scaler_series.inverse_transform(series_test_scaled)\n",
    "\n",
    "# Plot the forecast\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=test_series.time_index,\n",
    "    y=test_series.values().squeeze(),\n",
    "    mode='lines',\n",
    "    name='Actual',\n",
    "    line=dict(color='blue')\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=forecast.time_index,\n",
    "    y=forecast.values().squeeze(),\n",
    "    mode='lines',\n",
    "    name='Forecast',\n",
    "    line=dict(color='red', dash='dash')\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='RNN Model - Time Series Forecast',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Day Ahead Price (€/MWh)',\n",
    "    legend=dict(\n",
    "        x=1,\n",
    "        y=1,\n",
    "        xanchor='right',\n",
    "        yanchor='top',\n",
    "        bordercolor='black',\n",
    "        borderwidth=1\n",
    "    ),\n",
    "    template='plotly'\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Calculate and print error metrics\n",
    "print('Error Metrics on Test Set:')\n",
    "print(f'  Mean Absolute Percentage Error (MAPE): {mape(test_series, forecast):.2f}%')\n",
    "print(f'  Mean Absolute Error (MAE): {mae(test_series, forecast):.2f}')\n",
    "print(f'  Root Mean Squared Error (RMSE): {rmse(test_series, forecast):.2f}')\n",
    "print(f'  Mean Squared Error (MSE): {mse(test_series, forecast):.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-19 11:22:19,938] A new study created in memory with name: no-name-18df9c02-df78-4348-ada7-ad910869a0e2\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b053cd2fd2b145a0885b115b0bc16217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-19 11:22:45,779] Trial 0 finished with value: 205.57139587402344 and parameters: {'hidden_dim': 51, 'n_layers': 2, 'dropout': 0.39910456304305625, 'batch_size': 64, 'learning_rate': 0.0005359145324041791, 'input_chunk_length': 196}. Best is trial 0 with value: 205.57139587402344.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef87816076264756882793646bf95719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-19 11:23:07,364] Trial 1 finished with value: 400.8519287109375 and parameters: {'hidden_dim': 46, 'n_layers': 2, 'dropout': 0.08393738906984405, 'batch_size': 64, 'learning_rate': 3.4620746840546855e-05, 'input_chunk_length': 141}. Best is trial 0 with value: 205.57139587402344.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1511f57570e74d6694ec60d77d984e69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-19 11:23:53,252] Trial 2 finished with value: 11689.0869140625 and parameters: {'hidden_dim': 87, 'n_layers': 2, 'dropout': 0.1944015192022635, 'batch_size': 32, 'learning_rate': 0.026217265038648525, 'input_chunk_length': 194}. Best is trial 0 with value: 205.57139587402344.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2879c69d21ea4d22a0eae4b27d2132f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-19 11:25:13,799] Trial 3 finished with value: 114.58106994628906 and parameters: {'hidden_dim': 70, 'n_layers': 5, 'dropout': 0.4523217467058362, 'batch_size': 32, 'learning_rate': 1.3874588634864121e-05, 'input_chunk_length': 172}. Best is trial 3 with value: 114.58106994628906.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66c10c996e7a460b88cbf94d716eb323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-19 11:25:58,197] Trial 4 finished with value: 118.36807250976562 and parameters: {'hidden_dim': 63, 'n_layers': 3, 'dropout': 0.1509263419430691, 'batch_size': 32, 'learning_rate': 0.0338770459746194, 'input_chunk_length': 38}. Best is trial 3 with value: 114.58106994628906.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f0ed3271edb4e99ad48bceeb664a0b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-19 11:26:23,840] Trial 5 finished with value: 217.9854278564453 and parameters: {'hidden_dim': 49, 'n_layers': 2, 'dropout': 0.2606596339863262, 'batch_size': 64, 'learning_rate': 7.522677189627802e-05, 'input_chunk_length': 50}. Best is trial 3 with value: 114.58106994628906.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e6a997348154d1a97095e8b5b871011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-19 11:27:05,375] Trial 6 finished with value: 160.12881469726562 and parameters: {'hidden_dim': 11, 'n_layers': 4, 'dropout': 0.3779622727692257, 'batch_size': 32, 'learning_rate': 0.061274746716043715, 'input_chunk_length': 193}. Best is trial 3 with value: 114.58106994628906.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d69ca82987d471fab077018d0db39ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-19 11:27:59,814] Trial 7 finished with value: 287.53607177734375 and parameters: {'hidden_dim': 78, 'n_layers': 5, 'dropout': 0.3629235123676253, 'batch_size': 64, 'learning_rate': 0.003691784419843991, 'input_chunk_length': 48}. Best is trial 3 with value: 114.58106994628906.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89b6babc68144bbd94f585322aa595e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-19 11:29:00,160] Trial 8 finished with value: 66.19490051269531 and parameters: {'hidden_dim': 64, 'n_layers': 1, 'dropout': 0.34160105679751707, 'batch_size': 16, 'learning_rate': 0.015265711876397851, 'input_chunk_length': 34}. Best is trial 8 with value: 66.19490051269531.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "314a97e703db452b881c493d7941971e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-19 11:29:40,784] Trial 9 finished with value: 134.1493377685547 and parameters: {'hidden_dim': 51, 'n_layers': 4, 'dropout': 0.263331663740493, 'batch_size': 64, 'learning_rate': 0.05665671897174339, 'input_chunk_length': 64}. Best is trial 8 with value: 66.19490051269531.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3c4b81b561b46fd8e8e80ff7a974855",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-19 11:30:38,342] Trial 10 finished with value: 89.33930206298828 and parameters: {'hidden_dim': 25, 'n_layers': 1, 'dropout': 0.49423574035255324, 'batch_size': 16, 'learning_rate': 0.004455357513063347, 'input_chunk_length': 97}. Best is trial 8 with value: 66.19490051269531.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8ed477c05a349fcbf1911c64fbd9a38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-19 11:31:35,284] Trial 11 finished with value: 103.44505310058594 and parameters: {'hidden_dim': 25, 'n_layers': 1, 'dropout': 0.49944684021141705, 'batch_size': 16, 'learning_rate': 0.0028574059930340893, 'input_chunk_length': 83}. Best is trial 8 with value: 66.19490051269531.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a74cfe77bb44d3a8f0c01f6a5a031b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-19 11:32:41,946] Trial 12 finished with value: 55.464134216308594 and parameters: {'hidden_dim': 100, 'n_layers': 1, 'dropout': 0.3181620047751069, 'batch_size': 16, 'learning_rate': 0.008501557673410083, 'input_chunk_length': 102}. Best is trial 12 with value: 55.464134216308594.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44e988bfe3bc4afd924cdb56888d3c33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-19 11:33:48,416] Trial 13 finished with value: 85.6839828491211 and parameters: {'hidden_dim': 100, 'n_layers': 1, 'dropout': 0.32357135208735077, 'batch_size': 16, 'learning_rate': 0.01018350008673993, 'input_chunk_length': 127}. Best is trial 12 with value: 55.464134216308594.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "import traceback  \n",
    "import pandas as pd\n",
    "from darts import TimeSeries\n",
    "from darts.models import RNNModel\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "from darts.metrics import mape, mae, rmse, mse\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "import optuna\n",
    "import plotly.graph_objects as go\n",
    "from darts.utils.callbacks import TFMProgressBar\n",
    "\n",
    "# Create time series objects\n",
    "series_train = TimeSeries.from_dataframe(train_df, 'Date', 'Day_ahead_price (€/MWh)').astype('float32')\n",
    "series_test = TimeSeries.from_dataframe(test_df, 'Date', 'Day_ahead_price (€/MWh)').astype('float32')\n",
    "\n",
    "# Convert future covariates to TimeSeries objects\n",
    "\n",
    "future_covariates_train = TimeSeries.from_dataframe(train_df, 'Date', future_covariates_columns).astype('float32')\n",
    "\n",
    "# Determine required start date for future covariates during prediction\n",
    "max_input_chunk_length = 200  # Maximum input_chunk_length from your hyperparameter search\n",
    "required_covariate_start = series_test.start_time() - pd.DateOffset(days=(max_input_chunk_length - 1))\n",
    "required_covariate_end = series_test.end_time()\n",
    "\n",
    "# Ensure future_covariates_full covers the required range\n",
    "future_covariates_full = TimeSeries.from_dataframe(\n",
    "    df, 'Date', future_covariates_columns, fill_missing_dates=True, freq=\"D\"\n",
    ").astype('float32')\n",
    "\n",
    "# Slice future covariates for prediction\n",
    "future_covariates_for_prediction = future_covariates_full.slice(\n",
    "    required_covariate_start, required_covariate_end\n",
    ")\n",
    "\n",
    "# Scaling the data\n",
    "scaler_series = Scaler(MaxAbsScaler())\n",
    "scaler_covariates = Scaler(MaxAbsScaler())\n",
    "\n",
    "# Fit the scaler on the training data\n",
    "series_train_scaled = scaler_series.fit_transform(series_train)\n",
    "future_covariates_train_scaled = scaler_covariates.fit_transform(future_covariates_train)\n",
    "\n",
    "# Transform the test series and future covariates using the same scaler\n",
    "series_test_scaled = scaler_series.transform(series_test)\n",
    "future_covariates_for_prediction_scaled = scaler_covariates.transform(future_covariates_for_prediction)\n",
    "\n",
    "# Define the Optuna objective function without backtesting\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 10, 100)\n",
    "    n_layers = trial.suggest_int('n_layers', 1, 5)\n",
    "    dropout = trial.suggest_uniform('dropout', 0.0, 0.5)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64])\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
    "    input_chunk_length = trial.suggest_int('input_chunk_length', 30, 200)\n",
    "    n_epochs = 10  # Adjust epochs for optimization\n",
    "\n",
    "    # Ensure training_length >= input_chunk_length\n",
    "    training_length = max(200, input_chunk_length)\n",
    "\n",
    "    # Define the model\n",
    "    model = RNNModel(\n",
    "        model='LSTM',\n",
    "        input_chunk_length=input_chunk_length,\n",
    "        training_length=training_length,\n",
    "        hidden_dim=hidden_dim,\n",
    "        n_rnn_layers=n_layers,\n",
    "        dropout=dropout,\n",
    "        likelihood=GaussianLikelihood(),\n",
    "        batch_size=batch_size,\n",
    "        n_epochs=n_epochs,\n",
    "        optimizer_kwargs={'lr': learning_rate},\n",
    "        random_state=42,\n",
    "        save_checkpoints=True,\n",
    "        model_name= \"rnn_model\",\n",
    "        pl_trainer_kwargs={\n",
    "            'accelerator': 'gpu',  # Use GPU if available\n",
    "            'devices': 1,\n",
    "            'enable_progress_bar': True,\n",
    "            'logger': False,\n",
    "            'enable_model_summary': False,\n",
    "            \"callbacks\": [TFMProgressBar(enable_train_bar_only=True)],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Fit the model on the training data\n",
    "        model.fit(\n",
    "            series_train_scaled,\n",
    "            future_covariates=future_covariates_train_scaled,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        # Determine forecast horizon\n",
    "        n = len(series_test_scaled)\n",
    "\n",
    "        # Make predictions\n",
    "        forecast_val = model.predict(\n",
    "            n=n,\n",
    "            future_covariates=future_covariates_for_prediction_scaled\n",
    "        )\n",
    "\n",
    "        # Calculate MAPE on the validation set\n",
    "        error = mape(series_test_scaled, forecast_val)\n",
    "    except Exception as e:\n",
    "        print(f'Exception during model training: {e}')\n",
    "        traceback.print_exc()\n",
    "        return float('inf')\n",
    "\n",
    "    return error\n",
    "\n",
    "# Run Optuna optimization\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = study.best_params\n",
    "print('Best hyperparameters:')\n",
    "for key, value in best_params.items():\n",
    "    print(f'  {key}: {value}')\n",
    "\n",
    "# Ensure training_length >= input_chunk_length\n",
    "best_training_length = max(200, best_params['input_chunk_length'])\n",
    "\n",
    "# Train the best model on the full training data\n",
    "best_model = RNNModel(\n",
    "    model='LSTM',\n",
    "    input_chunk_length=best_params['input_chunk_length'],\n",
    "    training_length=best_training_length,\n",
    "    hidden_dim=best_params['hidden_dim'],\n",
    "    n_rnn_layers=best_params['n_layers'],\n",
    "    dropout=best_params['dropout'],\n",
    "    likelihood=GaussianLikelihood(),\n",
    "    batch_size=best_params['batch_size'],\n",
    "    n_epochs=10, \n",
    "    optimizer_kwargs={'lr': best_params['learning_rate']},\n",
    "    random_state=42,\n",
    "    pl_trainer_kwargs={\n",
    "        'accelerator': 'gpu',  \n",
    "        'devices': 1,\n",
    "        'enable_progress_bar': True,\n",
    "        'logger': False,\n",
    "        'enable_model_summary': False,\n",
    "    }\n",
    ")\n",
    "\n",
    "best_model.fit(\n",
    "    series_train_scaled,\n",
    "    future_covariates=future_covariates_train_scaled,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Determine forecast horizon based on available covariates\n",
    "n = len(series_test_scaled)\n",
    "\n",
    "# Make predictions on the test set\n",
    "forecast = best_model.predict(\n",
    "    n=n,\n",
    "    future_covariates=future_covariates_for_prediction_scaled\n",
    ")\n",
    "\n",
    "\n",
    "# Inverse transform the forecast and test_series\n",
    "forecast = scaler_series.inverse_transform(forecast)\n",
    "test_series = scaler_series.inverse_transform(series_test_scaled)\n",
    "\n",
    "# Plot the forecast\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=test_series.time_index,\n",
    "    y=test_series.values().squeeze(),\n",
    "    mode='lines',\n",
    "    name='Actual',\n",
    "    line=dict(color='blue')\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=forecast.time_index,\n",
    "    y=forecast.values().squeeze(),\n",
    "    mode='lines',\n",
    "    name='Forecast',\n",
    "    line=dict(color='red', dash='dash')\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='RNN Model - Time Series Forecast',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Day Ahead Price (€/MWh)',\n",
    "    legend=dict(\n",
    "        x=1,\n",
    "        y=1,\n",
    "        xanchor='right',\n",
    "        yanchor='top',\n",
    "        bordercolor='black',\n",
    "        borderwidth=1\n",
    "    ),\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Calculate and print error metrics\n",
    "print('Error Metrics on Test Set:')\n",
    "print(f'  Mean Absolute Percentage Error (MAPE): {mape(test_series, forecast):.2f}%')\n",
    "print(f'  Mean Absolute Error (MAE): {mae(test_series, forecast):.2f}')\n",
    "print(f'  Root Mean Squared Error (RMSE): {rmse(test_series, forecast):.2f}')\n",
    "print(f'  Mean Squared Error (MSE): {mse(test_series, forecast):.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Backtesting\n",
    "from darts.utils.timeseries_generation import concatenate\n",
    "\n",
    "# Combine training and test future covariates\n",
    "future_covariates_full_scaled = future_covariates_train_scaled.concatenate(future_covariates_for_prediction_scaled)\n",
    "\n",
    "# Combine the training and test series for the full series\n",
    "series_full_scaled = series_train_scaled.concatenate(series_test_scaled)\n",
    "\n",
    "# Define backtesting parameters\n",
    "forecast_horizon = 7  # Adjust based on your requirements\n",
    "stride = 1  # Number of time steps between forecasts\n",
    "start = series_train_scaled.end_time()  # Start backtesting after the training period\n",
    "\n",
    "# Run backtesting using historical_forecasts\n",
    "backtest_forecasts = best_model.historical_forecasts(\n",
    "    series=series_full_scaled,\n",
    "    future_covariates=future_covariates_full_scaled,\n",
    "    start=start,\n",
    "    forecast_horizon=forecast_horizon,\n",
    "    stride=stride,\n",
    "    retrain=False,\n",
    "    verbose=True,\n",
    "    last_points_only=False,\n",
    ")\n",
    "\n",
    "# Concatenate the list of forecasts into a single TimeSeries\n",
    "backtest_forecasts_concat = concatenate(backtest_forecasts, axis=0)\n",
    "\n",
    "# Get the actual series corresponding to the forecasts\n",
    "actual_series = series_full_scaled.slice_intersect(backtest_forecasts_concat)\n",
    "\n",
    "# Inverse transform the forecasts and actual series\n",
    "backtest_forecasts_inv = scaler_series.inverse_transform(backtest_forecasts_concat)\n",
    "actual_series_inv = scaler_series.inverse_transform(actual_series)\n",
    "\n",
    "# Calculate error metrics\n",
    "backtest_mape = mape(actual_series_inv, backtest_forecasts_inv)\n",
    "backtest_mae = mae(actual_series_inv, backtest_forecasts_inv)\n",
    "backtest_rmse = rmse(actual_series_inv, backtest_forecasts_inv)\n",
    "backtest_mse = mse(actual_series_inv, backtest_forecasts_inv)\n",
    "\n",
    "print('Backtesting Error Metrics:')\n",
    "print(f'  Mean Absolute Percentage Error (MAPE): {backtest_mape:.2f}%')\n",
    "print(f'  Mean Absolute Error (MAE): {backtest_mae:.2f}')\n",
    "print(f'  Root Mean Squared Error (RMSE): {backtest_rmse:.2f}')\n",
    "print(f'  Mean Squared Error (MSE): {backtest_mse:.2f}')\n",
    "\n",
    "# Plot the backtest forecasts against the actual series\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=actual_series_inv.time_index,\n",
    "    y=actual_series_inv.values().squeeze(),\n",
    "    mode='lines',\n",
    "    name='Actual',\n",
    "    line=dict(color='blue')\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=backtest_forecasts_inv.time_index,\n",
    "    y=backtest_forecasts_inv.values().squeeze(),\n",
    "    mode='lines',\n",
    "    name='Backtest Forecast',\n",
    "    line=dict(color='red', dash='dash')\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='RNN Model - Backtesting Forecast',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Day Ahead Price (€/MWh)',\n",
    "    legend=dict(\n",
    "        x=1,\n",
    "        y=1,\n",
    "        xanchor='right',\n",
    "        yanchor='top',\n",
    "        bordercolor='black',\n",
    "        borderwidth=1\n",
    "    ),\n",
    "    template='plotly'\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
