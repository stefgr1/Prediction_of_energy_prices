{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal Fusion Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import torch \n",
    "from darts import TimeSeries\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "from pytorch_lightning.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data \n",
    "def load_and_prepare_data(file_path):\n",
    "    \"\"\"\n",
    "    Load energy prices data from a CSV file, ensure chronological order, and convert 'Date' to datetime.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    df.sort_values('Date', inplace=True)\n",
    "    # Convert 'date' column to datetime\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    #df.set_index('Date', inplace=True)\n",
    "    df = pd.DataFrame(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Day_ahead_price (€/MWh)</th>\n",
       "      <th>Solar_radiation (W/m2)</th>\n",
       "      <th>Wind_speed (m/s)</th>\n",
       "      <th>Temperature (°C)</th>\n",
       "      <th>Biomass (GWh)</th>\n",
       "      <th>Hard_coal (GWh)</th>\n",
       "      <th>Hydro (GWh)</th>\n",
       "      <th>Lignite (GWh)</th>\n",
       "      <th>Natural_gas (GWh)</th>\n",
       "      <th>Other (GWh)</th>\n",
       "      <th>Pumped_storage_generation (GWh)</th>\n",
       "      <th>Solar_energy (GWh)</th>\n",
       "      <th>Wind_offshore (GWh)</th>\n",
       "      <th>Wind_onshore (GWh)</th>\n",
       "      <th>Net_total_export_import (GWh)</th>\n",
       "      <th>BEV_vehicles</th>\n",
       "      <th>Oil_price (EUR)</th>\n",
       "      <th>TTF_gas_price (€/MWh)</th>\n",
       "      <th>Nuclear_energy (GWh)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>18.19</td>\n",
       "      <td>14.75</td>\n",
       "      <td>4.95</td>\n",
       "      <td>8.39</td>\n",
       "      <td>98.605</td>\n",
       "      <td>108.454</td>\n",
       "      <td>51.011</td>\n",
       "      <td>325.337</td>\n",
       "      <td>188.811</td>\n",
       "      <td>54.040</td>\n",
       "      <td>19.314</td>\n",
       "      <td>6.263</td>\n",
       "      <td>3.404</td>\n",
       "      <td>235.467</td>\n",
       "      <td>54.662</td>\n",
       "      <td>6</td>\n",
       "      <td>99.64</td>\n",
       "      <td>21.10</td>\n",
       "      <td>250.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-01-02</td>\n",
       "      <td>33.82</td>\n",
       "      <td>15.12</td>\n",
       "      <td>5.00</td>\n",
       "      <td>7.41</td>\n",
       "      <td>98.605</td>\n",
       "      <td>222.656</td>\n",
       "      <td>51.862</td>\n",
       "      <td>343.168</td>\n",
       "      <td>229.293</td>\n",
       "      <td>54.166</td>\n",
       "      <td>28.892</td>\n",
       "      <td>6.312</td>\n",
       "      <td>3.350</td>\n",
       "      <td>231.772</td>\n",
       "      <td>-64.477</td>\n",
       "      <td>6</td>\n",
       "      <td>100.04</td>\n",
       "      <td>20.00</td>\n",
       "      <td>258.671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-01-03</td>\n",
       "      <td>35.03</td>\n",
       "      <td>31.88</td>\n",
       "      <td>7.77</td>\n",
       "      <td>5.23</td>\n",
       "      <td>98.605</td>\n",
       "      <td>162.204</td>\n",
       "      <td>48.851</td>\n",
       "      <td>336.773</td>\n",
       "      <td>241.297</td>\n",
       "      <td>53.518</td>\n",
       "      <td>21.072</td>\n",
       "      <td>24.226</td>\n",
       "      <td>7.292</td>\n",
       "      <td>504.484</td>\n",
       "      <td>-35.078</td>\n",
       "      <td>6</td>\n",
       "      <td>100.44</td>\n",
       "      <td>20.90</td>\n",
       "      <td>271.495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>32.16</td>\n",
       "      <td>25.21</td>\n",
       "      <td>8.04</td>\n",
       "      <td>4.78</td>\n",
       "      <td>98.605</td>\n",
       "      <td>189.633</td>\n",
       "      <td>47.101</td>\n",
       "      <td>323.976</td>\n",
       "      <td>252.289</td>\n",
       "      <td>52.194</td>\n",
       "      <td>28.300</td>\n",
       "      <td>14.157</td>\n",
       "      <td>7.828</td>\n",
       "      <td>541.528</td>\n",
       "      <td>22.924</td>\n",
       "      <td>6</td>\n",
       "      <td>103.15</td>\n",
       "      <td>21.40</td>\n",
       "      <td>270.613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>20.35</td>\n",
       "      <td>13.46</td>\n",
       "      <td>9.98</td>\n",
       "      <td>4.23</td>\n",
       "      <td>98.605</td>\n",
       "      <td>175.733</td>\n",
       "      <td>45.854</td>\n",
       "      <td>327.502</td>\n",
       "      <td>259.018</td>\n",
       "      <td>52.179</td>\n",
       "      <td>31.887</td>\n",
       "      <td>4.728</td>\n",
       "      <td>8.280</td>\n",
       "      <td>572.819</td>\n",
       "      <td>35.618</td>\n",
       "      <td>6</td>\n",
       "      <td>103.92</td>\n",
       "      <td>21.30</td>\n",
       "      <td>287.555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>2024-07-24</td>\n",
       "      <td>66.61</td>\n",
       "      <td>225.04</td>\n",
       "      <td>3.47</td>\n",
       "      <td>17.54</td>\n",
       "      <td>110.007</td>\n",
       "      <td>43.469</td>\n",
       "      <td>85.857</td>\n",
       "      <td>199.246</td>\n",
       "      <td>194.291</td>\n",
       "      <td>54.026</td>\n",
       "      <td>20.934</td>\n",
       "      <td>325.285</td>\n",
       "      <td>49.360</td>\n",
       "      <td>179.921</td>\n",
       "      <td>-168.705</td>\n",
       "      <td>992</td>\n",
       "      <td>75.75</td>\n",
       "      <td>32.63</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>2024-07-25</td>\n",
       "      <td>78.34</td>\n",
       "      <td>272.71</td>\n",
       "      <td>2.12</td>\n",
       "      <td>17.85</td>\n",
       "      <td>110.410</td>\n",
       "      <td>50.676</td>\n",
       "      <td>82.632</td>\n",
       "      <td>195.983</td>\n",
       "      <td>209.610</td>\n",
       "      <td>52.963</td>\n",
       "      <td>18.766</td>\n",
       "      <td>394.116</td>\n",
       "      <td>51.053</td>\n",
       "      <td>42.885</td>\n",
       "      <td>-194.496</td>\n",
       "      <td>992</td>\n",
       "      <td>76.36</td>\n",
       "      <td>31.70</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>2024-07-26</td>\n",
       "      <td>93.04</td>\n",
       "      <td>172.33</td>\n",
       "      <td>2.60</td>\n",
       "      <td>19.09</td>\n",
       "      <td>110.852</td>\n",
       "      <td>42.333</td>\n",
       "      <td>79.531</td>\n",
       "      <td>205.273</td>\n",
       "      <td>205.773</td>\n",
       "      <td>52.616</td>\n",
       "      <td>19.081</td>\n",
       "      <td>256.246</td>\n",
       "      <td>40.449</td>\n",
       "      <td>129.267</td>\n",
       "      <td>-241.786</td>\n",
       "      <td>993</td>\n",
       "      <td>75.21</td>\n",
       "      <td>32.20</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>2024-07-27</td>\n",
       "      <td>80.74</td>\n",
       "      <td>176.67</td>\n",
       "      <td>2.05</td>\n",
       "      <td>19.63</td>\n",
       "      <td>110.479</td>\n",
       "      <td>33.307</td>\n",
       "      <td>74.958</td>\n",
       "      <td>184.012</td>\n",
       "      <td>216.412</td>\n",
       "      <td>50.927</td>\n",
       "      <td>18.856</td>\n",
       "      <td>244.051</td>\n",
       "      <td>2.180</td>\n",
       "      <td>32.001</td>\n",
       "      <td>-251.655</td>\n",
       "      <td>992</td>\n",
       "      <td>74.79</td>\n",
       "      <td>32.90</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>2024-07-28</td>\n",
       "      <td>43.96</td>\n",
       "      <td>235.92</td>\n",
       "      <td>3.48</td>\n",
       "      <td>18.17</td>\n",
       "      <td>110.731</td>\n",
       "      <td>11.629</td>\n",
       "      <td>74.669</td>\n",
       "      <td>141.084</td>\n",
       "      <td>158.503</td>\n",
       "      <td>51.515</td>\n",
       "      <td>12.365</td>\n",
       "      <td>345.645</td>\n",
       "      <td>24.192</td>\n",
       "      <td>171.537</td>\n",
       "      <td>-65.418</td>\n",
       "      <td>992</td>\n",
       "      <td>74.37</td>\n",
       "      <td>33.25</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4593 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Day_ahead_price (€/MWh)  Solar_radiation (W/m2)  \\\n",
       "0   2012-01-01                    18.19                   14.75   \n",
       "1   2012-01-02                    33.82                   15.12   \n",
       "2   2012-01-03                    35.03                   31.88   \n",
       "3   2012-01-04                    32.16                   25.21   \n",
       "4   2012-01-05                    20.35                   13.46   \n",
       "..         ...                      ...                     ...   \n",
       "754 2024-07-24                    66.61                  225.04   \n",
       "755 2024-07-25                    78.34                  272.71   \n",
       "756 2024-07-26                    93.04                  172.33   \n",
       "757 2024-07-27                    80.74                  176.67   \n",
       "758 2024-07-28                    43.96                  235.92   \n",
       "\n",
       "     Wind_speed (m/s)  Temperature (°C)  Biomass (GWh)  Hard_coal (GWh)  \\\n",
       "0                4.95              8.39         98.605          108.454   \n",
       "1                5.00              7.41         98.605          222.656   \n",
       "2                7.77              5.23         98.605          162.204   \n",
       "3                8.04              4.78         98.605          189.633   \n",
       "4                9.98              4.23         98.605          175.733   \n",
       "..                ...               ...            ...              ...   \n",
       "754              3.47             17.54        110.007           43.469   \n",
       "755              2.12             17.85        110.410           50.676   \n",
       "756              2.60             19.09        110.852           42.333   \n",
       "757              2.05             19.63        110.479           33.307   \n",
       "758              3.48             18.17        110.731           11.629   \n",
       "\n",
       "     Hydro (GWh)  Lignite (GWh)  Natural_gas (GWh)  Other (GWh)  \\\n",
       "0         51.011        325.337            188.811       54.040   \n",
       "1         51.862        343.168            229.293       54.166   \n",
       "2         48.851        336.773            241.297       53.518   \n",
       "3         47.101        323.976            252.289       52.194   \n",
       "4         45.854        327.502            259.018       52.179   \n",
       "..           ...            ...                ...          ...   \n",
       "754       85.857        199.246            194.291       54.026   \n",
       "755       82.632        195.983            209.610       52.963   \n",
       "756       79.531        205.273            205.773       52.616   \n",
       "757       74.958        184.012            216.412       50.927   \n",
       "758       74.669        141.084            158.503       51.515   \n",
       "\n",
       "     Pumped_storage_generation (GWh)  Solar_energy (GWh)  Wind_offshore (GWh)  \\\n",
       "0                             19.314               6.263                3.404   \n",
       "1                             28.892               6.312                3.350   \n",
       "2                             21.072              24.226                7.292   \n",
       "3                             28.300              14.157                7.828   \n",
       "4                             31.887               4.728                8.280   \n",
       "..                               ...                 ...                  ...   \n",
       "754                           20.934             325.285               49.360   \n",
       "755                           18.766             394.116               51.053   \n",
       "756                           19.081             256.246               40.449   \n",
       "757                           18.856             244.051                2.180   \n",
       "758                           12.365             345.645               24.192   \n",
       "\n",
       "     Wind_onshore (GWh)  Net_total_export_import (GWh)  BEV_vehicles  \\\n",
       "0               235.467                         54.662             6   \n",
       "1               231.772                        -64.477             6   \n",
       "2               504.484                        -35.078             6   \n",
       "3               541.528                         22.924             6   \n",
       "4               572.819                         35.618             6   \n",
       "..                  ...                            ...           ...   \n",
       "754             179.921                       -168.705           992   \n",
       "755              42.885                       -194.496           992   \n",
       "756             129.267                       -241.786           993   \n",
       "757              32.001                       -251.655           992   \n",
       "758             171.537                        -65.418           992   \n",
       "\n",
       "     Oil_price (EUR)  TTF_gas_price (€/MWh)  Nuclear_energy (GWh)  \n",
       "0              99.64                  21.10               250.979  \n",
       "1             100.04                  20.00               258.671  \n",
       "2             100.44                  20.90               271.495  \n",
       "3             103.15                  21.40               270.613  \n",
       "4             103.92                  21.30               287.555  \n",
       "..               ...                    ...                   ...  \n",
       "754            75.75                  32.63                 0.000  \n",
       "755            76.36                  31.70                 0.000  \n",
       "756            75.21                  32.20                 0.000  \n",
       "757            74.79                  32.90                 0.000  \n",
       "758            74.37                  33.25                 0.000  \n",
       "\n",
       "[4593 rows x 20 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in the train and test data\n",
    "train_df = load_and_prepare_data('../../data/Final_data/train_df.csv')\n",
    "test_df = load_and_prepare_data('../../data/Final_data/test_df.csv')\n",
    "\n",
    "# Concatenate the train and test data\n",
    "df = pd.concat([train_df, test_df])\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Create a time series object\n",
    "series_train = TimeSeries.from_dataframe(train_df, 'Date', 'Day_ahead_price (€/MWh)').astype('float32')\n",
    "series_test = TimeSeries.from_dataframe(test_df, 'Date', 'Day_ahead_price (€/MWh)').astype('float32')\n",
    "\n",
    "# Show \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the future covariates columns from your dataframe\n",
    "future_covariates_columns = ['Solar_radiation (W/m2)', 'Wind_speed (m/s)', 'Temperature (°C)', \n",
    "                             'Biomass (GWh)', 'Hard_coal (GWh)', 'Hydro (GWh)', 'Lignite (GWh)', \n",
    "                             'Natural_gas (GWh)', 'Other (GWh)', 'Pumped_storage_generation (GWh)', \n",
    "                             'Solar_energy (GWh)', 'Wind_offshore (GWh)', 'Wind_onshore (GWh)', \n",
    "                             'Net_total_export_import (GWh)', 'BEV_vehicles', 'Oil_price (EUR)', \n",
    "                             'TTF_gas_price (€/MWh)', 'Nuclear_energy (GWh)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal Fusion Transformer (TFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "   | Name                              | Type                             | Params\n",
      "----------------------------------------------------------------------------------------\n",
      "0  | criterion                         | MSELoss                          | 0     \n",
      "1  | train_criterion                   | MSELoss                          | 0     \n",
      "2  | val_criterion                     | MSELoss                          | 0     \n",
      "3  | train_metrics                     | MetricCollection                 | 0     \n",
      "4  | val_metrics                       | MetricCollection                 | 0     \n",
      "5  | input_embeddings                  | _MultiEmbedding                  | 0     \n",
      "6  | static_covariates_vsn             | _VariableSelectionNetwork        | 0     \n",
      "7  | encoder_vsn                       | _VariableSelectionNetwork        | 8.3 K \n",
      "8  | decoder_vsn                       | _VariableSelectionNetwork        | 7.9 K \n",
      "9  | static_context_grn                | _GatedResidualNetwork            | 304   \n",
      "10 | static_context_hidden_encoder_grn | _GatedResidualNetwork            | 304   \n",
      "11 | static_context_cell_encoder_grn   | _GatedResidualNetwork            | 304   \n",
      "12 | static_context_enrichment         | _GatedResidualNetwork            | 304   \n",
      "13 | lstm_encoder                      | LSTM                             | 1.2 K \n",
      "14 | lstm_decoder                      | LSTM                             | 1.2 K \n",
      "15 | post_lstm_gan                     | _GateAddNorm                     | 160   \n",
      "16 | static_enrichment_grn             | _GatedResidualNetwork            | 368   \n",
      "17 | multihead_attn                    | _InterpretableMultiHeadAttention | 178   \n",
      "18 | post_attn_gan                     | _GateAddNorm                     | 160   \n",
      "19 | feed_forward_block                | _GatedResidualNetwork            | 304   \n",
      "20 | pre_output_gan                    | _GateAddNorm                     | 160   \n",
      "21 | output_layer                      | Linear                           | 27    \n",
      "----------------------------------------------------------------------------------------\n",
      "20.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.7 K    Total params\n",
      "0.083     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c0848fdb90041bc964d546150eb3772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from darts.models import TFTModel\n",
    "from darts import TimeSeries\n",
    "from darts.models.forecasting.tft_model import QuantileRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "from sklearn.preprocessing import MaxAbsScaler, RobustScaler, StandardScaler\n",
    "from darts.metrics import mape, rmse, mse, mae\n",
    "import torch\n",
    "\n",
    "# Set device to MPS if available, otherwise fallback to CPU\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# Convert future covariates to TimeSeries objects\n",
    "future_covariates_train = TimeSeries.from_dataframe(train_df, 'Date', future_covariates_columns).astype('float32')\n",
    "future_covariates_test = TimeSeries.from_dataframe(test_df, 'Date', future_covariates_columns).astype('float32')\n",
    "\n",
    "# Convert future covariates to TimeSeries objects\n",
    "future_covariates_full = TimeSeries.from_dataframe(df, 'Date', future_covariates_columns, fill_missing_dates=True, freq=\"D\").astype('float32')\n",
    "\n",
    "# Determine required start date for future covariates\n",
    "input_chunk_length = 200  # Set based on desired look-back period\n",
    "required_start_date = pd.Timestamp(test_df['Date'].iloc[0]) - pd.DateOffset(days=input_chunk_length)\n",
    "\n",
    "# Ensure future_covariates_full covers the required range\n",
    "required_end_date = pd.Timestamp(test_df['Date'].iloc[0]) + pd.DateOffset(days=len(series_test)-1)\n",
    "\n",
    "# Check if future_covariates_full has sufficient data\n",
    "if future_covariates_full.start_time() > required_start_date or future_covariates_full.end_time() < required_end_date:\n",
    "    print(\"Warning: The future_covariates_full is not long enough to cover the required input chunk length and prediction range.\")\n",
    "    # Extend the future_covariates_full or adjust your dataset\n",
    "\n",
    "# Slice the future covariates to the required range, including data from the training period\n",
    "future_covariates_test = future_covariates_full.slice(required_start_date, required_end_date)\n",
    "\n",
    "# Scaling the data\n",
    "scaler_series = Scaler(MaxAbsScaler())\n",
    "scaler_covariates = Scaler(MaxAbsScaler())\n",
    "\n",
    "# Fit the scaler on the training data\n",
    "series_train_scaled = scaler_series.fit_transform(series_train)\n",
    "future_covariates_train_scaled = scaler_covariates.fit_transform(future_covariates_train)\n",
    "\n",
    "# Transform the test series and future covariates using the same scaler\n",
    "series_test_scaled = scaler_series.transform(series_test)\n",
    "future_covariates_test_scaled = scaler_covariates.transform(future_covariates_test)\n",
    "\n",
    "# Define the TFT model, specifying the use of the MPS device\n",
    "model = TFTModel(\n",
    "    input_chunk_length=input_chunk_length,  # History length (number of past time steps used to predict the future)\n",
    "    output_chunk_length=len(series_test),  # Adjusted to predict the length of the test set\n",
    "    hidden_size=8,\n",
    "    lstm_layers=2,\n",
    "    num_attention_heads=4,\n",
    "    dropout=0.1,\n",
    "    likelihood=QuantileRegression(quantiles=[0.1, 0.5, 0.9]),  # Correctly using QuantileRegression\n",
    "    random_state=42,\n",
    "    add_relative_index=True,  # Automatically generate relative index as a future covariate\n",
    "    loss_fn=torch.nn.MSELoss(),  # Correctly using MSELoss\n",
    "    pl_trainer_kwargs={\n",
    "        'accelerator': 'gpu',  # Ensure PyTorch Lightning uses GPU\n",
    "        'devices': 1,  \n",
    "    }\n",
    ")\n",
    "\n",
    "# Train the model with future covariates on MPS\n",
    "model.fit(series_train_scaled, future_covariates=future_covariates_train_scaled, epochs=5, verbose=True)\n",
    "\n",
    "# Make predictions on the test set\n",
    "forecast_scaled = model.predict(n=len(series_test), future_covariates=future_covariates_test_scaled, num_samples=100)\n",
    "\n",
    "# Inverse transform the forecast to the original scale\n",
    "forecast = scaler_series.inverse_transform(forecast_scaled)\n",
    "\n",
    "# Convert TimeSeries to DataFrame for Plotly plotting\n",
    "test_df_plotly = series_test.pd_dataframe()\n",
    "forecast_df_plotly = forecast.pd_dataframe()\n",
    "\n",
    "# Plot the results using Plotly\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add actual test data trace\n",
    "fig.add_trace(go.Scatter(x=test_df_plotly.index, y=test_df_plotly['Day_ahead_price (€/MWh)'],\n",
    "                         mode='lines', name='Actual Test Data', line=dict(color='darkblue')))\n",
    "\n",
    "# Add forecast data trace\n",
    "fig.add_trace(go.Scatter(x=forecast_df_plotly.index, y=forecast_df_plotly['Day_ahead_price (€/MWh)'],\n",
    "                         mode='lines', name='TFT Model on Test Data', line=dict(color='red')))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title='TFT Model - Test Performance Only',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Day Ahead Price (€/MWh)',\n",
    "    legend=dict(\n",
    "        x=1,   # Set x position to 1 (far right)\n",
    "        y=1,   # Set y position to 1 (top)\n",
    "        xanchor='right',  # Anchor the legend's x position to the right\n",
    "        yanchor='top',    # Anchor the legend's y position to the top\n",
    "        bordercolor='black',  # Optional: Add a border around the legend\n",
    "        borderwidth=1        # Optional: Set the border width\n",
    "    ),\n",
    "    template='plotly'\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error on Test Set: nan\n",
      "Mean Absolute Percentage Error on Test Set: nan\n",
      "Mean Squared Error on Test Set: nan\n",
      "Root Mean Squared Error on Test Set: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/skyfano/Documents/Masterarbeit/Prediction_of_energy_prices/master_thesis/lib/python3.10/site-packages/darts/metrics/metrics.py:785: RuntimeWarning:\n",
      "\n",
      "Mean of empty slice\n",
      "\n",
      "/Users/skyfano/Documents/Masterarbeit/Prediction_of_energy_prices/master_thesis/lib/python3.10/site-packages/darts/metrics/metrics.py:244: RuntimeWarning:\n",
      "\n",
      "Mean of empty slice\n",
      "\n",
      "/Users/skyfano/Documents/Masterarbeit/Prediction_of_energy_prices/master_thesis/lib/python3.10/site-packages/darts/metrics/metrics.py:1904: RuntimeWarning:\n",
      "\n",
      "Mean of empty slice\n",
      "\n",
      "/Users/skyfano/Documents/Masterarbeit/Prediction_of_energy_prices/master_thesis/lib/python3.10/site-packages/darts/metrics/metrics.py:1161: RuntimeWarning:\n",
      "\n",
      "Mean of empty slice\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using Darts' metrics\n",
    "print(f'Mean Absolute Error on Test Set: {mae(series_test, forecast)}')\n",
    "print(f'Mean Absolute Percentage Error on Test Set: {mape(series_test, forecast)}')\n",
    "print(f'Mean Squared Error on Test Set: {mse(series_test, forecast)}')\n",
    "print(f'Root Mean Squared Error on Test Set: {rmse(series_test, forecast)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the created figure as png file and the error metrics \n",
    "fig.write_image(\"../../predictions/TFT/TFT_epochs_10.png\")\n",
    "error_metrics = pd.DataFrame({'MAE': [mae(series_test, forecast)], 'MAPE': [mape(series_test, forecast)], 'MSE': [mse(series_test, forecast)], 'RMSE': [rmse(series_test, forecast)]})\n",
    "error_metrics.to_csv('../../predictions/TFT/TFT_metrics_epochs_10.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Für 30 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts.models import TFTModel\n",
    "from darts import TimeSeries\n",
    "from darts.models.forecasting.tft_model import QuantileRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "from sklearn.preprocessing import MaxAbsScaler, RobustScaler, StandardScaler\n",
    "from darts.metrics import mape, rmse, mse, mae\n",
    "\n",
    "# Convert future covariates to TimeSeries objects\n",
    "future_covariates_train = TimeSeries.from_dataframe(train_df, 'Date', future_covariates_columns).astype('float32')\n",
    "future_covariates_test = TimeSeries.from_dataframe(test_df, 'Date', future_covariates_columns).astype('float32')\n",
    "\n",
    "future_covariates_full = TimeSeries.from_dataframe(df, 'Date', future_covariates_columns, fill_missing_dates=True, freq=\"D\").astype('float32')\n",
    "\n",
    "# Determine required start date for future covariates\n",
    "input_chunk_length = 200  # Set based on desired look-back period\n",
    "required_start_date = pd.Timestamp(test_df['Date'].iloc[0]) - pd.DateOffset(days=input_chunk_length)\n",
    "\n",
    "# Ensure future_covariates_full covers the required range\n",
    "required_end_date = pd.Timestamp(test_df['Date'].iloc[0]) + pd.DateOffset(days=len(series_test)-1)\n",
    "\n",
    "# Check if future_covariates_full has sufficient data\n",
    "if future_covariates_full.start_time() > required_start_date or future_covariates_full.end_time() < required_end_date:\n",
    "    print(\"Warning: The future_covariates_full is not long enough to cover the required input chunk length and prediction range.\")\n",
    "    # Extend the future_covariates_full or adjust your dataset\n",
    "\n",
    "# Slice the future covariates to the required range, including data from the training period\n",
    "future_covariates_test = future_covariates_full.slice(required_start_date, required_end_date)\n",
    "\n",
    "# Scaling the data\n",
    "scaler_series = Scaler(MaxAbsScaler())\n",
    "scaler_covariates = Scaler(MaxAbsScaler())\n",
    "\n",
    "# Fit the scaler on the training data\n",
    "series_train_scaled = scaler_series.fit_transform(series_train)\n",
    "future_covariates_train_scaled = scaler_covariates.fit_transform(future_covariates_train)\n",
    "\n",
    "# Transform the test series and future covariates using the same scaler\n",
    "series_test_scaled = scaler_series.transform(series_test)\n",
    "future_covariates_test_scaled = scaler_covariates.transform(future_covariates_test)\n",
    "\n",
    "# Define the TFT model\n",
    "model = TFTModel(\n",
    "    input_chunk_length=input_chunk_length,  # History length (number of past time steps used to predict the future)\n",
    "    output_chunk_length=len(series_test),  # Adjusted to predict the length of the test set\n",
    "    hidden_size=16,\n",
    "    lstm_layers=4,\n",
    "    num_attention_heads=4,\n",
    "    dropout=0.1,\n",
    "    likelihood=QuantileRegression(quantiles=[0.1, 0.5, 0.9]),  # Correctly using QuantileRegression\n",
    "    random_state=42,\n",
    "    add_relative_index=True,  # Automatically generate relative index as a future covariate\n",
    "    loss_fn=torch.nn.MSELoss()  # Correctly using MSELoss\n",
    ")\n",
    "\n",
    "# Train the model with future covariates\n",
    "model.fit(series_train_scaled, future_covariates=future_covariates_train_scaled, epochs=30, verbose=True)\n",
    "\n",
    "# Make predictions on the test set\n",
    "forecast_scaled = model.predict(n=len(series_test), future_covariates=future_covariates_test_scaled)\n",
    "\n",
    "# Inverse transform the forecast to the original scale\n",
    "forecast = scaler_series.inverse_transform(forecast_scaled)\n",
    "\n",
    "# Convert TimeSeries to DataFrame for Plotly plotting\n",
    "test_df_plotly = series_test.pd_dataframe()\n",
    "forecast_df_plotly = forecast.pd_dataframe()\n",
    "\n",
    "# Plot the results using Plotly\n",
    "fig_2 = go.Figure()\n",
    "\n",
    "# Add actual test data trace\n",
    "fig_2.add_trace(go.Scatter(x=test_df_plotly.index, y=test_df_plotly['Day_ahead_price (€/MWh)'],\n",
    "                         mode='lines', name='Actual Test Data', line=dict(color='darkblue')))\n",
    "\n",
    "# Add forecast data trace\n",
    "fig_2.add_trace(go.Scatter(x=forecast_df_plotly.index, y=forecast_df_plotly['Day_ahead_price (€/MWh)'],\n",
    "                         mode='lines', name='TFT Model on Test Data', line=dict(color='red')))\n",
    "\n",
    "# Update layout\n",
    "fig_2.update_layout(\n",
    "    title='TFT Model - Test Performance Only',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Day Ahead Price (€/MWh)',\n",
    "    legend=dict(\n",
    "        x=1,   # Set x position to 1 (far right)\n",
    "        y=1,   # Set y position to 1 (top)\n",
    "        xanchor='right',  # Anchor the legend's x position to the right\n",
    "        yanchor='top',    # Anchor the legend's y position to the top\n",
    "        bordercolor='black',  # Optional: Add a border around the legend\n",
    "        borderwidth=1        # Optional: Set the border width\n",
    "    ),\n",
    "    template='plotly'\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using Darts' metrics\n",
    "print(f'Mean Absolute Error on Test Set: {mae(series_test, forecast)}')\n",
    "print(f'Mean Absolute Percentage Error on Test Set: {mape(series_test, forecast)}')\n",
    "print(f'Mean Squared Error on Test Set: {mse(series_test, forecast)}')\n",
    "print(f'Root Mean Squared Error on Test Set: {rmse(series_test, forecast)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the created figure as png file and the error metrics \n",
    "fig_2.write_image(\"../../predictions/Other_Ideas/TFT_epochs_30.png\")\n",
    "error_metrics = pd.DataFrame({'MAE': [mae(series_test, forecast)], 'MAPE': [mape(series_test, forecast)], 'MSE': [mse(series_test, forecast)], 'RMSE': [rmse(series_test, forecast)]})\n",
    "error_metrics.to_csv('../../predictions/Other_Ideas/TFT_metrics_epochs_30.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimiziation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-25 11:04:28,257] A new study created in memory with name: no-name-9fa8eb93-c6ed-4f69-9ae8-6595d23e1cb6\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "ValueError: For the given forecasting horizon `n=759`, the provided future covariates at dataset index `0` do not extend far enough into the future. As `n > output_chunk_length` the future covariates must end at time step `2024-07-28 00:00:00`, whereas now they end at time step `2024-01-10 00:00:00`.\n",
      "[I 2024-09-25 11:05:11,227] Trial 0 finished with value: inf and parameters: {'hidden_size': 47, 'lstm_layers': 1, 'num_attention_heads': 1, 'dropout': 0.38824819536107896}. Best is trial 0 with value: inf.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to: For the given forecasting horizon `n=759`, the provided future covariates at dataset index `0` do not extend far enough into the future. As `n > output_chunk_length` the future covariates must end at time step `2024-07-28 00:00:00`, whereas now they end at time step `2024-01-10 00:00:00`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "ValueError: For the given forecasting horizon `n=759`, the provided future covariates at dataset index `0` do not extend far enough into the future. As `n > output_chunk_length` the future covariates must end at time step `2024-07-28 00:00:00`, whereas now they end at time step `2024-01-10 00:00:00`.\n",
      "[I 2024-09-25 11:05:43,507] Trial 1 finished with value: inf and parameters: {'hidden_size': 8, 'lstm_layers': 3, 'num_attention_heads': 7, 'dropout': 0.20709801440892822}. Best is trial 0 with value: inf.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to: For the given forecasting horizon `n=759`, the provided future covariates at dataset index `0` do not extend far enough into the future. As `n > output_chunk_length` the future covariates must end at time step `2024-07-28 00:00:00`, whereas now they end at time step `2024-01-10 00:00:00`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "ValueError: For the given forecasting horizon `n=759`, the provided future covariates at dataset index `0` do not extend far enough into the future. As `n > output_chunk_length` the future covariates must end at time step `2024-07-28 00:00:00`, whereas now they end at time step `2024-01-10 00:00:00`.\n",
      "[I 2024-09-25 11:06:26,816] Trial 2 finished with value: inf and parameters: {'hidden_size': 43, 'lstm_layers': 1, 'num_attention_heads': 7, 'dropout': 0.20324537623372685}. Best is trial 0 with value: inf.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to: For the given forecasting horizon `n=759`, the provided future covariates at dataset index `0` do not extend far enough into the future. As `n > output_chunk_length` the future covariates must end at time step `2024-07-28 00:00:00`, whereas now they end at time step `2024-01-10 00:00:00`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "ValueError: For the given forecasting horizon `n=759`, the provided future covariates at dataset index `0` do not extend far enough into the future. As `n > output_chunk_length` the future covariates must end at time step `2024-07-28 00:00:00`, whereas now they end at time step `2024-01-10 00:00:00`.\n",
      "[I 2024-09-25 11:07:08,634] Trial 3 finished with value: inf and parameters: {'hidden_size': 13, 'lstm_layers': 3, 'num_attention_heads': 2, 'dropout': 0.31368227313489444}. Best is trial 0 with value: inf.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to: For the given forecasting horizon `n=759`, the provided future covariates at dataset index `0` do not extend far enough into the future. As `n > output_chunk_length` the future covariates must end at time step `2024-07-28 00:00:00`, whereas now they end at time step `2024-01-10 00:00:00`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "ValueError: For the given forecasting horizon `n=759`, the provided future covariates at dataset index `0` do not extend far enough into the future. As `n > output_chunk_length` the future covariates must end at time step `2024-07-28 00:00:00`, whereas now they end at time step `2024-01-10 00:00:00`.\n",
      "[I 2024-09-25 11:07:50,370] Trial 4 finished with value: inf and parameters: {'hidden_size': 26, 'lstm_layers': 3, 'num_attention_heads': 3, 'dropout': 0.3695747225602523}. Best is trial 0 with value: inf.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "   | Name                              | Type                             | Params | Mode \n",
      "------------------------------------------------------------------------------------------------\n",
      "0  | criterion                         | MSELoss                          | 0      | train\n",
      "1  | train_criterion                   | MSELoss                          | 0      | train\n",
      "2  | val_criterion                     | MSELoss                          | 0      | train\n",
      "3  | train_metrics                     | MetricCollection                 | 0      | train\n",
      "4  | val_metrics                       | MetricCollection                 | 0      | train\n",
      "5  | input_embeddings                  | _MultiEmbedding                  | 0      | train\n",
      "6  | static_covariates_vsn             | _VariableSelectionNetwork        | 0      | train\n",
      "7  | encoder_vsn                       | _VariableSelectionNetwork        | 30.3 K | train\n",
      "8  | decoder_vsn                       | _VariableSelectionNetwork        | 28.6 K | train\n",
      "9  | static_context_grn                | _GatedResidualNetwork            | 9.1 K  | train\n",
      "10 | static_context_hidden_encoder_grn | _GatedResidualNetwork            | 9.1 K  | train\n",
      "11 | static_context_cell_encoder_grn   | _GatedResidualNetwork            | 9.1 K  | train\n",
      "12 | static_context_enrichment         | _GatedResidualNetwork            | 9.1 K  | train\n",
      "13 | lstm_encoder                      | LSTM                             | 18.0 K | train\n",
      "14 | lstm_decoder                      | LSTM                             | 18.0 K | train\n",
      "15 | post_lstm_gan                     | _GateAddNorm                     | 4.6 K  | train\n",
      "16 | static_enrichment_grn             | _GatedResidualNetwork            | 11.3 K | train\n",
      "17 | multihead_attn                    | _InterpretableMultiHeadAttention | 9.0 K  | train\n",
      "18 | post_attn_gan                     | _GateAddNorm                     | 4.6 K  | train\n",
      "19 | feed_forward_block                | _GatedResidualNetwork            | 9.1 K  | train\n",
      "20 | pre_output_gan                    | _GateAddNorm                     | 4.6 K  | train\n",
      "21 | output_layer                      | Linear                           | 144    | train\n",
      "------------------------------------------------------------------------------------------------\n",
      "174 K     Trainable params\n",
      "0         Non-trainable params\n",
      "174 K     Total params\n",
      "0.698     Total estimated model params size (MB)\n",
      "706       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to: For the given forecasting horizon `n=759`, the provided future covariates at dataset index `0` do not extend far enough into the future. As `n > output_chunk_length` the future covariates must end at time step `2024-07-28 00:00:00`, whereas now they end at time step `2024-01-10 00:00:00`.\n",
      "Best hyperparameters:  {'hidden_size': 47, 'lstm_layers': 1, 'num_attention_heads': 1, 'dropout': 0.38824819536107896}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c5dd46c6b4f47c987bb2a7281e6a228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "ValueError: For the given forecasting horizon `n=759`, the provided future covariates at dataset index `0` do not extend far enough into the future. As `n > output_chunk_length` the future covariates must end at time step `2024-07-28 00:00:00`, whereas now they end at time step `2024-01-10 00:00:00`.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "For the given forecasting horizon `n=759`, the provided future covariates at dataset index `0` do not extend far enough into the future. As `n > output_chunk_length` the future covariates must end at time step `2024-07-28 00:00:00`, whereas now they end at time step `2024-01-10 00:00:00`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 112\u001b[0m\n\u001b[1;32m    109\u001b[0m best_model\u001b[38;5;241m.\u001b[39mfit(series_train_scaled, future_covariates\u001b[38;5;241m=\u001b[39mfuture_covariates_train_scaled, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# Make predictions starting from the correct point\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m forecast_scaled \u001b[38;5;241m=\u001b[39m \u001b[43mbest_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mseries_test_scaled\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfuture_covariates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfuture_covariates_test_scaled\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# Inverse transform the forecast to the original scale\u001b[39;00m\n\u001b[1;32m    118\u001b[0m forecast \u001b[38;5;241m=\u001b[39m scaler_series\u001b[38;5;241m.\u001b[39minverse_transform(forecast_scaled)\n",
      "File \u001b[0;32m~/Documents/Masterarbeit/Prediction_of_energy_prices/master_thesis/lib/python3.10/site-packages/darts/utils/torch.py:103\u001b[0m, in \u001b[0;36mrandom_method.<locals>.decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m fork_rng():\n\u001b[1;32m    102\u001b[0m     manual_seed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_random_instance\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, high\u001b[38;5;241m=\u001b[39mMAX_TORCH_SEED_VALUE))\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdecorated\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Masterarbeit/Prediction_of_energy_prices/master_thesis/lib/python3.10/site-packages/darts/models/forecasting/torch_forecasting_model.py:1465\u001b[0m, in \u001b[0;36mTorchForecastingModel.predict\u001b[0;34m(self, n, series, past_covariates, future_covariates, trainer, batch_size, verbose, n_jobs, roll_size, num_samples, dataloader_kwargs, mc_dropout, predict_likelihood_parameters, show_warnings)\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[1;32m   1447\u001b[0m     n,\n\u001b[1;32m   1448\u001b[0m     series,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1453\u001b[0m     show_warnings\u001b[38;5;241m=\u001b[39mshow_warnings,\n\u001b[1;32m   1454\u001b[0m )\n\u001b[1;32m   1456\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_inference_dataset(\n\u001b[1;32m   1457\u001b[0m     target\u001b[38;5;241m=\u001b[39mseries,\n\u001b[1;32m   1458\u001b[0m     n\u001b[38;5;241m=\u001b[39mn,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1462\u001b[0m     bounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1463\u001b[0m )\n\u001b[0;32m-> 1465\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_from_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1466\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1467\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1468\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1469\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1470\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1471\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1472\u001b[0m \u001b[43m    \u001b[49m\u001b[43mroll_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mroll_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1473\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1474\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataloader_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloader_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmc_dropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmc_dropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpredict_likelihood_parameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredict_likelihood_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1477\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1479\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predictions[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m called_with_single_series \u001b[38;5;28;01melse\u001b[39;00m predictions\n",
      "File \u001b[0;32m~/Documents/Masterarbeit/Prediction_of_energy_prices/master_thesis/lib/python3.10/site-packages/darts/utils/torch.py:103\u001b[0m, in \u001b[0;36mrandom_method.<locals>.decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m fork_rng():\n\u001b[1;32m    102\u001b[0m     manual_seed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_random_instance\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, high\u001b[38;5;241m=\u001b[39mMAX_TORCH_SEED_VALUE))\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdecorated\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Masterarbeit/Prediction_of_energy_prices/master_thesis/lib/python3.10/site-packages/darts/models/forecasting/torch_forecasting_model.py:1559\u001b[0m, in \u001b[0;36mTorchForecastingModel.predict_from_dataset\u001b[0;34m(self, n, input_series_dataset, trainer, batch_size, verbose, n_jobs, roll_size, num_samples, dataloader_kwargs, mc_dropout, predict_likelihood_parameters)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verify_inference_dataset_type(input_series_dataset)\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# check that covariates and dimensions are matching what we had during training\u001b[39;00m\n\u001b[0;32m-> 1559\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verify_predict_sample(\u001b[43minput_series_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m   1561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m roll_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1562\u001b[0m     roll_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_chunk_length\n",
      "File \u001b[0;32m~/Documents/Masterarbeit/Prediction_of_energy_prices/master_thesis/lib/python3.10/site-packages/darts/utils/data/inference_dataset.py:711\u001b[0m, in \u001b[0;36mMixedCovariatesInferenceDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;28mself\u001b[39m, idx\n\u001b[1;32m    693\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    701\u001b[0m     Union[pd\u001b[38;5;241m.\u001b[39mTimestamp, \u001b[38;5;28mint\u001b[39m],\n\u001b[1;32m    702\u001b[0m ]:\n\u001b[1;32m    703\u001b[0m     (\n\u001b[1;32m    704\u001b[0m         past_target,\n\u001b[1;32m    705\u001b[0m         past_covariate,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    709\u001b[0m         pred_point,\n\u001b[1;32m    710\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds_past[idx]\n\u001b[0;32m--> 711\u001b[0m     _, historic_future_covariate, future_covariate, _, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mds_future\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    713\u001b[0m         past_target,\n\u001b[1;32m    714\u001b[0m         past_covariate,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    720\u001b[0m         pred_point,\n\u001b[1;32m    721\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/Masterarbeit/Prediction_of_energy_prices/master_thesis/lib/python3.10/site-packages/darts/utils/data/inference_dataset.py:599\u001b[0m, in \u001b[0;36mDualCovariatesInferenceDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;28mself\u001b[39m, idx\n\u001b[1;32m    584\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    590\u001b[0m     Union[pd\u001b[38;5;241m.\u001b[39mTimestamp, \u001b[38;5;28mint\u001b[39m],\n\u001b[1;32m    591\u001b[0m ]:\n\u001b[1;32m    592\u001b[0m     (\n\u001b[1;32m    593\u001b[0m         past_target,\n\u001b[1;32m    594\u001b[0m         historic_future_covariate,\n\u001b[1;32m    595\u001b[0m         _,\n\u001b[1;32m    596\u001b[0m         static_covariate,\n\u001b[1;32m    597\u001b[0m         ts_target,\n\u001b[1;32m    598\u001b[0m         pred_point,\n\u001b[0;32m--> 599\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mds_past\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    600\u001b[0m     _, future_covariate, _, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds_future[idx]\n\u001b[1;32m    601\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    602\u001b[0m         past_target,\n\u001b[1;32m    603\u001b[0m         historic_future_covariate,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    607\u001b[0m         pred_point,\n\u001b[1;32m    608\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/Masterarbeit/Prediction_of_energy_prices/master_thesis/lib/python3.10/site-packages/darts/utils/data/inference_dataset.py:418\u001b[0m, in \u001b[0;36mPastCovariatesInferenceDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;28mself\u001b[39m, idx: \u001b[38;5;28mint\u001b[39m\n\u001b[1;32m    410\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    416\u001b[0m     Union[pd\u001b[38;5;241m.\u001b[39mTimestamp, \u001b[38;5;28mint\u001b[39m],\n\u001b[1;32m    417\u001b[0m ]:\n\u001b[0;32m--> 418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mds\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Masterarbeit/Prediction_of_energy_prices/master_thesis/lib/python3.10/site-packages/darts/utils/data/inference_dataset.py:291\u001b[0m, in \u001b[0;36mGenericInferenceDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    286\u001b[0m covariate_series \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcovariates \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcovariates[series_idx]\n\u001b[1;32m    288\u001b[0m )\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m covariate_series \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;66;03m# get start and end indices (integer) of the covariates including historic and future parts\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m     covariate_start, covariate_end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_covariate_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseries_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_series\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime_index\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtarget_start_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_end\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_end\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcovariate_series\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcovariate_series\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcovariate_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcovariate_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_chunk_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_chunk_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_chunk_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_chunk_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_chunk_shift\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_chunk_shift\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;66;03m# extract covariate values and split into a past (historic) and future part\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     covariate \u001b[38;5;241m=\u001b[39m covariate_series\u001b[38;5;241m.\u001b[39mrandom_component_values(copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[\n\u001b[1;32m    305\u001b[0m         covariate_start:covariate_end\n\u001b[1;32m    306\u001b[0m     ]\n",
      "File \u001b[0;32m~/Documents/Masterarbeit/Prediction_of_energy_prices/master_thesis/lib/python3.10/site-packages/darts/utils/data/inference_dataset.py:108\u001b[0m, in \u001b[0;36mInferenceDataset._covariate_indexer\u001b[0;34m(target_idx, past_start, past_end, covariate_series, covariate_type, input_chunk_length, output_chunk_length, output_chunk_shift, n)\u001b[0m\n\u001b[1;32m     98\u001b[0m     raise_log(\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    100\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor the given forecasting case, the provided \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmain_covariate_type\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m covariates at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    105\u001b[0m         logger\u001b[38;5;241m=\u001b[39mlogger,\n\u001b[1;32m    106\u001b[0m     )\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m covariate_series\u001b[38;5;241m.\u001b[39mend_time() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m future_end:\n\u001b[0;32m--> 108\u001b[0m     \u001b[43mraise_log\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;167;43;01mValueError\u001b[39;49;00m\u001b[43m(\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFor the given forecasting horizon `n=\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mn\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m`, the provided \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmain_covariate_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m covariates \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    111\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mat dataset index `\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtarget_idx\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m` do not extend far enough into the future. As `\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    112\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mn > output_chunk_length\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[43mn\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43moutput_chunk_length\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mn <= output_chunk_length\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    113\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m` the \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmain_covariate_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m covariates must end at time step `\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfuture_end\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m`, \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    114\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwhereas now they end at time step `\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcovariate_series\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m`.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# extract the index position (integer index) from time_index value\u001b[39;00m\n\u001b[1;32m    120\u001b[0m covariate_start \u001b[38;5;241m=\u001b[39m covariate_series\u001b[38;5;241m.\u001b[39mtime_index\u001b[38;5;241m.\u001b[39mget_loc(past_start)\n",
      "File \u001b[0;32m~/Documents/Masterarbeit/Prediction_of_energy_prices/master_thesis/lib/python3.10/site-packages/darts/logging.py:132\u001b[0m, in \u001b[0;36mraise_log\u001b[0;34m(exception, logger)\u001b[0m\n\u001b[1;32m    129\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(exception)\n\u001b[1;32m    130\u001b[0m logger\u001b[38;5;241m.\u001b[39merror(exception_type \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m message)\n\u001b[0;32m--> 132\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mValueError\u001b[0m: For the given forecasting horizon `n=759`, the provided future covariates at dataset index `0` do not extend far enough into the future. As `n > output_chunk_length` the future covariates must end at time step `2024-07-28 00:00:00`, whereas now they end at time step `2024-01-10 00:00:00`."
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from darts.models import TFTModel\n",
    "from darts import TimeSeries\n",
    "from darts.models.forecasting.tft_model import QuantileRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import plotly.graph_objs as go\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "from darts.metrics import mape, rmse, mse, mae\n",
    "\n",
    "# Fixed input chunk length\n",
    "fixed_input_chunk_length = 200  # You can change this value based on your preference.\n",
    "\n",
    "# Convert future covariates to TimeSeries objects\n",
    "future_covariates_train = TimeSeries.from_dataframe(train_df, 'Date', future_covariates_columns).astype('float32')\n",
    "\n",
    "# Convert full covariates to TimeSeries objects\n",
    "future_covariates_full = TimeSeries.from_dataframe(df, 'Date', future_covariates_columns, fill_missing_dates=True, freq=\"D\").astype('float32')\n",
    "\n",
    "# Scaling the data\n",
    "scaler_series = Scaler()\n",
    "scaler_covariates = Scaler()\n",
    "\n",
    "# Fit the scaler on the training data\n",
    "series_train_scaled = scaler_series.fit_transform(series_train)\n",
    "future_covariates_train_scaled = scaler_covariates.fit_transform(future_covariates_train)\n",
    "\n",
    "# Transform the test series using the same scaler\n",
    "series_test_scaled = scaler_series.transform(series_test)\n",
    "\n",
    "# Recalculate required start and end dates based on fixed input_chunk_length\n",
    "required_start_date = pd.Timestamp(test_df['Date'].iloc[0]) - pd.DateOffset(days=fixed_input_chunk_length)\n",
    "required_end_date = pd.Timestamp(test_df['Date'].iloc[0]) + pd.DateOffset(days=len(series_test)-1)\n",
    "\n",
    "# Check if future_covariates_full has sufficient data\n",
    "if future_covariates_full.start_time() > required_start_date or future_covariates_full.end_time() < required_end_date:\n",
    "    print(f\"Warning: The future_covariates_full is not long enough for input_chunk_length = {fixed_input_chunk_length}\")\n",
    "\n",
    "# Slice and scale the future covariates\n",
    "# Slice future_covariates_test to match the exact length of series_test\n",
    "future_covariates_test = future_covariates_test.slice(required_start_date, required_end_date)\n",
    "future_covariates_test_scaled = scaler_covariates.transform(future_covariates_test)\n",
    "\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters (excluding input_chunk_length since it's fixed)\n",
    "    hidden_size = trial.suggest_int('hidden_size', 8, 64)\n",
    "    lstm_layers = trial.suggest_int('lstm_layers', 1, 4)\n",
    "    num_attention_heads = trial.suggest_int('num_attention_heads', 1, 8)\n",
    "    dropout = trial.suggest_float('dropout', 0.0, 0.5)\n",
    "\n",
    "    # Initialize the TFT model with suggested hyperparameters\n",
    "    model = TFTModel(\n",
    "        input_chunk_length=fixed_input_chunk_length,\n",
    "        output_chunk_length=7,\n",
    "        hidden_size=hidden_size,\n",
    "        lstm_layers=lstm_layers,\n",
    "        num_attention_heads=num_attention_heads,\n",
    "        dropout=dropout,\n",
    "        likelihood=QuantileRegression(quantiles=[0.1, 0.5, 0.9]),\n",
    "        random_state=42,\n",
    "        add_relative_index=True\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Train the model\n",
    "        model.fit(series_train_scaled, future_covariates=future_covariates_train_scaled, epochs=1, verbose=False)\n",
    "\n",
    "        # Make predictions\n",
    "        forecast_scaled = model.predict(n=len(series_test_scaled), future_covariates=future_covariates_test_scaled)\n",
    "\n",
    "        # Inverse transform the forecast to the original scale\n",
    "        forecast = scaler_series.inverse_transform(forecast_scaled)\n",
    "\n",
    "        # Return Mean Squared Error as the objective metric for Optuna to minimize\n",
    "        error = mse(series_test, forecast)\n",
    "        if np.isnan(error):\n",
    "            return float('inf')\n",
    "        return error\n",
    "    except Exception as e:\n",
    "        print(f\"Trial failed due to: {e}\")\n",
    "        return float('inf')\n",
    "\n",
    "# Run the Optuna study with more trials, using the fixed input_chunk_length\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=5, n_jobs=1)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print('Best hyperparameters: ', study.best_params)\n",
    "\n",
    "# Use the best hyperparameters with the fixed input_chunk_length\n",
    "best_params = study.best_params\n",
    "\n",
    "# Initialize the final model with best hyperparameters\n",
    "best_model = TFTModel(\n",
    "    input_chunk_length=fixed_input_chunk_length,\n",
    "    output_chunk_length=7,\n",
    "    hidden_size=best_params['hidden_size'],\n",
    "    lstm_layers=best_params['lstm_layers'],\n",
    "    num_attention_heads=best_params['num_attention_heads'],\n",
    "    dropout=best_params['dropout'],\n",
    "    likelihood=QuantileRegression(quantiles=[0.1, 0.5, 0.9]),\n",
    "    random_state=42,\n",
    "    add_relative_index=True,\n",
    "    loss_fn=torch.nn.MSELoss()\n",
    ")\n",
    "\n",
    "# Train the best model\n",
    "best_model.fit(series_train_scaled, future_covariates=future_covariates_train_scaled, epochs=1, verbose=True)\n",
    "\n",
    "# Make predictions starting from the correct point\n",
    "forecast_scaled = best_model.predict(\n",
    "    n=len(series_test_scaled),\n",
    "    future_covariates=future_covariates_test_scaled\n",
    ")\n",
    "\n",
    "# Inverse transform the forecast to the original scale\n",
    "forecast = scaler_series.inverse_transform(forecast_scaled)\n",
    "\n",
    "# Convert TimeSeries to DataFrame for Plotly plotting\n",
    "test_df_plotly = series_test.pd_dataframe()\n",
    "forecast_df_plotly = forecast.pd_dataframe()\n",
    "\n",
    "# Plot the results using Plotly\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add actual test data trace\n",
    "fig.add_trace(go.Scatter(x=test_df_plotly.index, y=test_df_plotly['Day_ahead_price (€/MWh)'],\n",
    "                         mode='lines', name='Actual Test Data', line=dict(color='darkblue')))\n",
    "\n",
    "# Add forecast data trace\n",
    "fig.add_trace(go.Scatter(x=forecast_df_plotly.index, y=forecast_df_plotly['Day_ahead_price (€/MWh)'],\n",
    "                         mode='lines', name='TFT Forecast on Test Data', line=dict(color='red')))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title='TFT Model - Test Performance with Optuna Hyperparameter Tuning',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Day Ahead Price (€/MWh)',\n",
    "    legend=dict(\n",
    "        x=1,\n",
    "        y=1,\n",
    "        xanchor='right',\n",
    "        yanchor='top',\n",
    "        bordercolor='black',\n",
    "        borderwidth=1\n",
    "    ),\n",
    "    template='plotly'\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n",
    "\n",
    "# Evaluate the model using Darts' metrics\n",
    "print(f'Mean Absolute Error on Test Set: {mae(series_test, forecast)}')\n",
    "print(f'Mean Absolute Percentage Error on Test Set: {mape(series_test, forecast)}')\n",
    "print(f'Mean Squared Error on Test Set: {mse(series_test, forecast)}')\n",
    "print(f'Root Mean Squared Error on Test Set: {rmse(series_test, forecast)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted future_covariates_test length: 759\n",
      "Length of series_test after adjustment: 759\n"
     ]
    }
   ],
   "source": [
    "print(f\"Adjusted future_covariates_test length: {len(future_covariates_test)}\")\n",
    "print(f\"Length of series_test after adjustment: {len(series_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2012-01-01', '2012-01-02', '2012-01-03', '2012-01-04',\n",
      "               '2012-01-05', '2012-01-06', '2012-01-07', '2012-01-08',\n",
      "               '2012-01-09', '2012-01-10',\n",
      "               ...\n",
      "               '2022-06-21', '2022-06-22', '2022-06-23', '2022-06-24',\n",
      "               '2022-06-25', '2022-06-26', '2022-06-27', '2022-06-28',\n",
      "               '2022-06-29', '2022-06-30'],\n",
      "              dtype='datetime64[ns]', name='Date', length=3834, freq='D')\n",
      "DatetimeIndex(['2021-12-13', '2021-12-14', '2021-12-15', '2021-12-16',\n",
      "               '2021-12-17', '2021-12-18', '2021-12-19', '2021-12-20',\n",
      "               '2021-12-21', '2021-12-22',\n",
      "               ...\n",
      "               '2024-07-19', '2024-07-20', '2024-07-21', '2024-07-22',\n",
      "               '2024-07-23', '2024-07-24', '2024-07-25', '2024-07-26',\n",
      "               '2024-07-27', '2024-07-28'],\n",
      "              dtype='datetime64[ns]', name='Date', length=959, freq='D')\n"
     ]
    }
   ],
   "source": [
    "print(future_covariates_train.time_index)\n",
    "print(future_covariates_test.time_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of forecast_scaled: (759, 1)\n",
      "Shape of series_test_scaled: (759, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of forecast_scaled: {forecast_scaled.values().shape}\")\n",
    "print(f\"Shape of series_test_scaled: {series_test_scaled.values().shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required start date: 2021-12-13 00:00:00\n",
      "Required end date: 2024-07-28 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(f\"Required start date: {required_start_date}\")\n",
    "print(f\"Required end date: {required_end_date}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time alignment check:\n",
      "series_test length: 759, forecast_scaled length: 759\n",
      "future_covariates_test length: 959\n"
     ]
    }
   ],
   "source": [
    "# Check for NaN values\n",
    "#if series_test.has_nan_values() or future_covariates_train.has_nan_values():\n",
    " #   print(\"NaN values detected in series_test or future_covariates_train. Please fix the data.\")\n",
    "\n",
    "# Ensure time alignment\n",
    "print(f\"Time alignment check:\")\n",
    "print(f\"series_test length: {len(series_test)}, forecast_scaled length: {len(forecast_scaled)}\")\n",
    "print(f\"future_covariates_test length: {len(future_covariates_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-26 10:57:17,038] A new study created in memory with name: no-name-82c149ec-b67a-4554-8500-e1aa45f0cbda\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "ValueError: For the given forecasting case, the provided future covariates at dataset index `0` do not extend far enough into the past. The future covariates must start at time step `2021-12-13 00:00:00`, whereas now they start at time step `2022-07-01 00:00:00`.\n",
      "[I 2024-09-26 10:58:51,245] Trial 0 finished with value: inf and parameters: {'hidden_size': 26, 'lstm_layers': 3, 'num_attention_heads': 7, 'dropout': 0.3097981299534905}. Best is trial 0 with value: inf.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to: For the given forecasting case, the provided future covariates at dataset index `0` do not extend far enough into the past. The future covariates must start at time step `2021-12-13 00:00:00`, whereas now they start at time step `2022-07-01 00:00:00`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "ValueError: For the given forecasting case, the provided future covariates at dataset index `0` do not extend far enough into the past. The future covariates must start at time step `2021-12-13 00:00:00`, whereas now they start at time step `2022-07-01 00:00:00`.\n",
      "[I 2024-09-26 11:00:42,041] Trial 1 finished with value: inf and parameters: {'hidden_size': 47, 'lstm_layers': 2, 'num_attention_heads': 5, 'dropout': 0.08471606478411381}. Best is trial 0 with value: inf.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to: For the given forecasting case, the provided future covariates at dataset index `0` do not extend far enough into the past. The future covariates must start at time step `2021-12-13 00:00:00`, whereas now they start at time step `2022-07-01 00:00:00`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "ValueError: For the given forecasting case, the provided future covariates at dataset index `0` do not extend far enough into the past. The future covariates must start at time step `2021-12-13 00:00:00`, whereas now they start at time step `2022-07-01 00:00:00`.\n",
      "[I 2024-09-26 11:02:47,035] Trial 2 finished with value: inf and parameters: {'hidden_size': 57, 'lstm_layers': 4, 'num_attention_heads': 6, 'dropout': 0.24911270467868285}. Best is trial 0 with value: inf.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to: For the given forecasting case, the provided future covariates at dataset index `0` do not extend far enough into the past. The future covariates must start at time step `2021-12-13 00:00:00`, whereas now they start at time step `2022-07-01 00:00:00`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "ValueError: For the given forecasting case, the provided future covariates at dataset index `0` do not extend far enough into the past. The future covariates must start at time step `2021-12-13 00:00:00`, whereas now they start at time step `2022-07-01 00:00:00`.\n",
      "[I 2024-09-26 11:04:01,889] Trial 3 finished with value: inf and parameters: {'hidden_size': 41, 'lstm_layers': 3, 'num_attention_heads': 1, 'dropout': 0.1044598547909319}. Best is trial 0 with value: inf.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to: For the given forecasting case, the provided future covariates at dataset index `0` do not extend far enough into the past. The future covariates must start at time step `2021-12-13 00:00:00`, whereas now they start at time step `2022-07-01 00:00:00`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "ValueError: For the given forecasting case, the provided future covariates at dataset index `0` do not extend far enough into the past. The future covariates must start at time step `2021-12-13 00:00:00`, whereas now they start at time step `2022-07-01 00:00:00`.\n",
      "[I 2024-09-26 11:05:40,765] Trial 4 finished with value: inf and parameters: {'hidden_size': 27, 'lstm_layers': 4, 'num_attention_heads': 7, 'dropout': 0.004164631003201691}. Best is trial 0 with value: inf.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to: For the given forecasting case, the provided future covariates at dataset index `0` do not extend far enough into the past. The future covariates must start at time step `2021-12-13 00:00:00`, whereas now they start at time step `2022-07-01 00:00:00`.\n",
      "Best hyperparameters:  {'hidden_size': 26, 'lstm_layers': 3, 'num_attention_heads': 7, 'dropout': 0.3097981299534905}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "   | Name                              | Type                             | Params | Mode \n",
      "------------------------------------------------------------------------------------------------\n",
      "0  | criterion                         | MSELoss                          | 0      | train\n",
      "1  | train_criterion                   | MSELoss                          | 0      | train\n",
      "2  | val_criterion                     | MSELoss                          | 0      | train\n",
      "3  | train_metrics                     | MetricCollection                 | 0      | train\n",
      "4  | val_metrics                       | MetricCollection                 | 0      | train\n",
      "5  | input_embeddings                  | _MultiEmbedding                  | 0      | train\n",
      "6  | static_covariates_vsn             | _VariableSelectionNetwork        | 0      | train\n",
      "7  | encoder_vsn                       | _VariableSelectionNetwork        | 20.3 K | train\n",
      "8  | decoder_vsn                       | _VariableSelectionNetwork        | 19.0 K | train\n",
      "9  | static_context_grn                | _GatedResidualNetwork            | 2.9 K  | train\n",
      "10 | static_context_hidden_encoder_grn | _GatedResidualNetwork            | 2.9 K  | train\n",
      "11 | static_context_cell_encoder_grn   | _GatedResidualNetwork            | 2.9 K  | train\n",
      "12 | static_context_enrichment         | _GatedResidualNetwork            | 2.9 K  | train\n",
      "13 | lstm_encoder                      | LSTM                             | 16.8 K | train\n",
      "14 | lstm_decoder                      | LSTM                             | 16.8 K | train\n",
      "15 | post_lstm_gan                     | _GateAddNorm                     | 1.5 K  | train\n",
      "16 | static_enrichment_grn             | _GatedResidualNetwork            | 3.5 K  | train\n",
      "17 | multihead_attn                    | _InterpretableMultiHeadAttention | 1.3 K  | train\n",
      "18 | post_attn_gan                     | _GateAddNorm                     | 1.5 K  | train\n",
      "19 | feed_forward_block                | _GatedResidualNetwork            | 2.9 K  | train\n",
      "20 | pre_output_gan                    | _GateAddNorm                     | 1.5 K  | train\n",
      "21 | output_layer                      | Linear                           | 81     | train\n",
      "------------------------------------------------------------------------------------------------\n",
      "96.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "96.3 K    Total params\n",
      "0.385     Total estimated model params size (MB)\n",
      "718       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22d0f5076dd04c52a9c73305a3d3b2b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "ValueError: For the given forecasting case, the provided future covariates at dataset index `0` do not extend far enough into the past. The future covariates must start at time step `2021-12-13 00:00:00`, whereas now they start at time step `2022-07-01 00:00:00`.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "For the given forecasting case, the provided future covariates at dataset index `0` do not extend far enough into the past. The future covariates must start at time step `2021-12-13 00:00:00`, whereas now they start at time step `2022-07-01 00:00:00`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 108\u001b[0m\n\u001b[1;32m    105\u001b[0m best_model\u001b[38;5;241m.\u001b[39mfit(series_train_scaled, future_covariates\u001b[38;5;241m=\u001b[39mfuture_covariates_train_scaled, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# Make predictions starting from the correct point\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m forecast_scaled \u001b[38;5;241m=\u001b[39m \u001b[43mbest_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mseries_test_scaled\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfuture_covariates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfuture_covariates_test_scaled\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# Inverse transform the forecast to the original scale\u001b[39;00m\n\u001b[1;32m    114\u001b[0m forecast \u001b[38;5;241m=\u001b[39m scaler_series\u001b[38;5;241m.\u001b[39minverse_transform(forecast_scaled)\n",
      "File \u001b[0;32m~/Documents/Masterarbeit/Prediction_of_energy_prices/master_thesis/lib/python3.10/site-packages/darts/utils/torch.py:103\u001b[0m, in \u001b[0;36mrandom_method.<locals>.decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m fork_rng():\n\u001b[1;32m    102\u001b[0m     manual_seed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_random_instance\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, high\u001b[38;5;241m=\u001b[39mMAX_TORCH_SEED_VALUE))\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdecorated\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Masterarbeit/Prediction_of_energy_prices/master_thesis/lib/python3.10/site-packages/darts/models/forecasting/torch_forecasting_model.py:1465\u001b[0m, in \u001b[0;36mTorchForecastingModel.predict\u001b[0;34m(self, n, series, past_covariates, future_covariates, trainer, batch_size, verbose, n_jobs, roll_size, num_samples, dataloader_kwargs, mc_dropout, predict_likelihood_parameters, show_warnings)\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[1;32m   1447\u001b[0m     n,\n\u001b[1;32m   1448\u001b[0m     series,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1453\u001b[0m     show_warnings\u001b[38;5;241m=\u001b[39mshow_warnings,\n\u001b[1;32m   1454\u001b[0m )\n\u001b[1;32m   1456\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_inference_dataset(\n\u001b[1;32m   1457\u001b[0m     target\u001b[38;5;241m=\u001b[39mseries,\n\u001b[1;32m   1458\u001b[0m     n\u001b[38;5;241m=\u001b[39mn,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1462\u001b[0m     bounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1463\u001b[0m )\n\u001b[0;32m-> 1465\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_from_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1466\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1467\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1468\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1469\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1470\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1471\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1472\u001b[0m \u001b[43m    \u001b[49m\u001b[43mroll_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mroll_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1473\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1474\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataloader_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloader_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmc_dropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmc_dropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpredict_likelihood_parameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredict_likelihood_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1477\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1479\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predictions[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m called_with_single_series \u001b[38;5;28;01melse\u001b[39;00m predictions\n",
      "File \u001b[0;32m~/Documents/Masterarbeit/Prediction_of_energy_prices/master_thesis/lib/python3.10/site-packages/darts/utils/torch.py:103\u001b[0m, in \u001b[0;36mrandom_method.<locals>.decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m fork_rng():\n\u001b[1;32m    102\u001b[0m     manual_seed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_random_instance\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, high\u001b[38;5;241m=\u001b[39mMAX_TORCH_SEED_VALUE))\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdecorated\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Masterarbeit/Prediction_of_energy_prices/master_thesis/lib/python3.10/site-packages/darts/models/forecasting/torch_forecasting_model.py:1559\u001b[0m, in \u001b[0;36mTorchForecastingModel.predict_from_dataset\u001b[0;34m(self, n, input_series_dataset, trainer, batch_size, verbose, n_jobs, roll_size, num_samples, dataloader_kwargs, mc_dropout, predict_likelihood_parameters)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verify_inference_dataset_type(input_series_dataset)\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# check that covariates and dimensions are matching what we had during training\u001b[39;00m\n\u001b[0;32m-> 1559\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verify_predict_sample(\u001b[43minput_series_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m   1561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m roll_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1562\u001b[0m     roll_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_chunk_length\n",
      "File \u001b[0;32m~/Documents/Masterarbeit/Prediction_of_energy_prices/master_thesis/lib/python3.10/site-packages/darts/utils/data/inference_dataset.py:711\u001b[0m, in \u001b[0;36mMixedCovariatesInferenceDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;28mself\u001b[39m, idx\n\u001b[1;32m    693\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    701\u001b[0m     Union[pd\u001b[38;5;241m.\u001b[39mTimestamp, \u001b[38;5;28mint\u001b[39m],\n\u001b[1;32m    702\u001b[0m ]:\n\u001b[1;32m    703\u001b[0m     (\n\u001b[1;32m    704\u001b[0m         past_target,\n\u001b[1;32m    705\u001b[0m         past_covariate,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    709\u001b[0m         pred_point,\n\u001b[1;32m    710\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds_past[idx]\n\u001b[0;32m--> 711\u001b[0m     _, historic_future_covariate, future_covariate, _, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mds_future\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    713\u001b[0m         past_target,\n\u001b[1;32m    714\u001b[0m         past_covariate,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    720\u001b[0m         pred_point,\n\u001b[1;32m    721\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/Masterarbeit/Prediction_of_energy_prices/master_thesis/lib/python3.10/site-packages/darts/utils/data/inference_dataset.py:599\u001b[0m, in \u001b[0;36mDualCovariatesInferenceDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;28mself\u001b[39m, idx\n\u001b[1;32m    584\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    590\u001b[0m     Union[pd\u001b[38;5;241m.\u001b[39mTimestamp, \u001b[38;5;28mint\u001b[39m],\n\u001b[1;32m    591\u001b[0m ]:\n\u001b[1;32m    592\u001b[0m     (\n\u001b[1;32m    593\u001b[0m         past_target,\n\u001b[1;32m    594\u001b[0m         historic_future_covariate,\n\u001b[1;32m    595\u001b[0m         _,\n\u001b[1;32m    596\u001b[0m         static_covariate,\n\u001b[1;32m    597\u001b[0m         ts_target,\n\u001b[1;32m    598\u001b[0m         pred_point,\n\u001b[0;32m--> 599\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mds_past\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    600\u001b[0m     _, future_covariate, _, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds_future[idx]\n\u001b[1;32m    601\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    602\u001b[0m         past_target,\n\u001b[1;32m    603\u001b[0m         historic_future_covariate,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    607\u001b[0m         pred_point,\n\u001b[1;32m    608\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/Masterarbeit/Prediction_of_energy_prices/master_thesis/lib/python3.10/site-packages/darts/utils/data/inference_dataset.py:418\u001b[0m, in \u001b[0;36mPastCovariatesInferenceDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;28mself\u001b[39m, idx: \u001b[38;5;28mint\u001b[39m\n\u001b[1;32m    410\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    416\u001b[0m     Union[pd\u001b[38;5;241m.\u001b[39mTimestamp, \u001b[38;5;28mint\u001b[39m],\n\u001b[1;32m    417\u001b[0m ]:\n\u001b[0;32m--> 418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mds\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Masterarbeit/Prediction_of_energy_prices/master_thesis/lib/python3.10/site-packages/darts/utils/data/inference_dataset.py:291\u001b[0m, in \u001b[0;36mGenericInferenceDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    286\u001b[0m covariate_series \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcovariates \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcovariates[series_idx]\n\u001b[1;32m    288\u001b[0m )\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m covariate_series \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;66;03m# get start and end indices (integer) of the covariates including historic and future parts\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m     covariate_start, covariate_end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_covariate_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseries_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_series\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime_index\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtarget_start_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_end\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_end\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcovariate_series\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcovariate_series\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcovariate_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcovariate_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_chunk_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_chunk_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_chunk_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_chunk_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_chunk_shift\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_chunk_shift\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;66;03m# extract covariate values and split into a past (historic) and future part\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     covariate \u001b[38;5;241m=\u001b[39m covariate_series\u001b[38;5;241m.\u001b[39mrandom_component_values(copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[\n\u001b[1;32m    305\u001b[0m         covariate_start:covariate_end\n\u001b[1;32m    306\u001b[0m     ]\n",
      "File \u001b[0;32m~/Documents/Masterarbeit/Prediction_of_energy_prices/master_thesis/lib/python3.10/site-packages/darts/utils/data/inference_dataset.py:98\u001b[0m, in \u001b[0;36mInferenceDataset._covariate_indexer\u001b[0;34m(target_idx, past_start, past_end, covariate_series, covariate_type, input_chunk_length, output_chunk_length, output_chunk_shift, n)\u001b[0m\n\u001b[1;32m     94\u001b[0m case_start \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     95\u001b[0m     future_start \u001b[38;5;28;01mif\u001b[39;00m covariate_type \u001b[38;5;129;01mis\u001b[39;00m CovariateType\u001b[38;5;241m.\u001b[39mFUTURE \u001b[38;5;28;01melse\u001b[39;00m past_start\n\u001b[1;32m     96\u001b[0m )\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m covariate_series\u001b[38;5;241m.\u001b[39mstart_time() \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m case_start:\n\u001b[0;32m---> 98\u001b[0m     \u001b[43mraise_log\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;167;43;01mValueError\u001b[39;49;00m\u001b[43m(\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFor the given forecasting case, the provided \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmain_covariate_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m covariates at \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    101\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdataset index `\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtarget_idx\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m` do not extend far enough into the past. The \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    102\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmain_covariate_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m covariates must start at time step `\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcase_start\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m`, whereas now \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    103\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthey start at time step `\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcovariate_series\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m`.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    104\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m covariate_series\u001b[38;5;241m.\u001b[39mend_time() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m future_end:\n\u001b[1;32m    108\u001b[0m     raise_log(\n\u001b[1;32m    109\u001b[0m         \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    110\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor the given forecasting horizon `n=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`, the provided \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmain_covariate_type\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m covariates \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    116\u001b[0m         logger\u001b[38;5;241m=\u001b[39mlogger,\n\u001b[1;32m    117\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/Masterarbeit/Prediction_of_energy_prices/master_thesis/lib/python3.10/site-packages/darts/logging.py:132\u001b[0m, in \u001b[0;36mraise_log\u001b[0;34m(exception, logger)\u001b[0m\n\u001b[1;32m    129\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(exception)\n\u001b[1;32m    130\u001b[0m logger\u001b[38;5;241m.\u001b[39merror(exception_type \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m message)\n\u001b[0;32m--> 132\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mValueError\u001b[0m: For the given forecasting case, the provided future covariates at dataset index `0` do not extend far enough into the past. The future covariates must start at time step `2021-12-13 00:00:00`, whereas now they start at time step `2022-07-01 00:00:00`."
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from darts.models import TFTModel\n",
    "from darts import TimeSeries\n",
    "from darts.models.forecasting.tft_model import QuantileRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import plotly.graph_objs as go\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "from darts.metrics import mape, rmse, mse, mae\n",
    "\n",
    "# Fixed input chunk length\n",
    "fixed_input_chunk_length = 200  # You can change this value based on your preference.\n",
    "\n",
    "# Convert future covariates to TimeSeries objects\n",
    "future_covariates_train = TimeSeries.from_dataframe(train_df, 'Date', future_covariates_columns).astype('float32')\n",
    "\n",
    "# Convert full covariates to TimeSeries objects\n",
    "future_covariates_full = TimeSeries.from_dataframe(df, 'Date', future_covariates_columns, fill_missing_dates=True, freq=\"D\").astype('float32')\n",
    "\n",
    "# Scaling the data\n",
    "scaler_series = Scaler()\n",
    "scaler_covariates = Scaler()\n",
    "\n",
    "# Fit the scaler on the training data\n",
    "series_train_scaled = scaler_series.fit_transform(series_train)\n",
    "future_covariates_train_scaled = scaler_covariates.fit_transform(future_covariates_train)\n",
    "\n",
    "# Transform the test series using the same scaler\n",
    "series_test_scaled = scaler_series.transform(series_test)\n",
    "\n",
    "# Slice future covariates based on series_test's date range to ensure perfect alignment\n",
    "future_covariates_test = future_covariates_full.slice(\n",
    "    series_test.start_time(),\n",
    "    series_test.end_time()\n",
    ")\n",
    "\n",
    "# Ensure the future covariates test set is scaled\n",
    "future_covariates_test_scaled = scaler_covariates.transform(future_covariates_test)\n",
    "\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters (excluding input_chunk_length since it's fixed)\n",
    "    hidden_size = trial.suggest_int('hidden_size', 8, 64)\n",
    "    lstm_layers = trial.suggest_int('lstm_layers', 1, 4)\n",
    "    num_attention_heads = trial.suggest_int('num_attention_heads', 1, 8)\n",
    "    dropout = trial.suggest_float('dropout', 0.0, 0.5)\n",
    "\n",
    "    # Initialize the TFT model with suggested hyperparameters\n",
    "    model = TFTModel(\n",
    "        input_chunk_length=fixed_input_chunk_length,\n",
    "        output_chunk_length=len(series_test_scaled),  # Predict over the entire test set length\n",
    "        hidden_size=hidden_size,\n",
    "        lstm_layers=lstm_layers,\n",
    "        num_attention_heads=num_attention_heads,\n",
    "        dropout=dropout,\n",
    "        likelihood=QuantileRegression(quantiles=[0.1, 0.5, 0.9]),\n",
    "        random_state=42,\n",
    "        add_relative_index=True\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Train the model\n",
    "        model.fit(series_train_scaled, future_covariates=future_covariates_train_scaled, epochs=1, verbose=False)\n",
    "\n",
    "        # Make predictions\n",
    "        forecast_scaled = model.predict(n=len(series_test_scaled), future_covariates=future_covariates_test_scaled)\n",
    "\n",
    "        # Inverse transform the forecast to the original scale\n",
    "        forecast = scaler_series.inverse_transform(forecast_scaled)\n",
    "\n",
    "        # Return Mean Squared Error as the objective metric for Optuna to minimize\n",
    "        error = mse(series_test, forecast)\n",
    "        if np.isnan(error):\n",
    "            return float('inf')\n",
    "        return error\n",
    "    except Exception as e:\n",
    "        print(f\"Trial failed due to: {e}\")\n",
    "        return float('inf')\n",
    "\n",
    "# Run the Optuna study with more trials, using the fixed input_chunk_length\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=5, n_jobs=1)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print('Best hyperparameters: ', study.best_params)\n",
    "\n",
    "# Use the best hyperparameters with the fixed input_chunk_length\n",
    "best_params = study.best_params\n",
    "\n",
    "# Initialize the final model with best hyperparameters\n",
    "best_model = TFTModel(\n",
    "    input_chunk_length=fixed_input_chunk_length,\n",
    "    output_chunk_length=len(series_test_scaled),  # Predict over the entire test set length\n",
    "    hidden_size=best_params['hidden_size'],\n",
    "    lstm_layers=best_params['lstm_layers'],\n",
    "    num_attention_heads=best_params['num_attention_heads'],\n",
    "    dropout=best_params['dropout'],\n",
    "    likelihood=QuantileRegression(quantiles=[0.1, 0.5, 0.9]),\n",
    "    random_state=42,\n",
    "    add_relative_index=True,\n",
    "    loss_fn=torch.nn.MSELoss()\n",
    ")\n",
    "\n",
    "# Train the best model\n",
    "best_model.fit(series_train_scaled, future_covariates=future_covariates_train_scaled, epochs=1, verbose=True)\n",
    "\n",
    "# Make predictions starting from the correct point\n",
    "forecast_scaled = best_model.predict(\n",
    "    n=len(series_test_scaled),\n",
    "    future_covariates=future_covariates_test_scaled\n",
    ")\n",
    "\n",
    "# Inverse transform the forecast to the original scale\n",
    "forecast = scaler_series.inverse_transform(forecast_scaled)\n",
    "\n",
    "# Convert TimeSeries to DataFrame for Plotly plotting\n",
    "test_df_plotly = series_test.pd_dataframe()\n",
    "forecast_df_plotly = forecast.pd_dataframe()\n",
    "\n",
    "# Plot the results using Plotly\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add actual test data trace\n",
    "fig.add_trace(go.Scatter(x=test_df_plotly.index, y=test_df_plotly['Day_ahead_price (€/MWh)'],\n",
    "                         mode='lines', name='Actual Test Data', line=dict(color='darkblue')))\n",
    "\n",
    "# Add forecast data trace\n",
    "fig.add_trace(go.Scatter(x=forecast_df_plotly.index, y=forecast_df_plotly['Day_ahead_price (€/MWh)'],\n",
    "                         mode='lines', name='TFT Forecast on Test Data', line=dict(color='red')))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title='TFT Model - Test Performance with Optuna Hyperparameter Tuning',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Day Ahead Price (€/MWh)',\n",
    "    legend=dict(\n",
    "        x=1,\n",
    "        y=1,\n",
    "        xanchor='right',\n",
    "        yanchor='top',\n",
    "        bordercolor='black',\n",
    "        borderwidth=1\n",
    "    ),\n",
    "    template='plotly'\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n",
    "\n",
    "# Evaluate the model using Darts' metrics\n",
    "print(f'Mean Absolute Error on Test Set: {mae(series_test, forecast)}')\n",
    "print(f'Mean Absolute Percentage Error on Test Set: {mape(series_test, forecast)}')\n",
    "print(f'Mean Squared Error on Test Set: {mse(series_test, forecast)}')\n",
    "print(f'Root Mean Squared Error on Test Set: {rmse(series_test, forecast)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
